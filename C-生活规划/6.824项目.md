
## 6.824 MapReduce

MapReduce是论文中提出的一种**大数据计算框架**，谷歌根据他们的计算业务，将大数据计算抽象成一系列Map操作和Reduce操作，基于MapReduce任务调度集群，数据分析人员只需要编写基本的Map函数和Reduce函数即可在大规模集群上运行分布式计算，无需考虑具体的分布式调度过程。

本实验是编写一个MapReduce分布式任务调度服务，整体为Master/Worker架构。首先Master启动，根据输入文件列表拆分为X个Map任务和Y个Reduce任务。Worker启动后定时通过rpc向Master发生心跳消息，Master初次收到新Worker消息会创建并返回WorkerID，并将Worker加入到空闲Worker队列中。Worker节点是支持动态扩容的。

任务执行阶段，对于Map任务，Master不断从空闲Worker队列中取出Worker节点，并当下一次心跳时将Map的输入文件位置、Reduce任务数量等信息发生给Worker，Worker收到任务并开始执行。Map函数的输入是文件的每一行，输出是kv列表，Worker对输出结果进行shuffle，利用hash函数运算k并对Reduece任务的数量取模，结果追加到X_Y.tmp中间文件中。当前Worker的Map任务执行完成后，会通过心跳将输出文件列表发送给master。Master将此Worker再放入空闲队列等待下次调度。当所有Map任务执行完成，Master将所有中间文件夹根据Reduce任务号进行分组，再把Reduce任务分配给Worker，Worker收到文件列表会先全部读取，排序，将相同key和value的列表传入Reduce函数，reduce结果追加到以Reduce任务号结尾结果文件中。并将结果返回Master，Master确认所有Reduce任务结束，整个任务执行完毕。

**高容错的设计**

- Master维护了每个Worker的上次心跳时间，当超时一定时间将Worker移除，并将其任务重新分配。当Worker恢复会再次将其加入Worker队列中。
- Map和Reduce输出结果都是先追加到临时文件中，当整个Map或Reduce任务执行完毕再将其重命名到最终文件，这样即使因为网络问题导致的任务重复执行，也不会有问题。

## 6.824 Raft

raft是一个分布式一致性协议，用于集群对一系列的提交达成共识。raft设计的出发点是简单易懂。节点分为Leader、follower、candidate，Leader负责处理数据的提交和对从节点的负责，尽可能避免复杂的操作。整个协议主要分为三个部分：Leader选举、日志复制、安全容错

Leader选举：

- 每一个节点记录了当前节点上次与其他节点正常通信的时间，如果超时未正常通信代表当前集群不存在Leader，自己变为candidate，对自己的Term+1，并给自己投一票，并发对其他节点发送requestVote投票请求，并带有Term和自己最新数据的任期、index。其他节点收到来自大于自己任期且数据不比自己旧的投票请求时，就对他投一票，更新自己的任期，每个节点在同一任期最多投一票。当候选者收到大于半数票，立即变为Leader，并给所有节点发送心跳，建立Leader地位。
- 所有日志读、写请求都是发送或转发给Leader。Leader通过心跳与follwer同步数据，使用两阶段提交，当超过半数节点确认收到日志，Leader本地提交日志，返回客户端并向其他节点发送提交信息，其他节点收到后在本地进行提交。

日志复制：

- Leader维护了每个follower节点复制的index与commitIndex，当有新数据提交，日志会随着心跳发送到各个节点上。当超过半数的节点复制成功，Leader本地提交并返回客户端，然后Leader向所有从节点发送提交信息，从节点在本地进行提交。

安全容错

- Leader必须有超过半数节点支持，旧Leader收到新任期消息立即变为follwer，避免了脑裂。
- 每个节点超时时间150~300m随机数，减少了多节点同时过期选主竞争失败的可能
- 数据提交需要超过半数节点的支持，Leader选举也需要超过半数节点支持，因此每个Leader必定携带已提交的数据，保证了数据提交的不丢失。
- 日志不同步问题：raft基于有限状态机的思想，所有相同初始状态的节点，按相同的顺序执行相同的操作，最终的状态是一致的。Leader维护了每一个follower的下一个待提交的index、已提交的index。在心跳时follwer发送当前同步位置的前一个日志的index和term，当follwer确认同步就可继续发送剩下的消息，当不同步时，Leader将同步位置减一，依次查找直到同步。
- Leader对之前任期的数据只复制不提交，当前任期有新日志时，在当前日志的担保下同时提交
- 数据集持久化，所有节点在提交数据前将本节点的状态信息序列化并持久化，宕机重启后加载之前的状态信息即可。

做这个项目的最大的困难是什么，怎么克服的？
1. 首先对论文整体内容的理解，这里很多细节信息，而且这些信息都特定的时刻，需要自己定义一些数据结构包含一些变量呀，这些实现基本都有类似状态机，不同时刻做不同事情，这个要自己仔细理解清楚。
2. 一些特殊情况的考虑
	1. 比如mapreduce的的备份任务要怎么做达到高可用，要怎么做， 比如mapreduce的的备份任务要怎么做达到高可用
	2. 多个节点同时发起选举导致选票分散，网络延迟造成的重复选举，新老领导者共存的脑裂情况
3. 日志一致性维护： 
	1. 节点崩溃后重启时的日志恢复
	2. 网络分区时日志的部分提交
	3. 日志条目索引匹配的复杂性




