# 实习业务背景

## 一些专有名词的解释

### SDN网络

软件定义网络（SDN）是一种将网络资源抽象到虚拟化系统中的 [IT 基础架构](https://www.redhat.com/zh/topics/cloud-computing/what-is-it-infrastructure)方法。这被称为[网络虚拟化](https://www.redhat.com/zh/topics/virtualization/what-is-network-virtualization "什么是网络虚拟化？")。SDN 将网络**转发功能与网络控制功能**分离开来，目的是创建可**集中管理且可编程的网络**，这也就是说将控制平面与数据平面分离。

- 软件定义网络的优势（与传统网络相比）
    - **控制平面与数据平面分离**：控制平面负责决定如何转发数据包，由基于软件的控制器集中实施。数据平面负责通过网络实际转发数据包，它仍存在于基于硬件的网络设备中，但经过了简化和专门设置，只专注于数据包转发。在传统网络中，控制平面和数据平面通常集成在交换机、路由器和接入点等网络设备中，无需进行集中控制。
    - **集中控制**：软件定义网络提供集中式控制，网络策略和配置由中央控制器管理和实施，这与传统网络不同，传统网络的网络策略和配置分布在多个网络设备上。
    - **成本更低**：与硬件基础架构相比，软件定义网络基础架构通常更便宜，因为它们是在现成的商用服务器上运行，而不是在昂贵的单一用途设备上运行。由于软件定义网络基础架构可以在单个服务器上运行多项功能，因此它们占用的空间也比较少。这就意味着需要的物理硬件更少，故而更利于资源整合，以降低物理空间占用、功耗和总体成本。 
    - **更高的可扩展性和灵活性**：通过[虚拟化](https://www.redhat.com/zh/topics/virtualization/what-is-virtualization)网络基础架构，您可以在合适的情况下根据需要扩展或收缩网络资源，而不必急于添加其他专有硬件。采用软件定义网络后，您会获得极大的灵活性，可实现网络资源的自助置备。
    - **可编程且能轻松实现自动化**：在软件定义网络中，管理员使用软件定义的逻辑和 API 来定义网络策略和配置。这使我们能够动态配置网络资源并基于策略对其进行管理，有利于快速部署和适应不断变化的业务需求。传统网络通常需要使用命令行界面（CLI）或特定于设备的配置工具对网络设备进行手动配置和管理。 
    - **简化管理**：软件定义网络使整个[基础架构](https://www.redhat.com/zh/topics/cloud-computing/what-is-it-infrastructure)更容易运维，因为无需极其专业的网络专家来管理。
### CDN网络

- cdn基础
    内容分发网络（CDN）是一种在现有互联网基础上增加的新型网络架构，通过遍布全国的**高性能节点**来存储和分发内容。它的工作原理类似于一个全国性的仓库系统：**源站**（比如位于北京的主服务器）将内容分发到**各地的CDN节点**，当用户请求内容时，系统会将请求**引导到距离用户最近的节点**，从而大大减少响应时间。CDN采用多层架构，从用户到地市节点，再到大区节点，最后到源站，这种层级结构确保了全国各地的用户都能获得相似的访问速度。CDN的主要优势在于提高了内容传输的效率，降低了源站的压力，并通过就近访问的原则，显著改善了用户体验。随着互联网的发展，CDN架构也在不断演进，从简单的地区分布发展到更复杂的多层次结构，目的是为了在全国范围内实现更均衡、更高效的内容分发。

- DNS调度
    CDN中的DNS调度是一种关键机制，用于将用户请求引导到**最合适的CDN节点**。这个过程利用了DNS系统的灵活性，通过智能分析用户的位置和网络状况来做出决策。当用户访问使用CDN服务的网站时，**DNS解析不会直接返回源站I**P，而是返回CDN的智能DNS系统。这个系统会根据用户的LDNS（本地DNS）地址或EDNS客户端子网信息来判断用户的大致位置和网络环境。基于这些信息，CDN的DNS系统会**选择一个最优的CDN节点**，并将其IP地址返回给用户。这种方法确保了用户能够连接到反应最快、最近或负载最轻的CDN节点，从而提高访问速度和用户体验。DNS调度的优势在于其简单性和广泛兼容性，但也面临着精确度和实时性的挑战。为了进一步优化，一些CDN提供商还采用了HTTPDNS等技术来补充传统DNS调度的不足，以实现更精准的用户定位和更灵活的调度策略。

- 缓存机制
    CDN的缓存机制是其高效运作的核心。这个机制主要涉及三个方面：缓存空间、缓存内容和缓存策略。
    缓存空间方面，CDN节点使用有限的磁盘空间来存储内容。为了有效管理这些空间，CDN通常采用"最近最少使用"（LRU）等算法来淘汰不常访问的内容，确保热门内容始终可用。
    在缓存内容方面，CDN主要缓存HTTP响应中的主体内容（body），而对于状态行和头部信息，则根据需要选择性地缓存。这种做法既节省了存储空间，又保证了关键信息的可用性。
    缓存策略是CDN运作的关键。CDN根据URL模式或文件类型设置不同的缓存规则。一般来说，静态内容会有较长的缓存时间，而动态内容可能不缓存或只短暂缓存。CDN还会遵循源站设置的缓存控制头，如Cache-Control和Expires。
    当缓存内容过期时，CDN节点会根据配置决定是直接删除内容还是验证内容是否真的需要更新。这种机制称为"尽力而为"的缓存，既保证了内容的及时性，又避免了不必要的回源请求。
    通过这些机制，CDN能够在提供最新内容和减少源站压力之间取得平衡，从而提高整体的内容分发效率和用户体验。同时，CDN还提供了刷新和预热等功能，让内容提供者可以主动管理缓存内容，以应对突发的内容更新需求。

- 预热篇
    CDN预热是一种主动将内容推送到CDN节点的机制，旨在提高用户首次访问特定内容时的响应速度。预热的主要目的是避免在高访问量期间出现大量回源请求，从而减轻源站压力并提升用户体验。
    预热通常在预期会有大量访问的内容发布前进行，比如新游戏发布、电商大促或重要网站更新时。通过预热，内容提供者可以确保在用户大规模访问前，内容已经分发到了CDN的各个节点。
    预热过程中，CDN系统会模拟用户请求，主动从源站获取指定的内容并存储在CDN节点上。预热可以针对单个URL、多个URL或整个目录进行。预热请求通常由专门的预热集群发起，以避免影响正常的用户访问。 
    预热的范围和深度可能因CDN提供商而异。有些支持仅预热到中间层节点，而有些可以预热到边缘节点。预热的效果取决于预热触发的CDN节点与源站的距离，距离越近，预热效果可能越差。
    大多数CDN服务商对预热功能有使用限制，如每日可预热的URL数量或单次提交的数量上限，这是为了平衡系统资源和避免滥用。
    预热虽然有助于提高内容可用性，但也需要谨慎使用。过度预热可能会占用大量带宽和存储资源，反而影响CDN的整体性能。因此，内容提供者需要根据实际需求和流量预期来合理使用预热功能，以达到最佳的内容分发效果。

- 刷新篇
    CDN刷新是一种强制更新CDN节点上缓存内容的机制。当源站内容更新，但CDN节点上的缓存尚未过期时，刷新功能可以确保用户能够及时访问到最新的内容。
    刷新主要有两种类型：URL刷新和目录刷新。URL刷新针对特定的文件，而目录刷新可以更新整个目录下的所有文件。目录刷新又分为刷新变更资源和刷新全部资源两种模式。
    刷新操作会影响CDN全网节点。对于URL刷新和目录刷新全部资源，系统会直接删除缓存的内容。而对于目录刷新变更资源，系统会将资源标记为过期，并在下次访问时与源站比对修改时间（Mtime）来决定是否需要更新。
    刷新通常在5分钟内生效，但具体时间可能因CDN提供商而异。大多数CDN服务商对刷新操作有数量限制，以防止过度刷新影响系统性能。
    刷新虽然能确保内容及时更新，但也有一些潜在风险：
    1. 可能导致短时间内回源请求激增，增加源站压力。
    2. 刷新后的首次访问可能会稍慢，因为需要重新从源站获取内容。
    3. 大规模刷新可能会暂时影响CDN的整体性能。
    因此，内容提供者应谨慎使用刷新功能，特别是目录刷新。在进行大规模内容更新时，建议配合使用预热功能，以减少对用户体验的影响。
    如果刷新后内容仍未更新，可能需要检查源站内容、用户本地缓存、中间代理服务器缓存等多个环节，以确定问题所在。


### ACL

控制面:访问控制列表ACL(Access Control List)是由一条或多条**规则**组成的**集合**。所谓规则,是指描述报文匹配条件的判断语句,这些条件可以是报文的**源地址、目的地址、端口号**等。

```
seq10 permit ip host192.168.10.1host192.168.20.1
```

数据面:ACL本质上是一种**报文过滤器**,规则是过滤器的滤芯。设备基于这些规则进行**报文匹配**,可以过滤出特定的报文,并根根据应用ACL的业务模块的处理策略来允许或阻止该报文通过。

```c
   table acl {
        key = {
            standard_metadata.ingress_port: ternary;
            hdr.ethernet.dst_addr: ternary;
            hdr.ethernet.src_addr: ternary;
            hdr.ethernet.ether_type: ternary;
            local_metadata.ip_proto: ternary;
            local_metadata.icmp_type: ternary;
            local_metadata.l4_src_port: ternary;
            local_metadata.l4_dst_port: ternary;
        }
        actions = {
            clone_to_cpu;
            drop;
            forward;
        }
        counters = acl_counter;
    }
```


#### ACL芯片原理


<img src="https://yesho-web.oss-cn-hangzhou.aliyuncs.com/img/20240902151709.png" alt="image.png" style="zoom:60%;" />

```sh
seq 100 permit ip host 192.168.10.1 host 192.168.20.1
```

1.智能模板选择器根据模板类型为每一个处理器生成一个key，key中的内容包括数据包自身的内容、四层端口检查结果、交换数据;
- Packet Data: 报文头部
- Range Check Result:四层端口检查结果
- Switch Status Data:L2/L3转发结果
2.生成的key分别和查找表(lookup engine)中存储的关键字进行比较，并返回表中与key匹配的表项的Index；（FP_TCAM）
3.通过该Index从策略表(policy engine)中找到相应的内容，该内容表明了针对该数据包的Action（FP_POLICY）和对应该数据包的速度统计（Meter）和计数（Statistics）
4.最后通过动作决策引擎(Action Resolution Engine)从匹配的个Action中选出一个或多个Action对数据包动作。

## 网络操作系统的背景


网络白盒化已成为大规模IDC建设的必然选择,1. 实现网络的可编程性和SDN化。白盒交换机基于Linux系统,更容易实现网络的可编程和软件定义。

1. 顺应市场趋势。文中提到白盒化已成为大规模IDC建设的必然选择,未来几年白盒交换机出货量将超过商用交换机。
2. 实现网络的可编程性和SDN化。白盒交换机基于Linux系统,更容易实现网络的可编程和软件定义。
3. 降低成本。相比商用交换机,白盒交换机的软件成本更低,整体TCO更低。
4. 提高迭代速度。可以根据自身需求快速迭代升级网络设备。
5. 提升运维效率。统一的NOS系统,便于实现网络运维的自动化和CI/CD。
6. 增强可控性。软硬件设计、关键芯片、供应链等都可以自主可控。
7. 促进新技术应用。为引入100G/400G等新技术提供便利。
8. 赋能业务系统。可以提升高性能计算、存储等系统的效率。
9. 与业界接轨。国内外互联网巨头都在大规模应用白盒交换机。
10. 提升网络监控能力。可以开发更精细化的网络监控手段。

### 商用交换机的问题

商用交换机是一个**封闭且异构**的系统，因此可以看做是一个黑盒

1. 难以满足精细化网络监控需求
    网络规模、网络带宽容量越来越大，对**网络监控系统**的要求也越来越高，精细化网络监控需求比较强烈，特别是**RDMA等高性能网络**场景，比如：
- 高精度（秒级）采集监控流量、时延、丢包等信息。
- 端到端监控能力，实时定位时延、丢包等异常问题，细化到具体的设备及链路。
- 设备运行状态细节、甚至芯片状态（比如缓存水位）的感知，以便快速定位网络问题。
- 针对不同网络场景或者网络问题定位需要，灵活按需增加特定的信息数据采集。
2. 难以满足大规模**网络自动化能力**要求
    各商用交换机产品的内部实现技术架构、对外接口界面格式都不相同，导致网络管理难度加大，故障定位困难，整体自动化程度低，比如：
- 运维界面不统一、内部运行机制也不尽相同，难以实施一致的故障定位及自动化策略。
- 需要大量适配代码、模板来实现对不同设备型号的支持，复杂度高且容易出错。
- 大量自动化策略只能基于存量设备型号的统计经验，新引入设备可能打破统计经验，从而需要全部重新实现，甚至引入稳定性风险。
- 操作结果验证困难（通过回显字符串解析）甚至无法验证，存在稳定性风险。


### KNOS介绍

<img src="https://yesho-web.oss-cn-hangzhou.aliyuncs.com/img/20240902113942.png" alt="image.png" style="zoom:40%;" />

- 在硬件质量保证上，主要采用定规格、抓过程的方法。自研团队制定网络设备的硬件规格书、测试规范、测试方法，通过审核厂商在设计和生产过程的设计文档、测试报告等手段对设备硬件进行质量保证，同时也会利用厂商的测试资源进行实验室测试、灰度测试等来对硬件质量进行验证；
- 在BSP&Driver的质量保证上，自研团队设计逻辑框架，由厂商进行具体的代码实现。通过自研的驱动框架进行设备的解耦，使自研SONiC可以方便的移植到不同厂商的硬件平台。质量保证是通过代码的review、单元测试、自动化测试等灰盒测试方法进行质量保证；
- 在转发平面，通过SAI实现对不同芯片差异的屏蔽，通过对SAI代码的掌控来保证控制逻辑的正确性，通过手动与自动化测试方法对芯片转发行为进行质量保证；
- 在控制平面、管理平面的功能设计是自研团队在社区SONiC代码的基础上进行验证、适配和开发，通过白盒的测试方法进行质量保证；

模块的事件关系

<img src="https://yesho-web.oss-cn-hangzhou.aliyuncs.com/img/20240902114540.png" alt="image.png" style="zoom:40%;" />
模块联动

<img src="https://yesho-web.oss-cn-hangzhou.aliyuncs.com/img/20240902115928.png" alt="image.png" style="zoom:80%;" />


- PortsOrch: 端口模块负责管理端口/LAG/VLAN的创建，删除，以及VLAN和LAG member的创建和删除。当有配置更新的时候，会通知相关的模块。当端口有up/down事件的时候，也会通知相关的模块。
- Neighsyncd：作用是通过RAW socket来获取端口上的ARP & NS & NA报文，然后根据报文头来向APP DB中写入邻居信息。邻居的创建，删除，邻居探测和刷新功能都是由Neighsyncd来完成。此外Neighsyncd还会更新内核中的邻居表，使内核的邻居表和下发交换机的保持一致。
- NeighOrch：负责监听APP DB中邻居table中的数据变化，然后根据变化来下发更新到ASIC DB中。此外，当有邻居添加动作的时候会通知相关的模块有邻居事件。当有邻居摘除的时候，会先通知相关模块邻居即将删除，然后再删除邻居（引用计数，相关模块摘除相关表相之前，邻居无法正常删除）
- FdbOrch： 负责VLAN FDB表维护的模块，当端口发生up/down，或者VLAN配置发生改变的时候，需要对这些事件做出响应。
- IntfsOrch： 负责三层Interface的管理工作，当端口发生up/down的时候，需要对此做出反应。
- AclOrch： ACL Orch中的重定向到端口的功能需要关注端口/LAG/VLAN的创建和删除事件，当发生该事件的时候，需要对ACL表项进行相应的操作。
- MirrorOrch： 负责Mirror Session的维护，关注LAG和VLAN member的添加和删除事件。

<img src="https://yesho-web.oss-cn-hangzhou.aliyuncs.com/img/20240902114558.png" alt="image.png" style="zoom:60%;" />
SAI的接口是开源的，芯片厂商根据SAI的标准接口调用自己的SDK来实现具体的芯片操作，芯片厂商提供二进制的libary完成具体SAI的功能，在编译的时候进行链接。

#### 快手自研NOS相比社区NOS优点

社区SONiC经过几年的发展迭代，已经可以满足绝大部分数据中心的需求。但由于微软数据中心的运维方式与国内数据中心的不同，在SONiC的设计上存在以下问题：
- 配置不支持无损动态修改。微软的数据中心的所有网络设备的配置都不会动态更改，当需要进行配置更改的时候对设备进行reload操作。一方面微软服务的弹性迁移能力很强，在配置变更之前很方便将受影响的业务进行迁移走，另一方面，国外对网络的SLA制定的比较合理，允许网络有一定的故障修复时间。
- 设备事件联动处理的不好。如端口出现down以后，需要进行FDB、路由的删除，以免出现路由黑洞现象，但在SONiC中没有这部分的处理。这是因为在微软的网络中，如T0设备出现端口down事件以后，如果是和服务器的连接端口，此时不需要做处理；如果是和T1设备相连接的端口，则由BGP协议的keepalive进行路由的切换。这种处理机制也是和国外的网络SLA有关系；
- 没有完善的CLI。在SONiC中的命令行是Linux的shell风格的，没有统一的命令行入口，命令比较风扇，同时很多配置命令也是缺失的，这也是和微软的运营方法有关系。微软的网络管理平台很完善，不需要运营工程师登陆设备进行操作，所有的操作都是在平台上完成。
- 缺少网络故障定位功能，如芯片底层寄存器的统计能力，格式化输出能力等。这是因为很多网络故障定位的工具是运行在服务器上，如pingmesh、everflow等，可以通过这些功能实现网络的故障发现和定位；
- 功能定义方面差异，如RDMA功能，微软使用的参数是和它的网络、流量模型有关，这些与网络流量的模型被直接写入到SONiC代码中，其他厂商使用RDMA功能就比较困难；
- 缺少一些必要的功能，如国内OTT厂商使用的去堆叠方案；

#### 端口的联动

<img src="https://yesho-web.oss-cn-hangzhou.aliyuncs.com/img/20240902141539.png" alt="image.png" style="zoom:60%;" />

<img src="https://yesho-web.oss-cn-hangzhou.aliyuncs.com/img/20240902141618.png" alt="image.png" style="zoom:60%;" />


# 实习工作介绍

- **实习背景**： 随着数据中心规模扩大，网络设备白盒化成为趋势。快手积极推进网络基础设施的自主可控，团队致力于开发基于开源SONiC的自研网络操作系统（NOS）。
- **主要工作**：
    1. 参与编写SONiC编译架构的脚本，并负责SONiC的BSP层的管理适配，提高了系统的可移植性和维护效率。
    2. 设计并实现了基于策略的路由（PBR）功能，增强ACL系统与路由、下一跳和ARP的联动处理，显著提高了网络策略的灵活性和可靠性，使网络管理更加高效。
    3. 参与动态端口分流功能的开发，负责后端组件的实现，主要对CLI下发的端口配置命令进行相应的处理以及VLAN、Interface的依赖管理。实现了配置的无损动态修改，提高了网络配置的灵活性。
    4. 对KNOS驱动层面的代码进行维护，负责定位和修复KNOS存在的软件缺陷，提高了系统的稳定性和性能。
- **个人成就**：深入理解了网络操作系统的架构和工作原理，提升了C++系统级编程能力。学会了在复杂开源项目中进行二次开发和定制化，增强了代码阅读和重构能力。

## 第一个工作内容

### 项目是什么？

sonic编译系统是一个基于GNU  make的自动化构建环境，它是一个很复杂的编译过程，里面一个makefile都要几千行，包含各种组件的编译过程。
### 我负责什么

我的第一个任务就是写把这个复杂的编译过程梳理写好一个文档(里面要讲好这个整体架构、编译流程、一个具体模块的编译过程、sonic新加一个功能(如何集成一个开源的项目))，并写好一个自动化的编译脚步，这个自动化的脚步可以适配各种厂商的类型，以及各种编译选项(release、asan_flag)，以及将最终目标文件一个上传到云端的操作(使用devcloud的命令)，让测试人员用前端页面选择好厂商和芯片类型就可以出版本文件。
### 最大的收获和困难

- 困难
    这个过程最难不是写这个自动化脚步，是梳理这个复杂的编译过程（里面涉及debian、docker、脚本、模块源代码、一堆设备配置、依赖和构建工具），大家都知道编译用makefile,但是这种大型开源项目的编译过程是很复杂的，难点就是在没有文档的参考下如何提炼出重点，就是知道哪些是重点、应该关注。
- 收获
    刚开始梳理这个文档，我是直接去看源代码，源代码很多，而且用了编译的技巧(用了很多宏文件和模版)，这种方式很累，又找不到重点，还怀疑自己的能力。后来mt告诉我，想要去了解一个东西，你应该去了解它的整体，可是没有文档，我不知道整体，那就去概括，概括一个整体过程，忽略任何的实现细节。后面我从编译过程的日志下手，我先看结果，分析了日志的过程(什么文件生成，安装什么依赖)，然后我大致概括出了编译的目的（这个编译过程是干什么的），整体的一个架构和流程。当我知道这些后我再看代码我真的知道自己需要看什么，就有选择了，最终花了快2个星期这个文档写完了，这个文档后来用来做我的新人串讲了，我把这个编译过程分成了所谓的前端和后端集合，我自己画了一个架构图，又将整体流程4部分，画了每部分的流程图以及一个时序图，当我能做完这些事情的时候，我发现这个过程真的很熟了，讲给团队的听了。后面的脚步编译写因为我对整体比较了解了，这个脚步的编写过程不是很复杂，因为我知道要做什么，我会就去查。

bsp管理是对不同厂商设备的适配到我们快手的KNOS中，我之前写的文档包含了各设备厂商通用的步骤，要适配需要改厂商的一些配置文件和源代码，这块工作也由我做，虽然每个厂商的步骤不一样，但大致逻辑差不多，我将厂商的逻辑理清楚，将它的逻辑解绑掉，添加我们快手的特定的配置管理。

## 第二个工作内容

### 项目是什么？ 

传统路由主要基于目的IP地址进行转发决策，而PBR允许根据更多条件（如**源IP、协议类型**等）来决定数据包的转发路径。这在复杂的网络环境中非常有用，比如实现流量工程、负载均衡或特定的安全策略。
PBR（基于策略的路由）功能的引入是为了增强网络的灵活性和控制能力。PBR采用ACL**匹配流(使用ACL识别特定的流量)**，动作redirect next-hop变更流量出端口来达到目的

我们的系统中ACL（访问控制列表）已经支持PBR动作。
前面说了社区的NOS设备事件联动处理的不好，这块缺乏与路由系统、下一跳管理和ARP的深度集成，这是项目内容
### 我负责什么
主要包括以下几个方面：
首先，我增强了ACL系统，使其能够感知和响应路由变化。当路由表更新时，相关的PBR规则也会自动调整。其次，我实现了下一跳的动态管理机制。当网络拓扑发生变化，如添加或删除路由器时，PBR规则能够及时更新以反映这些变化。最后，我建立了与ARP系统的联动，确保PBR规则始终使用有效的二层地址信息。
这个功能的实现涉及多个系统组件的协作，包括路由管理器、ACL管理器和ARP管理器。我通过设计新的接口和新的数据结构，实现了这些组件之间的信息共享和状态同步。
### 最大的收获和难题

1. 在实现PBR功能时，我遇到的两个主要难点是：
    复杂的组件联动逻辑梳理：
    最大的挑战是理清ACL、下一跳、路由和ARP组件之间的复杂联动关系。具体困难包括：
    a) 下一跳联动：需要设计当下一跳添加或删除时，如何同步通知ACL系统，以及ACL需要执行什么操作。这要求我深入理解现有的下一跳管理机制，并在ACL类中添加相应的功能。
    b) 路由联动：需要确定路由变化如何影响PBR规则，以及如何在路由更新时维护PBR规则的一致性。
    c) 数据结构设计：为了支持这些联动，需要设计和实现新的数据结构，如用于跟踪PBR相关路由的集合。
    解决方法：
    首先，我仔细研究了现有ACL、下一跳、路由和ARP组件的代码逻辑。
    然后，基于功能需求设计文档，我绘制了详细的组件交互图，清晰地展示了各组件间的联动关系。
    最后，我设计了新的接口和数据结构，如在ACL类中添加updateRouteChangeForPbr方法，以支持这些联动操作。
    实现过程中的逻辑缺陷和测试问题：
    在初步实现设计的联动逻辑后，遇到了一些错误和测试失败的情况。主要问题包括：
    a) 遗漏某些边缘情况的处理(一些递归问题比如优先级的问题，高优先级失效了，原来的低优先级要生效)。
    b) 某些组件的其他部分未被考虑到，导致了意外的行为。
    c) 测试结果与预期不符，难以定位问题所在。
    解决方法：
    在关键位置添加详细的日志记录，以便跟踪程序执行流程和状态变化。
    仔细分析错误日志，识别出遗漏的情况和未考虑到的组件交互。
    逐步完善逻辑，添加额外的检查和处理来覆盖之前忽略的情况。
    设计更全面的测试用例，包括各种边缘情况和异常情况，确保功能的健壮性。

具体实现
1. 在acl里面的验证动作里面，我们增加pbr重定向这个功能(这里我们对重定向信息进行解析，发现/是路由，没有就是下一跳，对于路由提取出ip的前缀，存在路由类和自己新加的重定向配置变量，然后得到重定向id)
2. 在acl的规则类里面写上下一跳更新要做的事情
3. 在移除acl规则里面加上一处路由的操作(在规则3类里面遍历所有的ip前缀，我把路由类的这个重定向的ip前缀设置为false)
4. 如何通知，在sonic里面通知有两种通知方式(第一种redis的是PubSub的服务间通信的接口，自带的keyspace消息通知机制当数据库中的任何一个key对应的值发生了变化，就会触发Redis发送两个keyspace的事件通知，另外一个是notifly方式定义一个observer类和一个subject类，在Subject定义函数attach、detach和notify，在observe里面定义update,要通知的类，在初始化是通知类.attch(this)，通知类状态变化触发notify里面会各种类的自己重新定义的update函数)
5. 在类的update里面添加一个重定向的通知类型，在处理acl规则的函数增加一个标志位表示是否重定向(在处理acl规则检测到set命令是关于重定向且验证正确这个标志位设置为true)
6. 在邻居类里面在移除下一跳那里移除acl的引用。
7. 在路由类里面的添加和移除路由方法那里，添加更新acl路由变化pbr方法。


收获
再接到这个任务时，这个任务的pbr的CLI配置，团队管控的那边的已经做了，这个任务我花了三周，有了前面的前车之鉴，这个任务我先去相关背景，了解什么是acl、路由、下一跳，先之前的代码得到代码，把之前的联动逻辑，然后试着写这个功能开发文档，画好逻辑图，做好这个方案，讲给团队的人，他们会给我提意见，比如路由ecmp的情况我没有考虑，引用计数没增加，后面补全这个方案，再去实现，实现的过程中可以复用很多这个类原来的方法，在清晰了目标后去写代码就没有那种盲目感了，这里的收获锻炼了自己的能力，解决问题的能力，还有学会怎么定制化二次开发


## 第三个工作内容

### 项目是什么？

静态端口分流是指在交换机启动时,根据预先定义的配置文件(通常是port_config.ini或类似文件)来设置端口的分流模式，这种静态方法虽然简单，但缺乏灵活性。假如我想要将Ethernet0从100G更改为4x25G，就需要修改默认的port_config.ini，重新分配通道，并重启设备。这种操作会导致所有端口的服务中断，在生产环境中会有很大的效率影响。

前面社区说的配置不支持无损动态修改就是这块。
我们要实现的动态端口分流就是允许在设备运行时改变端口的分流模式,而不需要重启设备或中断其他端口的流量。

### 我负责什么

前面端口的配置分流类型、以及CLI的检测命令和下发confib数据团队管控面的人已经做好了，我负责后端组件的实现，主要对CLI下发的端口配置命令进行相应的处理，这里的端口分流命令下发到后端是透明，因为结偶性，后端只会检测到这个是这是个删除、添加的动作，本来后端没有删除动作、添加动作也只是在初始化时候，我实现了后端的添加和删除动作，添加和删除只是基础的功能，这个动态分流还要做依赖处理，这里我做了vlan、lag、acl、interface

### 难点和收获

难点：
这个任务最难的是依赖的处理，我原来的方案里面是用端口引用计数，添加和删除端口之前去处理依赖，比如在删除端口之前我们要通过这个引用计数去检测这个端口的依赖关系，然后将这些依赖的属性删除然后才能安全的删除端口。这里的问题是目前实现的引用计数只能知道我被引用多少次，不知道谁引用我，这个功能本来用来误删除的，引用计数不为0不删除。后来组里将将静态的依赖(配置依赖VLAN成员、ACL绑定)，但是这里问题还有有些依赖系统运行过程中动态生成的依赖关系(FDB（转发数据库）条目、动态学习的邻居表项、动态路由) 这里依赖通常不直接存储在配置数据库中，而是在运行时维护。这里我们采用的方案是将端口down掉（这里移除端口之前查看一个标记位，是否动态端口的标记，调用端口down的函数），这个会端口状态变化的一系列联动，然后再执行真正的删除动作。
还有一个问题是这些操作要底层的芯片去支持，要跟硬件厂商沟通，让他们执行这种功能，在运行时支持增删端口的sai实现。
还有一个优化是复用现有端口配置比如一些特殊情况，在端口分流前后，一些端口配置没有变化，这些的配置可以不用删除，重新使用，比如在从2x50G切换到2x25G(2)+1x50G(2)模式时，系统识别到第二个50G端口可以保持不变，无需删除和重新创建。这复用了现有的端口配置，减少了不必要的操作。


收获：
     这个任务花了两周，做这个任务还是要先看静态端口分流的逻辑，然后再根据动态端口分流需求去实现，在遇到问题时根据已有这种代码逻辑去查找一种解决办法，想方案时，要给出为什么这么做的理由，就必须静态依赖交给CLI处理，动态依赖交给后台，这里给出这么做的理由(静态依赖通过configdb查询，这块可以通过CLI提前处理，后端有端口状态的变化联动可以采用down的技巧)，这也是团队合作的一种交流方式。

## 第4个工作内容

### 项目是什么？ 

KNOS驱动层面线上出现的一个bug问题，一般由测试或者自己发现.
### 我负责什么？

参与KNOS驱动层面的代码维护,定位/修复问题列表见附录-代码维护记录。

1. ACL绑定到端口时，LAG与PORT的CRM资源引用计数都加1，但实际没有LAG的创建。删除ACL Table，PORT的CRM资源引用计数减少，但LAG的不减少(CRM引用计数在增添ACL Table与删除ACL Table不对应，改删除操作为增添的对应删除操作。)。
2. 绑定2个包含规则的ACL Table至同一个端口，而后解绑并删掉2条规则再配置同名的空Table，原先的规则又出现(TableHwDone与Oid不同步导致软硬件资源删除进入错误判断分支提前返回，软件资源未能按照预期清除。修改代码逻辑使得：Oid为NULL则TableHwDone一定为false)。
3. 云合12.8T设备重启后端口不UP
4. ndp 代理未生效，收到NA请求，没有NA回复报文(查询ndppd代码是读取/etc/ndppd.conf文件，发现两个版本生成的ndppd.conf不同，通过j2模版查看是读取congdb，但是查看两个版本并没有什么区别排除CLI问题，发现第14行有区别)
5. 预加重参数在端口降速和模块替换后查询异常问题分析(当启用自协商时，设置的速度通常是一个期望速度，实际速度可能等于或者低于设置的速度，这个速度的设置是一个建议或上限)
6. DCN5.3.3版本多台设备进程和服务批量异常

### 难点和收获

- 难点
    - 问题需要一些专业的背景知识和硬件知识，比如我收到一个卡片任务是云合12.8T设备重启后端口不UP， 出现这个问题背景是引入100G降速40G，改了预加重参数的下发策略，需要去了解什么预加重参数下发策略、这种引出了光模块、自协商，需要去了解这些东西，在sonic是做什么的？
    - 分析出为什么会造成原因是一个比较复杂的过程，有些问题需要去查询相应的命令比如、sonic-cli 查询单一光模块信息，查看各种日志才能去解决问题。

- 收获
    - 在解决这个bug时，我们首先要做的是理解这个问题，理解这个问题出现背景，只有定位了背景我们分析下一步，然后设计一些复现步骤，多版本去复现这个问题。这个时候我们大概分析下那里出问题，然后再去查看相关的代码分析，这个时候多版本对比代码，看看改了什么东西，导致这个问题出现，分析出原因后去修复和测试。
    - 学会如何分析和排查问题，首先我们查看redis各数据库和syslog日志和sai日志，查看相应组件的docker日志，在docker日志中我们可以，我们可以`show reboot-cause history` 对比这两者的时间，然后还可以查看一些docker inspectshi xi

  2. 实习过程中你有哪些收获？  
      1. 首先是了解一个大公司是怎么运作的？在互联网员工工作是怎么样，平常要做些什么？(比如日报、周报要怎么写)，这点对我收获，对我后面的找工作来说就是没有从学生到职场那种过渡期，就是成熟一点
      2. 熟悉团队的开发流程，比如需求分析、方案设计、编码实现、测试什么的，以及一些“持续集成/持续部署”（Continuous Integration/Continuous Deployment，简称CI/CD）流程，工作了才对git这中版本管理更熟了(快手是用gitlab)，比如合并代码流、卡片接任务，任务状态处理，在gitlab代码中留言
      3. 能力得到锻炼，主要是解决问题的能力，思考方式的转变、以前认为程序员就是肤浅的实现功能，其实在项目组里面，相比实现，发现问题、分析问题、洞察现有的方案的不足，列出解决问题的方案，这些才更重要、更难，这点在我日常的代码维护和修bug有深刻体会。
      4. 实习期间，因为我们是做网络操作系统，属于二次开发，实习期间学习如何阅读大型的开源项目代码(对于代码多的项目，不要一开始扎进代码堆里，要先了解整体架构，有选择的去抓重点，这样也能提高效率和一些简单的重构需求



