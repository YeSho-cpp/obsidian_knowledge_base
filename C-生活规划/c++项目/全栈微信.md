---
excalidraw-plugin: parsed
tags:
  - excalidraw
---
## 项目整体框架


<img src="https://cdn.llfc.club/1709009717000.jpg" alt="image.png" style="zoom:60%;" />

## 项目用到的一些闪亮点

1. 使用 `reqId`来解决异步请求-响应匹配
	在qt发送http请求时，一般都采用异步，而这个时候请求发送和响应接收是分离的。当收到响应时，`reqId` 可以帮助我们确定这个响应对应哪个原始请求以及状态跟踪。 
2. 使用lambda的捕获列表来达到闭包以及加shared_from_this解决异步回调函数参数可能销毁导致导致访问已释放的内存。
3. 使用定义的ConfigMgr.h来读取配置信息,减少
4. 使用c++封装了一个类似go语言中Defer类，可以写一些清理代码，无论条件(异常)怎么样，清理代码都能被执行，增强了代码的健壮性，延迟执行任意的代码块，不仅限于资源释放。
5. 这里用到了状态负载均衡
6. 这里使用队列去保证了**异步发送的有序性**，每个send是判断队列是否有，有了就放入，没有就执行队列的第一个任务，还有解耦的作用。
7. 这里当网络想要收到数据放到**逻辑线程**去处理的时候，它是通过队列来通信的，逻辑线程里面有个工作线程会不断从队列中取数据
8. StateServer返回给GateServer最早采用的方法是轮询的方法，后来改用了最小负载均衡的算法
9. 当连接量一些连接的量上来的时候内存压力比较大，可以放到redis中
10. 这里的滚动聊天是做了一点优化，每次滚动条范围变化都可能触发滚动到底部的操作，当新消息被添加时，`isAppended` 被设置为 true，在接下来的 500 毫秒内，所有的滚动条范围变化都会被视为"新消息添加"的一部分，500 毫秒后，`isAppended` 被重置为 false，这样，多个快速连续的变化被视为一个整体，只触发一次滚动到底部的操作


## 项目可以改进点

### 没有分表、分库和合服

假设我们正在运营一个大型多人在线角色扮演游戏（MMORPG）。

1. 初始状态：

假设我们的游戏刚开始时只有一个数据库，包含以下表：
- players (玩家信息)
- items (物品信息)
- quests (任务信息)

```sql
CREATE TABLE players (
    id INT PRIMARY KEY,
    name VARCHAR(50),
    level INT,
    experience INT
);

CREATE TABLE items (
    id INT PRIMARY KEY,
    player_id INT,
    name VARCHAR(50),
    quantity INT
);

CREATE TABLE quests (
    id INT PRIMARY KEY,
    player_id INT,
    name VARCHAR(100),
    status VARCHAR(20)
);
```

2. 分表：

随着玩家数量增加，`items` 表变得非常大，查询速度下降。我们决定按玩家ID范围分表：

```sql
CREATE TABLE items_0_9999 (
    id INT PRIMARY KEY,
    player_id INT,
    name VARCHAR(50),
    quantity INT
);

CREATE TABLE items_10000_19999 (
    -- 相同结构
);

-- 更多分表...
```

现在，当查询某个玩家的物品时，我们可以根据玩家ID直接查询对应的分表，提高查询效率。

3. 分库：

随着进一步增长，我们决定将不同的功能分到不同的数据库：

- player_db: 存储玩家基本信息
- inventory_db: 存储物品信息（已分表）
- quest_db: 存储任务信息

每个数据库可以部署在不同的服务器上，分散负载。

4. 分服：

为了处理不同地区的玩家，我们创建多个游戏服务器，每个服务器有自己的一套数据库：

- 美国服务器：us_player_db, us_inventory_db, us_quest_db
- 欧洲服务器：eu_player_db, eu_inventory_db, eu_quest_db
- 亚洲服务器：asia_player_db, asia_inventory_db, asia_quest_db

5. 合服：

一段时间后，我们发现美国和欧洲服务器的玩家活跃度下降，决定合并这两个服务器。合服过程可能包括：

a. 数据迁移：
   - 创建新的合并数据库：merged_player_db, merged_inventory_db, merged_quest_db
   - 将美国和欧洲服务器的数据导入到新数据库

b. 数据冲突处理：
   - 处理重复的玩家名称：
     ```sql
     UPDATE merged_player_db.players
     SET name = CONCAT(name, '_US')
     WHERE id IN (SELECT id FROM us_player_db.players);
     ```

c. 更新关联：
   - 更新物品表中的 player_id 引用
   - 更新任务表中的 player_id 引用

d. 服务器配置：
   - 更新游戏服务器配置，指向新的合并数据库

实际应用：

1. 分表：
   ```cpp
   int getPlayerItemTable(int playerId) {
       return playerId / 10000;  // 决定使用哪个分表
   }
   
   void addItem(int playerId, int itemId, int quantity) {
       int tableNum = getPlayerItemTable(playerId);
       std::string query = "INSERT INTO items_" + std::to_string(tableNum) + 
                           " (player_id, item_id, quantity) VALUES (?, ?, ?)";
       // 执行查询...
   }
   ```

2. 分库：
   ```cpp
   sql::Connection* getInventoryDBConnection(int playerId) {
       int serverNum = playerId % NUM_INVENTORY_SERVERS;
       return connectToDatabase("inventory_db_" + std::to_string(serverNum));
   }
   ```

3. 合服：
   ```cpp
   void mergePlayerData() {
       // 从美国服务器导入数据
       executeSql("INSERT INTO merged_player_db.players SELECT * FROM us_player_db.players");
       
       // 从欧洲服务器导入数据，处理可能的ID冲突
       executeSql("INSERT INTO merged_player_db.players "
                  "SELECT id + 1000000, name, level, experience "
                  "FROM eu_player_db.players");
       
       // 更新物品表的引用
       executeSql("UPDATE merged_inventory_db.items "
                  "SET player_id = player_id + 1000000 "
                  "WHERE player_id IN (SELECT id FROM eu_player_db.players)");
   }
   ```

这个例子展示了如何通过分表、分库和合服来处理大规模数据和用户基础。这些技术可以帮助提高系统的性能、可扩展性和管理效率。在实际应用中，这些操作通常会更复杂，可能需要考虑数据一致性、事务处理、数据备份等多个方面。


### 没有根据应用场景选取不同逻辑队列和工作线程

- 单一逻辑队列和单一工作线程可能成为性能瓶颈，无法根据不同类型的消息或任务进行优先级处理，可能导致某些高频或耗时任务阻塞其他任务的处理
- a. 任务分类：
	- 根据消息类型或处理逻辑将任务分类。
	- 例如：登录/注册、好友操作、聊天消息、系统通知等。
- b. 多队列设计：
	- 为每种类型的任务创建专门的队列。


## HttpMgr类的实现



![Image_1725581164233.jpg](http://yesho-web.oss-cn-hangzhou.aliyuncs.com/img/Image_1725581164233.jpg)



登录功能和状态服务


1. 客户端发送登录请求给这个GateServer,这里是做一个简单的验证(邮箱和密码，这里是查询数据库)
2. 然后调用grpc请求给这个StateServer，StateServer会去查chatServer1,这里两个server是TCP的一个**长连接**的server 
3. StateServer会维护一张表，里面是这两个服务连上了多少客户端，会选择一个连接比较少的server,回传到GateServer的是一个ip和token(是在GateServer这里生成的)
4. 这里StateServer起到了一个中转以及查询的作用




可能的问题：

1. 你的项目为什么要用到StateServer？
	我们这里的GateServer要去StateServer获取服务器ip和token，这里的StateServer主要起到一个负载均衡的作用(查看那个TCP服务器比较空闲)
	chatserver是一个TCP长连接的服务，StateServer会维护一张表，维护这两个服务连上了多少个客户端，会给GateServer返回连接较小的chatserver,这个服务器ip和token是在状态服务里面生成的，这里起一个中转以及查询的作用



### 简介

项目第一季完结了，本文做一个整理，介绍面试将被问到的相关问题和技术难点，以及第二季将涉及的开发内容。

下面先介绍项目如何描述。

### 项目如何描述

按照HR搜索简历的方式，基本都是采用关键字搜索，所以要在简历中暴露项目中的技术亮点。

为了让面试官通过简历快速的了解项目和采用的技术，需在项目介绍时融入技术细节，让项目描述更饱满一点。

可增加个人业绩或者个人成长，让面试官了解到项目的意义等。

所以综上所述，简单做个总结，一个项目的描述需包含如下几点：

- 项目描述
- 技术亮点
- 项目价值

**项目描述**

这是一个全栈的即时通讯项目，前端基于QT实现气泡聊天对话框，通过`QListWidget`实现好友列表，利用`GridLayout`和`QPainter`封装气泡聊天框组件，基于`QT network`模块封装`http`和`tcp`服务。支持添加好友，好友通信，聊天记录展示等功能，仿微信布局并使用`qss`优化界面

后端采用分布式设计，分为`GateServer`网关服务，多个`ChatServer`聊天服务，`StatusServer`状态服务以及`VerifyServer`验证服务。

各服务通过`grpc`通信，支持断线重连。`GateServer`网关对外采用`http`服务，负责处理用户登录和注册功能。登录时`GateServer`从`StatusServer`查询聊天服务达到负载均衡，`ChatServer`聊天服务采用`asio`实现tcp可靠长链接异步通信和转发, 采用多线程模式封装`iocontext`池提升并发性能。数据存储采用mysql服务，并基于`mysqlconnector`库封装连接池，同时封装`redis`连接池处理缓存数据，以及`grpc`连接池保证多服务并发访问。

经测试单服务器支持8000连接，多服务器分布部署可支持1W~2W活跃用户。

**技术点**

**asio 网络库**，**grpc**，**Node.js**，**多线程，Redis, MySql，Qt 信号槽，网络编程，设计模式**

**项目意义**

关于项目意义可结合自身讨论，比如项目解决了高并发场景下单个服务连接数吃紧的情况，提升了自己对并发和异步的认知和处理能力等。

### 考察点

#### 1 如何利用asio实现的tcp服务

利用asio 的多线程模式，根据cpu核数封装iocontext连接池，每个连接池跑在独立线程，采用异步`async_read`和`assync_write`方式读写，通过消息回调完成数据收发。整个项目采用的网络模式是Proactor模式，每个连接通过Session类管理，通过智能指针管理Session,b保证回调之前Session可用，底层绑定用户id和session关联，回调函数可根据session反向查找用户进行消息推送。客户端和服务器通信采用json, 通过tlv方式(消息头(`消息id+消息长度`)+消息内容)封装消息包防止粘包。通过心跳机制检测连接可用性。

#### 2 如何保证服务高可用

1. **故障检测与自动恢复**：
    - 实施监控系统，实时检测服务的健康状况。
    - 配置自动重启或故障转移机制，确保在故障发生时能够迅速恢复服务。
2. **分布式架构**：
    - 采用微服务架构，将应用拆分为多个独立的服务，降低单个服务故障对整体系统的影响。
3. **数据备份与恢复**：
    - 定期备份数据，并进行恢复演练，确保在数据丢失或损坏时能够快速恢复。
4. **多活部署**：
    - 在不同地理位置部署多个活跃的数据中心，确保在某个数据中心发生故障时，其他数据中心可以继续提供服务。

#### 3 为何封装Mysql连接池

 首先多个线程使用同一个mysql连接是不安全的，所以要为每个线程分配独立连接，而连接数不能随着线程数无线增加，所以考虑连接池，每个线程想要操作mysql的时候从连接池取出连接进行数据访问。

Mysql连接池封装包括Mgr管理层和Dao数据访问层，Mgr管理层是单例模式，Dao层包含了一个连接池，采用生产者消费者模式管理可用连接，并且通过心跳定时访问mysql保活连接。

#### 4 如何测试性能

 测试性能分为三个方面：

- 压力测试，测试服务器连接上限
  
- 测试一定连接数下，收发效率稳定性
  
- 采用pingpong协议，收发效率稳定在10ms下，连接数上限

压力测试，看服务器性能，客户端初始多个线程定时间隔连接，单服务节点连接上限2w以上稳定连接，并未出现掉线情况

测试稳定性，单服务节点连接数1W情况下，收发稳定未出现丢包和断线，并且延迟稳定在10ms

保证10ms延迟情况下，增加连接数，测下连接数上限，这个看机器性能，8000~2W连接不等。

#### 5 用到哪些设计模式和思想

- Acto模式，逻辑解耦
- 生产者消费者模式（涉及线程池）
- 单例模式(网络管理和数据库管理类)
- RAII思想(defer 回收连接)
- 代理模式(数据库，redis等通过代理对接应用层调用，底层线程池隐藏技术细节)
- MVC控制思想，客户端通过MVC三层结构设计
- 线程分离，网络线程，数据处理线程，以及UI渲染线程分离
- 心跳服务
- 数据序列化压缩发送(Protobuf，Json)
- 队列解耦合，服务器采用发送队列保证异步顺序，通过接受队列缓存收到数据，通过逻辑队列处理数据。
- 分布式设计，多服务通过grpc通信，支持断线重连
- C++11 现代化技术，智能指针，伪闭包，模板类型推导，线程池，future, promise等

#### 6 描述线程池封装

 描述线程池封装，线程池采用C++ 11 风格编写，整体来说线程池通过单例封装，内部初始化N个线程，采用生产者消费者方式管理线程，包含任务队列，任务队列采用package_task打包存储，提供对外接口commit提交任务，采用bind语法实现任务提交在commit内部自行绑定，通过智能指针伪闭包方式保证任务生命周期。同时使用C++ 11 future特性，允许外部等待任务执行完成。

#### 7 为什么要设计心跳？

在网络情况下，会出现各种各样的中断，有些是网络不稳定或者客户端主动断开连接，这种服务器是可以检测到的。

PC拔掉网线，还有一种情况客户端突然崩溃，有时候服务器会检测不到断开连接，那么你这个用户就相当于僵尸连接。

当服务器有太多僵尸连接就会造成服务器性能的损耗。

另外心跳还有一个作用，保证连接持续可用，比如mysql，redis这种连接池，如果不设计心跳，

时间过长没有访问的时候连接会自动断开。

### 第二季待完成内容

第二季半年后开发并更新视频

待开发内容

- 未实现资源服务器及断点续传
  
- 客户端和聊天服务的心跳机制
  
- 实现断线重连和踢人操作(未完全实现，目前仅支持客户端重新登录，服务器重新绑定连接，原连接未踢掉)
  
- 未完整实现用户离线后数据清空操作
  
- 客户端未实现用户信息编辑，头像上传等UI和逻辑
  
- 未实现文件，图片，语音等信息传输
  
- 未实现语音，视频实时通信，涉及音视频编程 





