```sh
root="/PointWSSIS/celldataset"
config_file="configs/PointWSSIS/R101_teacher.yaml" # 指定训练的配置文件
exp_name="SOLOv2_R101_coco5p_teacher" # 实验名称，可能用于标识和保存实验结果。
trainsets="('coco_2017_train_5p_s',)" #强数据名称
testsets="('coco_2017_val',)"
prompt="point"
eval_pseudo_label="True"
learning_rate="0.05"
decay_steps="(20000,25000)"
train_iter="30001" #训练迭代次数
ngpus=2
export DETECTRON2_DATASETS="/PointWSSIS/celldataset"
```



```sh
OMP_NUM_THREADS=1 python3 -W ignore tools/train_net.py \
    --config-file ${config_file} \
    --num-gpus ${ngpus} \
    SEED 1 \
    OUTPUT_DIR training_dir/${exp_name} \
    DATASETS.TRAIN ${trainsets} \
    DATASETS.TEST ${testsets} \
    SOLVER.STEPS ${decay_steps} \
    SOLVER.MAX_ITER ${train_iter} \
    SOLVER.BASE_LR ${learning_rate} \
    MODEL.SOLOV2.PROMPT ${prompt} \
    MODEL.SOLOV2.EVAL_PSEUDO_LABEL ${eval_pseudo_label} \
    TEST.EVAL_PERIOD 5000  #每 5000 个迭代周期进行一次测试评估。
```

```sh
root:
	"images"
		"[]"
			"file_name"
			"height"
			"width"
			"id"
		"type"
		"annotations"
			"[]"
				"segmentation"
					"[[]](4个点坐标)""
				"area"
				"iscrowd"
				"image_id(目标所属tu'x)  "
				"bbox (位置和大小)"
				"category_id"
				"id(框顺序id) "
				"ignore"
		"categories"
			
```


这个segmentation怎么这么多数字，代表什么？
 {"segmentation": [[477.69, 199.52, 477.22, 213.67, 472.51, 226.4, 466.38, 237.25, 445.63, 268.37, 431.95, 268.37, 426.76, 266.48, 424.41, 261.77, 429.59, 259.88, 444.68, 230.17, 454.59, 206.59, 463.08, 190.56, 469.68, 178.3, 477.22, 171.23, 483.83, 168.87, 489.01, 172.17, 491.37, 174.53, 491.84, 180.19, 491.84, 185.84, 487.13, 188.67, 483.83, 188.67, 479.11, 190.56, 478.17, 193.86, 478.17, 195.75]], "area": 2222.093700000001, "iscrowd": 0, "image_id": 276840, "bbox": [424.41, 168.87, 67.43, 99.5], "category_id": 36, "id": 1456106},

这个segmentation是一个包含多个点的列表，代表一个物体的边界。每两个连续的点表示物体边界上的一个线段。数字对代表每个点在图像中的坐标，例如[477.69, 199.52]表示第一个点在图像中的位置。这些数字描述了一个多边形区域，可以用于在图像中标记物体或进行分割任务。



下面是coco一段json格式的注释,counts是一个很大的数组，分别解释参数
```json
segmentation: 
	counts:[...] 
	size: 
		[0]:480 
		[1]:640 
	area:9901 
	iscrowd:1 
	image_id:422405 
bbox: 
	[0]:62 
	[1]:197 
	[2]:418 
	[3]:89 
category_id:1 
id:900100422405 
```

- `segmentation`: 表示目标的分割信息，通常是一个二维数组。在这个例子中，未提供具体分割信息，因此没有值。
- `counts`: 表示目标的分割掩码（mask）的编码形式。它是一个很大的数组，其中每个元素表示一个像素点是否属于目标区域。具体编码方式根据数据集的不同而有所不同。
- `size`: 表示目标的尺寸大小。它是一个长度为2的数组，第一个元素表示目标的高度（480），第二个元素表示目标的宽度（640）。
- `area`: 表示目标区域的面积大小（9901）。
- `iscrowd`: 表示该目标是否为拥挤物体。在这个例子中，该值为1，表示是拥挤物体。
- `image_id`: 表示图像的唯一标识符（422405）。
- `bbox`: 表示目标边界框（bounding box）。它是一个长度为4的数组，分别表示边界框左上角点的x坐标（62），y坐标（197），边界框宽度（418），边界框高度（89）。
- `category_id`: 表示目标所属类别的唯一标识符。在这个例子中，该值为1。
- `id`: 表示该目标的唯一标识符（900100422405）。

下面这个rle是什么还是听不懂？解释下
如果iscrowd=1，那么segmentation就是RLE格式(segmentation字段会含有counts和size数组)，在json文件中gemfield挑出一个这样的例子，如下所示：

```json
segmentation : 
{
    u'counts': [272, 2, 4, 4, 4, 4, 2, 9, 1, 2, 16, 43, 143, 24......], 
    u'size': [240, 320]
}
```

COCO数据集的RLE都是uncompressed RLE格式（与之相对的是compact RLE）。 RLE所占字节的大小和边界上的像素数量是正相关的。RLE格式带来的好处就是当基于RLE去计算目标区域的面积以及两个目标之间的unoin和intersection时会非常有效率。 上面的segmentation中的counts数组和size数组共同组成了这幅图片中的分割 mask。其中size是这幅图片的宽高，然后在这幅图像中，每一个像素点要么在被分割（标注）的目标区域中，要么在背景中。很明显这是一个bool量：如果该像素在目标区域中为true那么在背景中就是False；如果该像素在目标区域中为1那么在背景中就是0。对于一个240x320的图片来说，一共有76800个像素点，根据每一个像素点在不在目标区域中，我们就有了76800个bit，比如像这样（随便写的例子，和上文的数组没关系）：00000111100111110...；但是这样写很明显浪费空间，我们直接写上0或者1的个数不就行了嘛（Run-length encoding)，于是就成了54251...，这就是上文中的counts数组。下面这个python代码片段直观的显示了这些bit：

```python
rle = [272, 2, 4, 4, 4, 4, 2, 9, 1, 2, 16, 43, 143, 24, 5, 8......]
assert sum(rle) == 240*320
```

这段文本解释了RLE（Run-length Encoding）格式在COCO数据集中的应用。RLE是一种压缩数据的方法，用于表示图像的分割掩码。在COCO数据集中，当目标物体的iscrowd字段为1时，分割掩码采用RLE格式。

RLE格式由两个数组组成：counts和size。counts数组记录了图像中每个像素点在目标区域中出现的连续次数，而size数组记录了图像的宽度和高度。

对于一个240x320的图片来说，共有76800个像素点。根据每个像素点是否在目标区域中，我们可以用0或1来表示。但是直接使用每个像素点对应的0或1会浪费空间，所以可以使用RLE编码来压缩表示。例如，counts数组中的值[272, 2, 4, 4, 4, 4, 2, 9, 1, 2, 16, 43, 143, 24] 表示有272个0、2个1、4个0、4个1、4个0、4个1、2个0、9个1等等。

通过使用RLE格式，不仅可以有效地计算目标区域的面积，还可以计算两个目标之间的union和intersection等操作。

最后一个python代码片段展示了如何将RLE数组转换回原始图像大小，并通过断言来验证转换是否正确。


我有一份带10点标签的coco数据集json文件

结构如下：
```
info:{...} 
licenses : [ ... ] 
images:[...] 
categories : [ ... ] 
annotations : [ ... ] 
	[0]:
		segmentation : [ ... ] 
			[0]:
				...
		area:
		iscrowd : 
		image_id:
		bbox : [ ... ] 
		category_id : 
		id :  
		point_coords:[...] 
			[0]: 
				[0]:370 
				[1]:345 
			...
			[9]
		point labels : [ ... ] 
			[0]:0 
			[1]:0 
			[2]:1 
			[3]:1 
			[4]:0 
		    ...
		    [9]
   ...
```

请给我生成一份coco可视化代码,要在图片中显示点标签和分割标签

这是文件相关路径

```python
json_file = './annotations/instances_train2017_n10_v1_without_masks_pro.json'
dataset_dir = './train2017/'
```

以下是使用Python中的`matplotlib`库和`COCO API`来可视化COCO数据集中带有点标签的图片的代码：

```python
import json
import matplotlib.pyplot as plt
from pycocotools.coco import COCO

# 载入JSON文件
json_file = './annotations/instances_train2017_n10_v1_without_masks.json'
dataset_dir = './train2017/'

with open(json_file, 'r') as f:
    coco_data = json.load(f)

# 初始化COCO对象
coco = COCO(json_file)

# 获取所有图片ID和标注ID
image_ids = coco.getImgIds()
annotation_ids = coco.getAnnIds()

# 循环遍历每张图片
for image_id in image_ids:
    # 加载图片信息
    image_info = coco.loadImgs(image_id)[0]
    file_name = dataset_dir + image_info['file_name']
    
    # 加载图片数据并显示
    image = plt.imread(file_name)
    plt.figure(figsize=(10, 10))
    plt.imshow(image)
    
    # 获取该图片对应的所有标注ID和标注信息
    annotation_ids = coco.getAnnIds(imgIds=image_id)
    annotations = coco.loadAnns(annotation_ids)
    
    # 循环遍历每个标注并显示点标签
    for annotation in annotations:
        point_coords = annotation['point_coords']
        point_labels = annotation['point_labels']
        
        for coord, label in zip(point_coords, point_labels):
            x, y = coord[0], coord[1]
            
            # 根据点标签设置不同颜色和形状的点
            if label == 0:
                color, marker = 'red', 'o'
            elif label == 1:
                color, marker = 'blue', 'x'
            else:
                color, marker = 'green', '+'
            
            plt.scatter(x, y, c=color, marker=marker)
            
    plt.axis('off')
    plt.show()
```

请确保已经安装了`matplotlib`和`pycocotools`库，可以使用以下命令来安装：

```python
pip install matplotlib pycocotools
```

此代码将循环遍历COCO数据集中的每张图片，并加载图片数据。然后，它将获取与该图片相关联的所有标注，并根据标注中的点标签显示不同颜色和形状的点。最后，使用`plt.imshow()`函数显示带有点标签的图片。

请注意，此代码假设您已经安装了COCO API并正确设置了JSON文件和图像文件夹的路径。

再显示下分割的标签，顺便问下这个蓝点和红点是什么？

要在图片中显示分割的标签，可以使用`matplotlib.patches`模块来绘制多边形。

以下是修改后的代码，在图片中显示点标签和分割标签：

```python
import json
import matplotlib.pyplot as plt
from matplotlib.patches import Polygon
from pycocotools.coco import COCO

# 载入JSON文件
json_file = './annotations/instances_train2017_n10_v1_without_masks.json'
dataset_dir = './train2017/'

with open(json_file, 'r') as f:
    coco_data = json.load(f)

# 初始化COCO对象
coco = COCO(json_file)

# 获取所有图片ID和标注ID
image_ids = coco.getImgIds()
annotation_ids = coco.getAnnIds()

# 循环遍历每张图片
for image_id in image_ids:
    # 加载图片信息
    image_info = coco.loadImgs(image_id)[0]
    file_name = dataset_dir + image_info['file_name']
    
    # 加载图片数据并显示
    image = plt.imread(file_name)
    plt.figure(figsize=(10, 10))
    plt.imshow(image)
    
    # 获取该图片对应的所有标注ID和标注信息
    annotation_ids = coco.getAnnIds(imgIds=image_id)
    annotations = coco.loadAnns(annotation_ids)
    
    # 循环遍历每个标注并显示点标签和分割标签
    for annotation in annotations:
        point_coords = annotation['point_coords']
        point_labels = annotation['point_labels']
        segmentations = annotation['segmentation']
        
        for coord, label, segmentation in zip(point_coords, point_labels, segmentations):
            x, y = coord[0], coord[1]
            
            # 根据点标签设置不同颜色和形状的点
            if label == 0:
                color, marker = 'red', 'o'
            elif label == 1:
                color, marker = 'blue', 'x'
            else:
                color, marker = 'green', '+'
            
            plt.scatter(x, y, c=color, marker=marker)
            
            # 绘制分割标签
            polygon = Polygon(segmentation, closed=True, fill=False, edgecolor=color)
            plt.gca().add_patch(polygon)
            
    plt.axis('off')
    plt.show()
```

蓝点和红点代表了不同的点标签，例如，蓝点可能表示目标的左眼，红点可能表示目标的右眼。这些颜色和形状只是示例，并可以根据需要进行修改。

分割标签是指通过多边形或轮廓来定义目标区域的边界。代码中使用`Polygon`对象来绘制分割标签，其中`segmentation`变量是一个多边形顶点的列表。

请确保已经安装了`matplotlib`和`pycocotools`库，并使用以下命令来安装：

```python
pip install matplotlib pycocotools
```

请注意，此代码假设您已经安装了COCO API并正确设置了JSON文件和图像文件夹的路径。











我有一份带标签的coco数据集json文件，地址为：'./mo/annotations/new_train.json'

结构如下：
```
info:{...} 
licenses : [ ... ] 
images:[...] 
	[0]: 
		file_name:"000001.jpg" 
		height:1000 
		width:1000 
		id:1 
categories : [ ... ] 
annotations : [ ... ] 
	[0]:
		segmentation : [ ... ] 
			[0]:
				...
		area:
		iscrowd : 
		image_id:
		bbox : [ ... ] 
		category_id : 
		id :  
		point_coords:[...] 
			[0]: 
				[0]:370 
				[1]:345 
			...
			[9]
		point labels : [ ... ] 
			[0]:0 
			[1]:0 
			[2]:1 
			[3]:1 
			[4]:0 
		    ...
		    [9]
   ...
```

划分一个10p,就是随机打乱，按处理图片数量的10%的组成一个json，剩下90%组成一个json文件,生成的文件分别是new_train_10p.json和new_train_10w.json

你可以按照以下步骤来划分你的数据集：

。


这是训练深度学习是终端输出的信息解释一下
```
[07/17 23:11:34 d2.utils.events]: eta: 2 days, 6:44:12  iter:19  total_loss:3.346 loss_ins:2.86 loss_cate:0.4982 time: 4.6463 las_time:5.4223 data_ime:0.2750 last_data_time:0.2564 lr:0.0008135 maxmem:12584M 
```

这段信息是深度学习训练过程中的一次迭代的输出。下面是对其中每个字段的解释：

- `[07/17 23:11:34 d2.utils.events]`：表示输出信息的时间和来源。
- `eta: 2 days, 6:44:12`：表示预计还需要多长时间才能完成整个训练过程。
- `iter:19`：表示当前进行到第19次迭代。
- `total_loss:3.346`：表示总体损失值，用于衡量模型预测与实际标签之间的差异。
- `loss_ins:2.86`：表示实例分割任务中的损失值，用于衡量模型对像素级别的目标检测准确性。
- `loss_cate:0.4982`：表示分类任务中的损失值，用于衡量模型对类别预测准确性。
- `time: 4.6463`：表示此次迭代所花费的时间。
- `las_time:5.4223`：表示上一次迭代所花费的时间。
- `data_ime:0.2750`：表示数据加载所花费的时间。
- `last_data_time:0.2564`：表示上一次数据加载所花费的时间。
- `lr:0.0008135`：表示当前学习率（learning rate）的数值。学习率控制了模型在每次迭代中参数更新的速度。
- `maxmem:12584M`：表示模型训练过程中最大的内存使用量。











测试1
```
Command Line Args: Namespace(config_file='configs/PointWSSIS/R101_teacher.yaml', dist_url='tcp://127.0.0.1:50358', eval_only=False, machine_rank=0, num_gpus=2, num_machines=1, opts=['SEED', '1', 'OUTPUT_DIR', 'training_dir/SOLOv2_R101_coco10p_teacher', 'DATASETS.TRAIN', "('coco_2017_train_10p_s',)", 'DATASETS.TEST', "('coco_2017_val',)", 'SOLVER.STEPS', '(35000,40000)', 'SOLVER.MAX_ITER', '45001', 'SOLVER.BASE_LR', '0.005', 'MODEL.SOLOV2.PROMPT', 'point', 'MODEL.SOLOV2.EVAL_PSEUDO_LABEL', 'True', 'TEST.EVAL_PERIOD', '500'], resume=False)

```



当spring容器启动的时候，发现有@EnableTransactionManagement注解，此时会拦截所有bean的创建，然后会扫描一下bean上是否有@Transaction注解（类、接口、或者方法上有这个注解都可以），如果有这个注解，spring会通过aop的方式给这个bean生成代理对象（代理对象中存在本类对象），代理对象中会增加一个拦截器，拦截器会拦截bean中public方法的执行，会在方法执行前启动事务，方法执行完毕之后提交或者回滚事务。

```text
[GitHub - HUANGLIZI/LViT: This repo is the official implementation of "LViT: Language meets Vision Transformer in Medical Image Segmentation" (IEEE Transactions on Medical Imaging/TMI)](https://github.com/huanglizi/lvit)
[GitHub - McGregorWwww/UCTransNet: Implementation of our AAAI'22 work: 'UCTransNet: Rethinking the Skip Connections in U-Net from a Channel-wise Perspective with Transformer'.](https://github.com/McGregorWwww/UCTransNet)
[GitHub - wuyongjianCODE/Cyclic: This repo provides the official code for : Cyclic Learning: Bridging Image-level Labels and Nuclei Instance Segmentation](https://github.com/wuyongjiancode/cyclic)
[GitHub - honglianghe/CDNet: ICCV2021-CDNet: Centripetal Direction Network for Nuclear Instance Segmentation](https://github.com/honglianghe/cdnet)
[GitHub - hust-linyi/insmix](https://github.com/hust-linyi/insmix)
```



|Method Name|Dice(%)|AJI(%)|IoU (%)|
|:-:|:-:|:-:|:-:|
|CDNet |83.16|63.31|  |
|UCTransNet|79.08±0.67 |  |65.50±0.91|
|LViT-T|80.36|  |67.31|

