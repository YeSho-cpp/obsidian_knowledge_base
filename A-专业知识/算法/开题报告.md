# 开题报告

题目：**图-文跨模态学习的细胞核实例分割算法研究**
# 课题来源及研究的目的和意义

## 研究背景与意义

1. 首先介绍癌症疾病、人类健康安全的背景，然后叙述一下现代人工智能、医学图像、计算病理学的结合和发展，引出细胞核分割这个技术
2. 介绍细胞核分割的技术原理、意义；并对比传统的核分割的操作，说明现在与人工智能结合的细胞核分割技术的优势
3. 介绍细胞核的实例分割的技术，说明语义分割和细胞实例的区别，并开始介绍核实例分割遇到的挑战和难点(比如边缘重叠、聚集、标签不足)
4. 开始介绍一些对比学习和视觉预训练的概念，浅谈一下这些视觉预训练的意义(可以减少人工标注成本以及提供额外信息监督细胞分割等等)
# 国内外研究现状

## 细胞实例分割算法研究现状

1. 介绍现在细胞实例分割的方法面临的问题和挑战(就是什么原因造成分割的性能、效果、精度、泛化等等不好)
2. 开始从最早的细胞核实例分割算法开始介绍，介绍他们提出了什么方法和网络，解决了什么问题
3. 总结大部分方法是在xxx地方改进，忽略了一些问题，浅谈一下我们打算从哪里入手去填补这些空白

## 图文跨模态学习研究现状
1. 介绍图文跨模态(多模态)学习这个热点，应用到n个方向领域，对这些领域的任务提供了帮助，很受关注，引出跨模态中比较火的CLIP
2. 开始介绍一系列CLIP的相关研究，也是他们提出了什么方法和网络，怎么应用CLIP到自己的领域任务，改善了什么
3. 介绍目前在细胞核实例分割任务还没有应用CLIP的方法，本课题打算应用进去，解决以往细胞核实例分割的挑战和难点

# 课题研究目标、内容及拟解决的关键问题

## 研究目标

1. 说明本课题打算在细胞核分割这个任务的哪些出发和困难点(全监督的人工标注成本耗时、贵或者细胞重叠聚集的实例难以分割)上研究，在这些点上现有的方法都做的不是很好，所以本课题的目标是减少标注的成本，增强网络区分不同重叠实例的能力
2. 本课题将利用CLIP模型在预训练期间学习的图像和文本之间的跨模态对齐，用CLIP强大的语言视觉预训练来帮助解释细胞核分割的全监督的人工标注以及帮助分离重叠的实例

## 研究内容

1. 在CLIP结合下游任务的应用上有很多的研究方法,说明在下游的分割任务上，一些现在方法，它们所处理是简单的一个图片一个物体，所应对是简单分类的自然图像数据，对于全图多种类复杂的图像数据或者医学图像，这些方法都不行。说明本课题所做的是最大化利用合适语言文本去剖析细胞核图像的特征信息，在CLIP的视觉预训练下将这部分信息作为一种代替的人工标注或者对齐融合到图像的分割网络中提高细胞核实例分割的性能。
2. 列举出研究内容之前的关系(这部分画好图)
3. 对主要研究内容划分
	1. 细胞核分割算法的低性能、低感知结构能力、弱轮廓边界检测能力分析
	2. 细胞核图像文本信息特征的研究(主要是选择什么类型的文本信息(如细胞核数量、细胞类别))
	3. 细胞核图像、文本的跨模态特征对齐研究(主要研究用什么方式适合，比如zero-shot、One-shot、few-shot)
## 拟解决的关键问题

1. 如何选择合适的文本信息与图像进行配对？
2. 细胞核图像的缺少的配对标签信息怎么解决和处理
3. 如何对不同网络的文本编码和图像编码进行对齐
# 课题研究方案、实验方案、技术路线及可行性分析

## 研究方案

1. 一个网络图
2. 简短叙述一下整个网络处理的流程(从xxx开始，从xxx提取特征，从xxx开始对齐，从xxx开始算loss)
3. 画个整个研究方案的流程图

### 文献阅读阶段

研究准备阶段(xxxx 年 x 月至 xxxx 年 x 月)
....
### 理论研究阶段

研究中期阶段(xxxx 年 x 月至 xxxx 年 x 月)

1. 细胞核分割算法的低性能、低感知结构能力、弱轮廓边界检测能力分析
	- 研究方案
		- 画出研究流程图
		- 说一下流程
	- 实验方案
	- 介绍实验环境、设备信息、数据集、实验思路设计

2. 细胞核图像文本信息特征的研究
	- 研究方案
		- 画出研究流程图
		- 说一下流程
	- 实验方案
	- 介绍实验环境、设备信息、数据集、实验思路设计

3. 细胞核图像、文本的跨模态特征对齐研究
	- 研究方案
		- 画出研究流程图
		- 说一下流程
	- 实验方案
	- 介绍实验环境、设备信息、数据集、实验思路设计
### 实验验证阶段

研究后期阶段(xxxx 年 x 月至 xxxx 年 x 月)
## 可行性分析
xxxx
# 预期结果与创新点

## 预期结果及形式

- 预期成果
xxx

- 成果展示
xxx
## 创新点
这里做总结
1. 本课题是第一个创新的把CLIP视觉语言预训练应用进入了细胞核实例分割任务
2. 提出一种网络，实现了细胞核图像和文本之间的跨模态对齐
3. 提出融合这两个模态特征的算法，解决了人工标注成本以及细胞核重叠的问题
# 研究工作计划及进度安排

研究进度表
# 参考文献


医学成像被视为一种重要的技术，可帮助医生评估疾病并优化预防和控制措施。医学图像中目标物体的分割和随后的定量评估为病理分析提供了有价值的信息，并且对于治疗策略的规划、疾病进展的监测和患者预后的预测很重要[[开题报告#^1|1]]。

病理图像分析被视为癌症诊断、治疗和预防的黄金标准，其中细胞核实例分割是核心步骤。之所以如此，是因为细胞核的形态学特征（包括形状、外观和在病理图像中的分布）提供了可解释的特征，这些特征是诊断和预后癌症指标的关键因素。[[开题报告#^2|2]]

与常规图像对象分割相比，细胞核实例分割面临着一些特殊挑战：(i) 密集的细胞核分布导致重叠实例的聚集。 (ii) 相互接触或重叠的细胞核之间模糊不清的边界增加了区分单个实例的难度。 (iii) 不同图像中细胞核在大小、形状、纹理和强度方面的巨大变异性要求更加健壮的标注和预测。[[开题报告#^3|3]]


近年来，预训练通用语言表示取得了巨大成功[4, 2, 35, 33, 5]。ELMo [33] 被提出用来提取上下文敏感特征。BERT [5] 采用了遮蔽语言模型来学习深度双向表示。CLIP [34] 提出了从图像-文本对中学习表示的方法。实验结果表明，CLIP在零/少样本转移上效率更高，这证明了语言的强大能力。受到CLIP卓越表现的鼓舞，许多基于CLIP的方法被提出。Patashnik等人[31] 提出了StyleCLIP，它利用CLIP模型的力量开发了一个基于文本的StyleGAN接口。Wang等人[45] 介绍了用于视频动作识别的ActionCLIP。ActionCLIP遵循“预训练、提示和微调”的范式，在动作识别任务上取得了强大的性能。Gao等人[9] 提出了CLIP-Adapter，用于在下游任务上使用CLIP模型。Zhang等人[48] 进一步提出了Tip-Adapter，以增强CLIP的少样本能力，无需训练。Wav2CLIP [47] 被提出来通过从CLIP模型中提炼来学习鲁棒的音频表示。在本文中，我们利用了来自CLIP模型的语言先验。为了更好地利用CLIP中的语言先验，我们进一步提出了可微分的等级提示来模拟数字的连续属性。最相关的工作是[50]和[49]。Zhou等人[50] 提出了一种名为上下文优化的新方法。这种方法学习提示的上下文，取得了显著的性能提升。Zhou [49] 还提出了[50]的改进版本，通过将视觉特征融入文本特征，提高了模型的泛化能力。需要注意的是，[50] 只优化了上下文嵌入。因此，将其直接应用于顺序回归会由于缺乏顺序属性而导致性能下降。我们没有与[49]进行比较，因为我们想单独研究作为语言原型引入的语言先验如何帮助顺序回归任务。

[4] Dai A M, Le Q V. Semi-supervised sequence learning[J]. Advances in neural information processing systems, 2015, 28.
[2] Brown T, Mann B, Ryder N, et al. Language models are few-shot learners[J]. Advances in neural information processing systems, 2020, 33: 1877-1901.
[35] Radford A, Narasimhan K, Salimans T, et al. Improving language understanding with unsupervised learning[J]. 2018.
[33] Peters M E, Neumann M, Iyyer M, et al. Deep contextualized word representations. NAACL-HLT[J]. arXiv, 2018.
[34] Radford, A., Kim, J.W., Hallacy, C., Ramesh, A., Goh, G., Agarwal, S., Sastry, G., Askell, A., Mishkin, P., Clark, J., Krueger, G., Sutskever, I.: Learning transferable visual models from natural language supervision. In: ICML (2021)
[31] Patashnik O, Wu Z, Shechtman E, et al. Styleclip: Text-driven manipulation of stylegan imagery[C]//Proceedings of the IEEE/CVF International Conference on Computer Vision. 2021: 2085-2094.
[45] Wang M, Xing J, Liu Y. Actionclip: A new paradigm for video action recognition[J]. arXiv preprint arXiv:2109.08472, 2021.
[9] Gao P, Geng S, Zhang R, et al. Clip-adapter: Better vision-language models with feature adapters[J]. International Journal of Computer Vision, 2023: 1-15.
[48] Zhang R, Fang R, Zhang W, et al. Tip-adapter: Training-free clip-adapter for better vision-language modeling[J]. arXiv preprint arXiv:2111.03930, 2021.
[47] Wu H H, Seetharaman P, Kumar K, et al. Wav2clip: Learning robust audio representations from clip[C]//ICASSP 2022-2022 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP). IEEE, 2022: 4563-4567.
[50] Zhou K, Yang J, Loy C C, et al. Learning to prompt for vision-language models[J]. International Journal of Computer Vision, 2022, 130(9): 2337-2348.
[49] Zhou K, Yang J, Loy C C, et al. Conditional prompt learning for vision-language models[C]//Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition. 2022: 16816-16825.

近期，对比性语言-图像预训练（Contrastive Language-Image Pre-Training, 简称CLIP）作为一种新型范式，由于其卓越的转移能力而受到日益增长的关注。CLIP通过利用大规模、带有噪声的图像-文本对来学习视觉表征，已经在多种下游视觉任务中表现出色，例如物体检测[38]、语义分割[56]和图像生成[10]。然而，如何将这种以语言为驱动的模型应用于人群计数领域，目前还未有深入的探讨。显然，由于在CLIP对比性预训练过程中不存在计数监督，因此无法直接将CLIP应用于计数任务。

[38] Shi H, Hayat M, Wu Y, et al. Proposalclip: Unsupervised open-category object proposal generation via exploiting clip cues[C]//Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition. 2022: 9611-9620.
[56] Xu M, Zhang Z, Wei F, et al. A simple baseline for open-vocabulary semantic segmentation with pre-trained vision-language model[C]//European Conference on Computer Vision. Cham: Springer Nature Switzerland, 2022: 736-753.
[10] Hong F, Zhang M, Pan L, et al. Avatarclip: Zero-shot text-driven generation and animation of 3d avatars[J]. arXiv preprint arXiv:2205.08535, 2022.






为了应对这些挑战，多项研究集中于探索创新的网络架构[4，5，6]并结合距离图[7，8，9，10]来增强分割性能。然而，现有工作通常依赖于像素级损失函数，如交叉熵/骰子损失，这种方法强制预测与真实像素逐个对齐，但忽略了实例的关键结构信息。由于这种方法独立处理每个像素，它们对高级结构特征（如边界的连通性）的敏感性不足，这些特征对于合理分割单个实例至关重要。像素级损失的这种局限性通常会导致不合理的结果，如断裂边界，从而无法区分接触或重叠的实例。这进一步对后续的定量形态学分析产生不良影响。如图1（右上角）所示，像素级损失关注错位像素，从而减少像素误差。然而，由于缺乏对结构信息的感知，像素比例较小的重叠实例之间的边界没有得到足够的考虑，导致了错误的实例预测。


深度学习已被广泛应用于细胞核实例分割[11, 8, 12, 13]。在2015年，Ronneberger等人[14]提出了U-Net模型，它已成为医学图像分割中最基本的模型之一。Raza等人[13]提出了Micro-Net，该模型通过利用多分辨率和加权损失函数，实现了对核大小内部/外部巨大变异的鲁棒性。Qu等人[15]提出了一种全分辨率卷积神经网络（FullNet），在网络结构中不采用降采样操作，以提高定位精度。He等人[4]提出了一种混合注意力嵌套U型网络（Han-Net），用于从多个层次提取有效的特征信息。

为了利用轮廓信息区分接触/重叠的细胞核，Chen等人[11]最初提出将轮廓信息融入多层次的全卷积网络（FCN），创建了一种深度轮廓感知网络，用于细胞核实例分割。随后，Zhou等人[16]提出了轮廓感知信息聚合网络，结合细胞核和轮廓之间的空间和纹理特征。此外，一些研究[7, 8, 9, 10]引入了距离图来分离接触/重叠的细胞核。Naylor等人[10]通过将分割任务构建为细胞核内部距离图的回归任务，解决了分割接触细胞核的问题。Graham等人[8]提出了一个同时进行细胞核分割和分类的网络（Hover-Net），该网络使用细胞核像素与其质心之间的垂直和水平距离来分离细胞核簇。此外，He等人[12]提出了一个向心方向网络（CDNet），用于细胞核实例分割，将方向信息融入网络。






Wang H, Cao P, Wang J, et al. Uctransnet: rethinking the skip connections in u-net from a channel-wise perspective with transformer[C]//Proceedings of the AAAI conference on artificial intelligence. 2022, 36(3): 2441-2449. ^1

Pinckaers H, Bulten W, van der Laak J, et al. Detection of prostate cancer in whole-slide images through end-to-end training with image-level labels[J]. IEEE Transactions on Medical Imaging, 2021, 40(7): 1817-1826. ^2


Liu D, Zhang D, Song Y, et al. Panoptic feature fusion net: a novel instance segmentation paradigm for biomedical and biological images[J]. IEEE Transactions on Image Processing, 2021, 30: 2045-2059. ^3

[4] He H, Zhang C, Chen J, et al. A hybrid-attention nested UNet for nuclear segmentation in histopathological images[J]. Frontiers in Molecular Biosciences, 2021, 8: 614174.

[5] Qu H, Yan Z, Riedlinger G M, et al. Improving nuclei/gland instance segmentation in histopathology images by full resolution neural network and spatial constrained loss[C]//Medical Image Computing and Computer Assisted Intervention–MICCAI 2019: 22nd International Conference, Shenzhen, China, October 13–17, 2019, Proceedings, Part I 22. Springer International Publishing, 2019: 378-386.

[6] Ronneberger O, Fischer P, Brox T. U-net: Convolutional networks for biomedical image segmentation[C]//Medical Image Computing and Computer-Assisted Intervention–MICCAI 2015: 18th International Conference, Munich, Germany, October 5-9, 2015, Proceedings, Part III 18. Springer International Publishing, 2015: 234-241.

[7] Chen S, Ding C, Liu M, et al. CPP-net: Context-aware polygon proposal network for nucleus segmentation[J]. IEEE Transactions on Image Processing, 2023, 32: 980-994.

[8] Graham S, Vu Q D, Raza S E A, et al. Hover-net: Simultaneous segmentation and classification of nuclei in multi-tissue histology images[J]. Medical image analysis, 2019, 58: 101563.

[9] Liu X, Guo Z, Cao J, et al. MDC-net: A new convolutional neural network for nucleus segmentation in histopathology images with distance maps and contour information[J]. Computers in Biology and Medicine, 2021, 135: 104543.

[10] Naylor P, Laé M, Reyal F, et al. Segmentation of nuclei in histopathology images by deep regression of the distance map[J]. IEEE transactions on medical imaging, 2018, 38(2): 448-459.

[11] Chen H, Qi X, Yu L, et al. DCAN: Deep contour-aware networks for object instance segmentation from histology images[J]. Medical image analysis, 2017, 36: 135-146.

[12] He H, Huang Z, Ding Y, et al. Cdnet: Centripetal direction network for nuclear instance segmentation[C]//Proceedings of the IEEE/CVF International Conference on Computer Vision. 2021: 4026-4035.

[13] Raza S E A, Cheung L, Shaban M, et al. Micro-Net: A unified model for segmentation of various objects in microscopy images[J]. Medical image analysis, 2019, 52: 160-173.

[14] Ronneberger O, Fischer P, Brox T. U-net: Convolutional networks for biomedical image segmentation[C]//Medical Image Computing and Computer-Assisted Intervention–MICCAI 2015: 18th International Conference, Munich, Germany, October 5-9, 2015, Proceedings, Part III 18. Springer International Publishing, 2015: 234-241.

[15] Qu H , Yan Z , Riedlinger G M ,et al.Improving Nuclei/Gland Instance Segmentation in Histopathology Images by Full Resolution Neural Network and Spatial Constrained Loss[C]//2019.DOI:10.1007/978-3-030-32239-7_42.

[16] Zhou Y , Onder O F , Dou Q ,et al.CIA-Net: Robust Nuclei Instance Segmentation with Contour-aware Information Aggregation[J].Springer, Cham, 2019.DOI:10.1007/978-3-030-20351-1_53.








计算病理学在精确的细胞估计及诊断中扮演着重要角色。特别是，通过提取丰富且可解释的基于细胞的特征，细胞核分割和分类正成为计算病理学中下游可解释模型的重要资产。研究人员已经研究了数十年用于结肠细胞核在苏木精-伊红染色组织学图像中的自动分割和分类方法。近年来，卷积神经网络（CNN）的出现在这一领域引起了革命性的变化，带来了最先进的分割和分类结果。尽管已经报告了令人充满希望的结果，但由于不同类型细胞之间的形状差异巨大，这项任务仍然充满挑战。传统方法基于手工制作的特征进行细胞分割，例如[1, 2]。然而，由于缺乏高度语义信息，即对图像的全局理解，传统方法在性能上仍然有限。

与语义模型不同，实例技术通常使用两阶段架构来检测和分割每个实例。一种成熟的技术是Faster RCNN[3]。它由一个区域提议阶段和一个边界框回归阶段组成，对检测任务非常有效。Mask-RCNN[4]在Faster R-CNN的基础上增加了一个掩码预测分支，与边界框识别分支并行，以同时进行实例检测和分割。Cascade Mask R-CNN[5]比之前的模型实现了更好的分割和分类性能，它在Mask-RCNN的基础上增加了一系列检测器，这些检测器通过逐步提高IoU阈值来训练。


细胞学图像在癌症筛查和早期诊断中具有至关重要的作用。这包括了对细胞形态的定性和定量鉴别，如细胞核的大小、核质比以及其他细胞学特征的识别[6, 7, 8]。然而，通过显微镜人工观察数以万计的细胞不仅极为繁琐，而且还存在观察者之间和个体内部的变异性。计算技术为从细胞学图像中有效且精准地分析细胞特征提供了可能[6, 9]。在所有计算技术中，细胞分割是一项基本且被广泛研究的任务，因为获得细胞级别的识别信息是后续评估和分析的基础[10, 11]

深度学习（DL）方法在组织病理学图像中的细胞核分割方面显示出了有希望的结果[12,13]。然而，细胞学图像的分割仍然面临着两大挑战。首先，细胞学图像中的细胞容易相互聚集，导致重叠问题。在这些图像中，细胞的半透明细胞质（如图1所示）往往由于低对比度染色相互遮挡，导致细胞边界的预测模糊不清。这一现象在宫颈细胞图像中尤为明显。其次，背景中广泛存在的难以模拟的物质，以及泡沫等技术性伪影，可能误导实例分割模型。以宫颈细胞图像为例，广泛分布的白细胞和粘液染色导致了对核的错误预测。为了应对这些挑战，一些工作[14, 15]提出了先分割再细化的范式，而其他工作[16]则利用基于检测的框架，例如 Mask R-CNN[4]。然而，它们未能明确地模拟半透明细胞团中交叉和互补子区域之间的相互作用，从而导致了对跨区域关系理解的局限。

如今，数字病理学在精确细胞估计和癌症预后中发挥着至关重要的作用[18]。特别是，细胞核实例分割不仅捕捉了位置和密度信息，还包含了丰富的形态特征，如大小和细胞质比，这在肿瘤诊断和随后的治疗程序中至关重要[23]。然而，由于几个原因，自动地在实例层面分割细胞核仍然是一个挑战。首先，大量细胞核的遮挡和聚集可能导致过度分割或欠分割，从而妨碍对细胞核实例形态的准确测量。其次，模糊的边界和不一致的染色使得图像中不可避免地包含了难以区分的实例，因此引入了主观的注释和错误标记，这对于获得稳健和客观的结果是一个挑战[8]。第三，不同细胞类型和器官之间细胞外观、大小和密度的变异性要求方法具有良好的泛化能力，以便进行稳健的分析。


[1] Cheng J, Rajapakse J C. Segmentation of clustered nuclei with shape markers and marking function[J]. IEEE transactions on Biomedical Engineering, 2008, 56(3): 741-748.

[2] Jung C, Kim C. Segmenting clustered nuclei using H-minima transform-based marker extraction and contour parameterization[J]. IEEE transactions on biomedical engineering, 2010, 57(10): 2600-2604.

[3] Ren S, He K, Girshick R, et al. Faster r-cnn: Towards real-time object detection with region proposal networks[J]. Advances in neural information processing systems, 2015, 28.

[4] He K, Gkioxari G, Dollár P, et al. Mask r-cnn[C]//Proceedings of the IEEE international conference on computer vision. 2017: 2961-2969.

[5] Cai Z, Vasconcelos N. Cascade r-cnn: Delving into high quality object detection[C]//Proceedings of the IEEE conference on computer vision and pattern recognition. 2018: 6154-6162.

[6] Hoda R S, Hoda S A. Fundamentals of Pap test cytology[M]. Springer Science & Business Media, 2007.

[7] Jiang H, Li S, Liu W, et al. Geometry-aware cell detection with deep learning[J]. Msystems, 2020, 5(1): 10.1128/msystems. 00840-19.

[8] Nayar R , Wilbur D C , Solomon D .The Bethesda System for Reporting Cervical Cytology[M].Springer-Verlag, 2008.

[9] Jiang H, Zhou Y, Lin Y, et al. Deep learning for computational cytology: A survey[J]. Medical Image Analysis, 2023, 84: 102691.

[10] Chai Z, Luo L, Lin H, et al. Deep semi-supervised metric learning with dual alignment for cervical cancer cell detection[C]//2022 IEEE 19th International Symposium on Biomedical Imaging (ISBI). IEEE, 2022: 1-5.

[11] Lin H, Chen H, Wang X, et al. Dual-path network with synergistic grouping loss and evidence driven risk stratification for whole slide cervical image analysis[J]. Medical Image Analysis, 2021, 69: 101955.

[12] Chen H, Qi X, Yu L, et al. DCAN: Deep contour-aware networks for object instance segmentation from histology images[J]. Medical image analysis, 2017, 36: 135-146.

[13] Hussain E, Mahanta L B, Das C R, et al. A shape context fully convolutional neural network for segmentation and classification of cervical nuclei in Pap smear images[J]. Artificial Intelligence in Medicine, 2020, 107: 101897.

[14] Lu Z, Carneiro G, Bradley A P. An improved joint optimization of multiple level set functions for the segmentation of overlapping cervical cells[J]. IEEE Transactions on Image Processing, 2015, 24(4): 1261-1272.

[15] Ushizima D M , Bianchi A C , Carneiro C .Segmentation of subcellular compartments combining superpixel representation with Voronoi diagrams[C]//International Symposium on Biomedical Imaging.2014.

[16] Zhou Y, Chen H, Lin H, et al. Deep semi-supervised knowledge distillation for overlapping cervical cell instance segmentation[C]//Medical Image Computing and Computer Assisted Intervention–MICCAI 2020: 23rd International Conference, Lima, Peru, October 4–8, 2020, Proceedings, Part I 23. Springer International Publishing, 2020: 521-531.

[17] Pantanowitz L. Digital images and the future of digital pathology[J]. Journal of pathology informatics, 2010, 1.










