# 缓存重建业务较复杂的key 

缓存重建：我们的缓存在redis中存着，到了一定时间会被清除，失效后我们需要**重新从数据库里查询写入**redis

> [!summary]+
> 1. 从数据库里查询并且构建这个数据并不一定是查到什么就往redis里存什么
> 2. 一些比较复杂的业务，我们需要从**多个数据库**的表中进行查询
> 3. 甚至于要去做各种各样的**表关联的运算**，最终得到这个结果才缓存起来
> 4. 这样的一个业务**耗时是比较长的**


# double check


> [!summary]+
> 1. 在多线程编程中，`double check`是一种常见的优化技术，用于在保证线程安全的同时提高性能。
> 2. 具体实现时，当一个线程尝试获取互斥锁时，如果互斥锁未被其他线程占用，则该线程获取到了互斥锁，并进入临界区（即对共享资源进行操作）。此时其他线程尝试获取互斥锁时会失败，并进入等待状态。
> 3. 但是，在某些情况下，在第一个检查之后，可能有**其他线程已经修改了共享资源的状态**。为了解决这个问题，需要在获取到互斥锁之后**再次进行检查**（即第二次检查），以确保共享资源的状态没有发生变化。如果发现共享资源的状态已经改变，则当前线程放弃对临界区的访问，并释放互斥锁。这样可以避免对于已经失效或者无效的数据进行操作。
> 4. 通过使用double check技术，可以在保证线程安全的前提下，尽可能地减少对互斥锁的使用，从而提高并发性能。



# 锁的粒度

> [!summary]+
> 1. 锁的粒度指的是在并发编程中，锁定**共享资源的范围大小**。它表示了在对共享资源进行保护时，锁定的粒度有多细或多粗。
> 2. 较细粒度的锁意味着只锁定共享资源的一小部分，从而允许多个线程同时访问其他部分的共享资源。这可以提高并发性能，因为不同的线程可以同时操作不同的数据。然而，在细粒度锁的情况下，可能会引入更多的锁竞争和上下文切换开销。
> 3. 相反，较粗粒度的锁涉及锁定更大范围的共享资源，从而限制了多个线程之间的并发性。虽然较粗粒度的锁不容易产生锁竞争和上下文切换开销，但它可能导致并发性能下降，因为需要等待其他线程完成对整个资源的操作才能进行自己的操作。
> 4. 选择适当的锁粒度取决于应用程序的需求和场景。对于高并发的场景，通常使用较细粒度的锁以获得更好的并发性能。但是，在某些情况下，较粗粒度的锁可能更加简单且有效。
> 5. 在设计并发程序时，需要仔细考虑锁的粒度，并进行测试和性能调优来确定最适合的锁策略。


# 消息队列

## 一 什么是消息队列

我们可以把消息队列比作是一个存放消息的容器，提供了从一个进程向另外一个进程，**发送一块数据**的方法,每个数据块都被认为是有一个类型,接收者进程 接收的数据块可以有不同的类型值,当我们需要使用消息的时候可以取出消息供自己使用。消息队列是分布式系统中重要的组件，使用消息队列主要是为了通过异步处理提高系统性能和削峰、降低系统耦合性。目前使用较多的消息队列有ActiveMQ，RabbitMQ，Kafka，RocketMQ，我们后面会一一对比这些消息队列。

另外，我们知道队列 Queue 是一种先进先出的数据结构，所以消费消息时也是按照顺序来消费的。比如生产者发送消息1,2,3...对于消费者就会按照1,2,3...的顺序来消费。但是偶尔也会出现消息被消费的顺序不对的情况，比如某个消息消费失败又或者一个 queue 多个consumer 也会导致消息被消费的顺序不对，我们一定要保证消息被消费的顺序正确。

除了上面说的消息消费顺序的问题，使用消息队列，我们还要考虑如何保证消息不被重复消费？如何保证消息的可靠性传输（如何处理消息丢失的问题）？......等等问题。所以说使用消息队列也不是十全十美的，使用它也会让系统可用性降低、复杂度提高，另外需要我们保障一致性等问题。


# fork函数详解

## 首先了解什么是fork?

> 一个进程，包括代码、数据和分配给进程的资源。fork（）函数通过系统调用**创建一个与原来进程几乎完全相同的进程**，也就是两个进程可以做完全相同的事，但如果初始参数或者传入的变量不同，两个进程也可以做不同的事。
> 一个进程调用fork（）函数后，系统先给新的进程分配资源，例如存储数据和代码的空间。然后**把原来的进程的所有值都复制到新的新进程中**，只有少数值与原来的进程的值不同。

上面的话通俗理解就是: fork是**复制进程的函数**，程序一开始就会产生一个进程，当这个进程(代码)执行到fork()时，fork就会复制一份原来的进程即就是创建一个新进程,我们称**子进程**，而原来的进程我们称为**父进程**，此时父子进程是共存的，他们一起向下执行代码。
注意的一点：就是调用fork函数之后，一定是两个进程同时执行fork函数之后的代码，而之前的代码以及由父进程执行完毕。

## fork的特点:

首先明白linux中:

**PID**表示的进程号,是唯一的，一个PID只标识一个进程
**PCB**:进程控制块,进程控制块是用一个结构体`struct task_struct`来实现

<img src="https://img-blog.csdnimg.cn/31b49ff7cb964a5b940d5408fe15be37.png" alt="image.png" style="zoom:50%;" />
> fork的返回值问题:
> 在父进程中，fork返回新创建子进程的进程ID；
> 在子进程中，fork返回0；
> 如果出现错误，fork返回一个负值；  
> `getppid()`:得到一个进程的父进程的PID;
> `getpid()`:得到当前进程的PID;
> `*`注意:在fork函数执行完毕后，如果创建新进程成功，则出现两个进程，一个是子进程，一个是父进程。在子进程中，fork函数返回0，在父进程中，fork返回新创建子进程的进程ID。我们可以通过fork返回的值来判断当前进程是子进程还是父进程。

fork是把已有的进程复制一份,当然把PCB也复制了一份,然后申请一个PID
子进程的PID=父进程的PID+1;

<img src="https://img-blog.csdnimg.cn/bf2ba936cfb649ab8c5e0606fabd3af1.png" alt="image.png" style="zoom:50%;" />

<img src="https://www.subingwen.cn/linux/process/image-20210203181255536.png" alt="image.png" style="zoom:40%;" />

- 相同点：

`拷贝完成之后（注意这个时间点），两个地址空间中的用户区数据是相同的`。用户区数据主要数据包括：

- 代码区：默认情况下父子进程地址空间中的源代码始终相同。
- 全局数据区：父进程中的全局变量和变量值全部被拷贝一份放到了子进程地址空间中
- 堆区：父进程中的堆区变量和变量值全部被拷贝一份放到了子进程地址空间中
- 动态库加载区（内存映射区）：父进程中数据信息被拷贝一份放到了子进程地址空间中
- 栈区：父进程中的栈区变量和变量值全部被拷贝一份放到了子进程地址空间中
- 环境变量：默认情况下，父子进程地址空间中的环境变量始终相同。
- 文件描述符表: `父进程中被分配的文件描述符都会拷贝到子进程中，在子进程中可以使用它们打开对应的文件`。
- 区别：
	- 父子进程各自的虚拟地址空间是相互独立的，不会互相干扰和影响。
	- 父子进程地址空间中代码区代码虽然相同，但是父子进程执行的代码逻辑可能是不同的。
	- 由于父子进程可能执行不同的代码逻辑，因此地址空间拷贝完成之后，`全局数据区, 栈区, 堆区, 动态库加载区(内存映射区)`数据会各自发生变化，由于地址空间是相互独立的，因此不会互相覆盖数据。
	- 由于每个进都有自己的进程ID，因此内核区存储的父子进程ID是不同的。
	- 进程启动之后进入就绪态，运行需要争抢CPU时间片而且可能执行不同的业务逻辑，所以父子进程的状态可能是不同的。
- `fork() `<font color=#ff0000>调用成功之后，会返回两个值，父子进程的返回值是不同的</font>。
	- `该函数调用成功之后，从一个虚拟地址空间变成了两个虚拟地址空间，每个地址空间中都会将 fork() 的返回值记录下来`，这就是为什么会得到两个返回值的原因。
	- 父进程的虚拟地址空间中将该返回值标记为一个大于0的数（其实记录的是子进程的进程ID）
	- 子进程的虚拟地址空间中将该返回值标记 0
	- <font color=#ff0000>在程序中需要通过 fork() 的返回值来判断当前进程是子进程还是父进程</font>。


**下面我们举一个简单的例子:**

第一次看的时候非常的奇怪，一个函数返回两次？是的，在调用fork后，fork函数后面的所有代码会执行两遍。

```c++
#include <stdio.h>
#include <stdlib.h>
#include <unistd.h>
/**
 *最基础的fork例子
 **/
int main(int argc, char const *argv[])
{
    pid_t pid;
    //判断1
    if ((pid=fork()) < 0)
    {
        perror("fork error");
    }
    //判断2
    else if (pid == 0)//子进程
    {
         printf("child getpid()=%d\n", getpid());
    }
    //判断3
    else if(pid > 0)//父进程
    {
        printf("parent getpid()=%d\n", getpid());
    }
 
    return 0;
}
```

结果如下:
```c++
parent getpid()=13725
child getpid()=13726
```

两个判断的代码都执行了，这是非常不可思议的，但fork函数确实实现了这样的功能。也就是在fork函数后面的代码都会执行2遍。 这就是为什么两个判断都会被执行的原因。
现在来梳理一下成功fork的执行流程
第一步： `pid=fork()`，如果成功那么pid就有一个非0正值。否则返回-1。
第二步： 因为pid>0，所以进入判断3。这是在父进程。
第三步： 父进程的代码执行完了，程序又会把fork后面的函数再执行一遍，此时pid的值变为0，所以进入判断2。

`*`注意:这里的pid_t类似一个类型，就像int型一样，int型定义的变量都是整型的，pid_t定义的类型都是进程号类型。这个语句的意思是定义了一个pid_t类型的变量pid，fork()函数返回一个进程号，这个进程号赋给了pid。pid_t在头文件types.h（sys/types.h）中定义

pid_t就是一个short类型变量，实际表示的是内核中的进程表的索引

**试试判断下面代码:**

```c++
  #include<stdio.h>
  #include<stdlib.h>
  #include<unistd.h>
   
   int main()
   {
      pid_t fpid;//fpid表示fork函数返回的值
      int count=0;
      fpid=fork();
      if(fpid<0)
          printf("error in fork!");
      else if(fpid==0)
      {
          printf("我是子进程,id:%d\n",getpid());
          count++;
      }
      else
      {
          printf("我是父进程,id:%d\n",getpid());
          count++;
      }
      printf("统计结果是:%d\n",count);
      exit(0);
  }
```

<img src="https://img-blog.csdnimg.cn/4daf60e5731e4d37bb893cee07fe533c.png" alt="image.png" style="zoom:50%;" />

## **父子进程的调用流程:**

下面我们讲解一下fork调用的细节

```cpp
int main(){
	fork();//fork1
	fork();//fork2
	printf("love\n");
	return 0;
}
```

上述代码打印了4次love，创建了4个进程（1一个父进程，3个子进程）

<img src="https://img-blog.csdnimg.cn/581bff9bef734e929209386343aaf074.png" alt="image.png" style="zoom:50%;" />
假设我们的main进程pid是1001，注意看左边的1，2，4进程其实都是main进程1001。进程3，6是同一个进程1002。所有一共有1001，1002，1003，1004四个进程。也就是只要数叶子节点就行了。其中1个是main进程，其它3个是子进程。有多少个进程就输出多少次hello字符串。也就是只有4，5，6，7执行了printf。

如果明白了上面的过程下面我给出四个例子和解释，可以自己先试着判断

```cpp
int main()
{
    int n=2;
    for(;i<n;i++)
    {
        fork();
        printf("A\n");//遇到\n会自动刷新缓冲区
    }
    exit(0);
}
```

<img src="https://img-blog.csdnimg.cn/13a43ca4f51348fe8a67ed2d30f9ca0a.png" alt="image.png" style="zoom:50%;" />

```cpp
int main()
{
    int n=2;
    for(;i<n;i++)
    {
        fork();
        printf("-");//不会刷新缓冲区
    }
    exit(0);
}
```

<img src="https://img-blog.csdnimg.cn/34aedb9eee3241ab99e53dd4084a1aca.png" alt="image.png" style="zoom:50%;" />

```cpp
int main()
{
	fork()||fork();
	printf("A\n");
	exit(0);
	1）在父进程中，fork返回新创建子进程的进程ID；大于0的
    2）在子进程中，fork返回0；
    3）如果出现错误，fork返回一个负值；
}
```

结果打印3个A，共创建3个进程
fork()给子进程返回一个零值，而给父进程返回一个非零值
在main这个主进程中，首先执行 `fork() || fork()`, 左边的`fork()`返回一个非零值，根据||的短路原则，前面的表达式为真时，后面的表达式不执行，故包含main的这个主进程创建了一个子进程，
由于子进程会复制父进程，而且子进程会根据其返回值继续执行，就是说，在子进程中， `fork()||fork()`这条语句 左边表达式的返回值是0, 所以||右边的表达式要执行，这时在子进程中又创建了一个进程，
即main进程->子进程->子进程，一共创建了3个进程。

<img src="https://img-blog.csdnimg.cn/a491461cc6934bf3ad3d73a20a5c971e.png" alt="image.png" style="zoom:50%;" />

```cpp
int main()
{
	fork()&&fork();
	printf("A\n");
	exit(0);
}
```

**结果输出3个A，创建3个进程**

<img src="https://img-blog.csdnimg.cn/57c3ee87567647afa62ab471f2ad2624.png" alt="image.png" style="zoom:50%;" />

注意小tips:
父子进程相同：
刚刚fork后，data段，text段，堆，栈，环境变量，全局变量，宿主目录位置，进程工作目录，信号处理方式
父子进程不同：
进程id，返回值，各自父进程，进程创建时间，闹钟，未决信号
父子进程共享：
文件描述符
mmap映射区
读时共享，写时复制-----------------全局变量
对fork复制进程做了一个优化----写时拷贝技术。写时拷贝指的是两个任务可以同时自由读取内存，但任意一个任务试图对内存进行修改时，内存就会复制一份提供给修改方单独使用，以免影响到其他的任务使用。

<img src="https://img-blog.csdnimg.cn/7b2238578ca9467584aa72fdb1b19385.png" alt="image.png" style="zoom:50%;" />

<img src="https://img-blog.csdnimg.cn/87abf93b5401400386bf09589bbfedb5.png" alt="image.png" style="zoom:50%;" />

特别的，fork之后父进程先执行还是子进程先执行不确定，取决于内核所使用的调度算法。
注意父进程多次fork后不加以控制，我们会发现打印结果不唯一，无序。是因为对于操作系统将代码交给cpu执行的时候产生的子进程相当于同时产生的，并发运行，他们站在同一起跑线上去争夺cpu，谁抢到了谁就去运行打印数据，这是与系统调度有关，想让他们有序，可以加入sleep函数让其休眠一下

# 什么是快照？ 快照与备份有什么区别？

一句话答案：快照是数据存储的**某一时刻的状态记录**；备份则是数据存储的**某一个时刻的副本**。这是两种完全不同的概念。
## [快照](https://so.csdn.net/so/search?q=%E5%BF%AB%E7%85%A7&spm=1001.2101.3001.7020)

先说背景知识：我们现在电脑上的数据，记录方式都是**地址->数据**这样存放的。例如我们最熟悉的机械硬盘，最小存储单位是扇区，老式硬盘一个扇区512字节，新式硬盘一个扇区4096字节。每个扇区都有自己的地址，现在主流的LBA寻址方式，就是从0开始，0,1,2,3，……，N这样。

<img src="https://pic3.zhimg.com/80/v2-eed420cd0f81621318ab2320426674a2_hd.jpg" alt="image.png" style="zoom:70%;" />
当然，对于外部存储，我们一般不会这样直接存放数据，我们可能通过硬盘分区，并且格式化对应分区后存放数据，于是就变成这样的情况：

<img src="https://pic3.zhimg.com/80/v2-9e0455a3225f47a1edc710963aee0d32_hd.jpg" alt="image.png" style="zoom:70%;" />

例如上图，我们建立**一张逻辑地址**和**物理地址的映射表**，**每个逻辑地址对应两个物理存储单元**。当然，这是比较简单的情况：物理硬盘，上面有一个磁盘分区，格式化的时候一个分配单元（Windows叫“簇”）占两个扇区。复杂一点的，可能会有多层逻辑地址，例如分区上有一个虚拟磁盘文件，作为虚拟机的“物理”设备。而虚拟盘的每一个物理扇区号，其实只是虚拟磁盘文件的某个逻辑地址，又对应着文件系统的某个分配单元，同时又是物理磁盘的某个物理扇区号。也就是说可能存在多层逻辑地址，而每一层逻辑地址都会把上一层逻辑地址看做是物理地址对待，这个就不展开了。

如果这个时候，我们做一个快照，**快照的数据**大概类似这么一个东西：

<img src="https://pic3.zhimg.com/80/v2-8c6815d656dfddf5a7ac3dce6466b14c_hd.jpg" alt="image.png" style="zoom:90%;" />

如果我们要把保存的ABCD改成AACD，**在没有快照的时候，是下图的情况（数据在原来的地址上被覆盖了）**：

<img src="https://pic3.zhimg.com/80/v2-6d32a00c13a837a0d5985ad1bb48f317_hd.jpg" alt="image.png" style="zoom:70%;" />
很显然，我们找不回ABCD这个数据了。而**如果我们做了快照**，快照地址0、1 对应的物理地址`[0-3]`  **就被锁定不可更改了**，结果会类似这么一个情况：

<img src="https://pic4.zhimg.com/80/v2-32c1ba79a05970f1f91977b13e51522d_hd.jpg" alt="image.png" style="zoom:70%;" />
（PS：因为我们之前做快照，所有逻辑地址`[0,1]`以及与其对应的物理地址`[0,1,2,3]`都被锁定了。于是我们在尝试修改被锁定的**逻辑区域**的时候，我们会把新的修**改存到一个新的区域**。例如，我们对原来的逻辑地址0（即物理地址`[0,1]`）进行修改的时候，会将修改写到**新的逻辑地址**0（物理地址`[7,8]`）中）

这个时候，我们按照0-1-2-3这样的逻辑地址，读取出来的就是AACD，两个空单元。按照快照地址0-1读取数据，我们就能读取到原来的ABCD了。同时，我们可以看到，**原来的逻辑地址4没有了**。**换句话说，我们的存储空间少了一个逻辑存储单元**。

当然，上面这是最简单的快照。事实上，我们要考虑将来，逻辑地址1可能要从CD改成EF；将来我们需要再做快照2、快照3，更复杂的，我们可能做了快照3之后，回滚到快照1，然后继续修改数据，之后再做一个快照4……又或者这是一个虚拟硬盘文件，放入一份原始数据之后，做了一个快照；然后我们在这个基础上创建了虚拟硬盘2、3、……、N，用于存放不同逻辑的数据处理结果。这些更复杂的情况就不展开说了。

一般来说，原则就是就是**快照时锁定物理单元内容**，并记录本次快照和上一次快照的所对应的物理地址（或者是**上一层逻辑地址**）的**差异**。上面例子中，**快照完成后，物理地址0-3的数据是不可改动的**。**如果改写后再做第2次快照，则物理地址8-9也会锁定**，同时第二次快照会记录下逻辑地址0所对应的物理地址从0改为8。

因为快照**仅仅记录**逻辑地址和物理地址的**对应关系**，因此快照的速度非常快。在上面例子中，一个逻辑地址对应2个物理扇区，按照现代硬盘一个扇区4KiB，就算按照ZFS的地址宽度128bit=16Byte算，加上物理地址宽度，做一次快照的写入的数据量可能只有整体数据量的0.5%不到。

## **备份**

而**备份**，则是另外一份数据副本，例如这样的：

<img src="https://pic4.zhimg.com/80/v2-5013c3b1a934ea4e1e563e6dd690af32_hd.jpg" alt="image.png" style="zoom:70%;" />
同一物理设备上的备份

或者这样的：

<img src="https://pic3.zhimg.com/80/v2-4312c9b4624d8fe4dbd7eb6d5a15629d_hd.jpg" alt="image.png" style="zoom:70%;" />
不同物理设备上的备份

另外，备份又分**全量备份**和**增量备份**，全量备份就是上面的情况了。**增量备份**则类似快照，但不同的地方在于**两次快照之间**只记录了两层地址之间的对应关系的差异，而**增量备份**则把这些差异中，新增地址所对应的底层数据也复制了一份出来。

快照和备份的不同在于：

- **备份的数据安全性更好**：如果原始数据损坏（例如物理介质损坏，或者绕开了快照所在层的管理机制对锁定数据进行了改写），快照回滚是无法恢复出正确的数据的，而备份可以。
- **快照的速度比备份快得多**：生成快照的速度比备份速度快的多。也因为这个原因，为了回避因为备份时间带来的各种问题（例如IO占用、数据一致性等）很多备份软件是先生成快照，然后再按照快照所记录的对应关系去读取底层数据来生成备份。
- **占用空间不同**：备份会占用双倍的存储空间，而快照所占用的存储空间则取决于快照的数量以及数据变动情况。**极端情况下，快照可能会只占用1%不到的存储空间，也可能会占用数十倍的存储空间**。（PS：不过如果同一份数据，同时做相同数量的快照和增量备份的话，备份还是会比快照占用的存储空间多得多。）

# BusyBox
`BusyBox`将许多常见UNIX实用程序的小版本组合成一个小的**可执行文件**。它提供了大多数你通常在GNU fileutils，shellutils等中找到的实用程序的替代品。BusyBox中的实用程序通常比它们的功能齐全的GNU表亲有更少的选项;然而，包含的选项提供了预期的功能，并且行为非常类似于GNU对应的选项。BusyBox为任何小型或嵌入式系统提供了一个相当完整的环境。


# 什么是挂载？Linux挂载

首先先说一下在**Linux**中一切皆文件（硬件设备也是文件），所有文件都是存放在以根目录为树形目录结构中；下面来说说一下什么是**挂载**

> **挂载：** 指的就是将设备文件中的**顶级目录**连接到 Linux 根目录下的某一目录（最好是空目录），访问此目录就等同于访问设备文件。

**注意：** 并不是根目录下任何一个目录都可以作为挂载点，由于挂载操作会**使得原有目录中文件被隐藏**，因此根目录以及系统原有目录都不要作为挂载点，会造成系统异常甚至崩溃，挂载点最好是**新建的空目录**

下面举个例子:  
想通过命令行的方式访问某个U盘中的数据，如图所示为Linux系统文件目录和U盘的文件系统目录

<img src="https://article.biliimg.com/bfs/article/3bc586a0d7684c3428f81e277083ff8346eada43.png" alt="image.png" style="zoom:50%;" />

从图中我们可以看出，目前Linux和U盘文件系统分属两个文件系统，无法使用命令去找到U盘中的文件，此时则需要将两个系统挂载：在根目录下创建一个新的目录`/sdb-u（sdb1`），挂载效果如图如下图：

<img src="https://img-blog.csdnimg.cn/20201117092103664.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L2Nvcm5lcmxpbg==,size_16,color_FFFFFF,t_70" style="zoom:60%;" />
可以看到，U 盘文件系统已经成为 Linux 文件系统目录的一部分，此时访问 `/sdb-u/` 就等同于访问 U 盘。
当U盘插入 Linux 后，系统给U盘分配一个**目录文件**(比如`sdb1`），就位于`/dev/` 目录下（`/dev/sdb1`），但无法通过`/dev/sdb1/`直接访问U盘数据，访问此目录只会提供给你此设备的一些基本信息（比如容量）

**/dev：** 设备文件保存位置；根目录下的 `/dev/` 目录文件负责所有的硬件设备文件，

> **总之，Linux 系统使用任何硬件设备，都必须将设备文件与已有目录文件进行挂载** 

将文件系统挂载到Linux系统上，就需要使用**mount挂载命令**  
mount命令的常用格式有以下三种：

```bash
mount [-l]            单纯使用 mount 命令，会显示出系统中已挂载的设备信息，使用 -l 选项，会额外显示出卷标名称
```

```bash
mount -a            a 选项的含义是自动检查 /etc/fstab 文件中有无疏漏被挂载的设备文件，如果有，则进行自动挂载操作； /etc/fstab 文件是文件自动挂载文件
```

```bash
mount [-t 系统类型] [-L 卷标名] [-o 特殊选项] [-n] 设备文件名  挂载点 
-t 系统类型：指定欲挂载的文件系统类型。Linux 常见的支持类型有 EXT2、EXT3、EXT4、iso9660（光盘格式）、vfat、reiserfs 等。如果不指定具体类型，挂载时 Linux 会自动检测。
-L 卷标名：除了使用设备文件名（例如 /dev/hdc6）之外，还可以利用文件系统的卷标名称进行挂载。
-n：在默认情况下，系统会将实际挂载的情况实时写入 /etc/mtab 文件中，但在某些场景下（例如单人维护模式），为了避免出现问题，会刻意不写入，此时就需要使用这个选项；
-o 特殊选项：可以指定挂载的额外选项，比如读写权限、同步/异步等，如果不指定，则使用默认值（defaults）
```

# 管道pipe详解

[管道pipe详解](https://blog.csdn.net/oguro/article/details/53841949?ops_request_misc=%257B%2522request%255Fid%2522%253A%2522169391985016800188590331%2522%252C%2522scm%2522%253A%252220140713.130102334..%2522%257D&request_id=169391985016800188590331&biz_id=0&utm_medium=distribute.pc_search_result.none-task-blog-2~all~top_positive~default-1-53841949-null-null.142^v93^control&utm_term=%E7%AE%A1%E9%81%93&spm=1018.2226.3001.4187)


# redis内存说明

下面的内容改下，一些地方加上``
- "`peak.allocated`" //Redis进程自启动以来消耗内存的峰值。 
	- (integer) 79492312 
- "`total.allocated`"//Redis使用其分配器分配的总字节数，即当前的总内存使用量。 
	- (integer) 79307776 
- "`startup.allocated`" //Redis启动时消耗的初始内存量。 
	- (integer) 45582592 
- "`replication.backlog`" //复制积压缓冲区的大小。 
	- (integer)33554432 
- "`clients.slaves`" //主从复制中所有从节点的读写缓冲区大小。 
	- (integer) 17266 
- "`clients.normal`" //除从节点外，所有其他客户端的读写缓冲区大小。 
	- (integer)119102 
- "`aof.buffer`" //AOF持久化使用的缓存和AOF重写时产生的缓存。 
	- (integer) 0 
- "`db.0`"//业务数据库的数量。 
	- 1)"`overhead.hashtable.main`" //当前数据库的hash链表开销内存总和，即元数据内存。 
	- 2)(integer) 144 
	- 3)"`overhead.hashtable.expires`"//用于存储key的过期时间所消耗的内存。 
	- (integer) 0 
- "`overhead.total`"//数值 =`startup.allocated+replication.backlog+clients.slaves+clients.normal+aof.buffer+db.X`。 
	- (integer) 79273616 
- "`keys.count`" //当前Redis实例的key总数 
	- (integer) 2 
- "`keys.bytes-per-key`" //当前Redis实例每个key的平均大小，计算公式 
	- : `(total.allocated-startup.allocated)/keys.count`。 
	- (integer) 16862592 
- "`dataset.bytes`" //纯业务数据占用的内存大小。 
	- (integer) 34160 
- "`dataset.percentage`" //纯业务数据占用的内存比例，计算公式 
	- : `dataset.bytes*100/(total.allocated-startup.allocated)`。 
	- "0.1012892946600914" 
- "`peak.percentage`" //当前总内存与历史峰值的比例，计算公式
	- ：`total.allocated*100/peak.allocated`。 
	- "99.767860412597656" 
- "`fragmentation`" //内存的碎片率。 
	- "0.45836541056632996"




# 软限制和硬限制

在计算机领域中，软限制（soft limit）和硬限制（hard limit）是两个用于控制资源使用的概念。
## 软限制

- 软限制：软限制是一种可配置的限制，它指定了某个资源的最大使用量或行为。当达到软限制时，并不会立即发生严重的影响，而是根据具体情况逐渐采取一些操作来限制资源的使用。例如，在网络通信中，软限制可以用来限制数据传输速率，避免网络拥塞或内存溢出。软限制通常可以通过调整系统参数或配置选项进行更改。
## 硬限制

- 硬限制：硬限制是一种严格的限制，超过该限制将立即受到限制或终止行为。超过硬限制可能会导致系统崩溃、进程终止或其他严重的问题。例如，在操作系统中，硬限制可以用来限制单个进程的内存使用量，一旦进程超过硬限制，操作系统会立即终止该进程以保护系统稳定性。硬限制通常由操作系统或其内核定义，并通常无法直接修改。

总结来说，软限制提供一种可调节的资源使用控制方法，而硬限制则提供一种严格的、不能被突破的限制。根据具体场景和需求，可以根据系统的要求来选择使用软限制还是硬限制。


# 大小端存储

大小端存储是计算机存储的一个设计概念，涉及了高地址和低地址，数据的高位和低位等概念，所以在理解大小端存储之前，需要知道什么是高地址和低地址，什么是数据的高位和低位这些概念。

## 数据的高位和低位

> **数据的高位是数据的左边位置的数，数据的低位是数据右边位置的数，** 数据的高位和低位又称高字节和低字节。


拿一个十进制数来讲，例如简单的1234，**那么数据的高位是在左边**，也就是**1是1234的高位**，**数据的低位是在数据的右边，4是数据的低位**，**高位和低位是一个相对的概念，在1234中，相对于4,1是高位，相对于1,4是低位。** 如图所示

<img src="https://img-blog.csdnimg.cn/5eca86be2d00457eb9851996c879835f.png" alt="image.png" style="zoom:50%;" />
拿八位二进制数来讲，1111 0000是八位二进制数，类似的，1111是数据的高位，而0000是数据的低位

<img src="https://img-blog.csdnimg.cn/e5b9b3d172494919a7b1fedf5c1958ef.png" alt="image.png" style="zoom:50%;" />

## 高地址和低地址 

> **为了便于管理存储地址，给地址进行编号，值较大的地址是高地址，值较小的地址是低地址**

 拿4位16进制的数来讲,该数表示一个地址，例如0xFFFF和0x0000，则0xFFFF则是高地址，0x0000则是低地址，如图所示。

<img src="https://img-blog.csdnimg.cn/50c0573204604182a1054369ccd09706.png" alt="image.png" style="zoom:50%;" />

## 大端存储和小端存储 

> 大端存储，是将数据的低位字节放到高地址处，高位字节放到低地址处。
> 小端存储，是将数据的低位字节放到低地址处，高位字节放到高地址处。
> 大端存储和小端存储记忆时，可以理解为将低位字节放到大端还是小端？大端存储就是将低为放到高地址，小端就是将低位放到低地址，这样方便记忆

例如将4位16进制数存储到地址中，数据为0x1234,如图所示

<img src="https://img-blog.csdnimg.cn/ec5cb34ebb3d4f59836fe5051f38ec3a.png" alt="image.png" style="zoom:50%;" />

<img src="https://img-blog.csdnimg.cn/a6c086e1ae404056ac089306fc8688df.png" alt="image.png" style="zoom:50%;" />
**大端存储和小端存储并没有优劣之分**


## 为什么会有大小端存储

对于位数大于8的处理器，寄存器的宽度大于1个字节，那么将会存在如何将多个字节安排在寄存器内，就可以有大小端存储两种方法，**大小端存储并没有优劣之分，都是存储的方法**


## 验证C语言的数据的存储是大端还是小端
```c
//判断大小端
//假设右边是高地址，左边是低地址
int main()
{
	// ------------> 内存地址增长方向
	int a = 1; // 0x0000 0001
	//如果是大端 低位字节放到高地址，高位字节放到低地址
	//00 00 00 01
	//如果是小端 高位字节放到高地址，低位字节放到低地址
	//01 00 00 00
	char* p = (char*)&a; //字符指针只读1个字节，读8位
    //如果是大端存储，则p读取的值是0
    //如果是小端存储，则p读取的值是1
	if (*p == 1)
		printf("小端\n");
	else
		printf("大端\n");
	return 0;
}
```


# 什么是JWT

## 起源
需要了解一门技术，首先从为什么产生开始说起是最好的。==JWT 主要用于用户登录鉴权==，所以我们从最传统的session认证开始说起。

## **session认证**

众所周知，==http 协议本身是无状态的协(指的是服务器不会保存任何与客户端请求相关的信息，每个请求都是相互独立的，服务器不能直接判断一个请求的上下文信息。也就是说，服务器无法知道之前的请求是谁发起的，也无法知道是否存在其他的相关请求)==，那就意味着当有用户向系统使用账户名称和密码进行用户认证之后，下一次请求还要再一次用户认证才行。因为我们不能通过 http 协议知道是哪个用户发出的请求，所以如果要知道是哪个用户发出的请求，那就需要在服务器保存一份用户信息(保存至[[javaweb#Session|session]])，然后在认证成功后返回cookie值传递给浏览器，那么用户在下一次请求时就可以带上 cookie 值，服务器就可以识别是哪个用户发送的请求，是否已认证，是否登录过期等等。这就是传统的session认证方式。

session 认证的==缺点==其实很明显，由于session是保存在服务器里，所以==如果分布式部署应用的话，会出现session不能共享的问题，很难扩展==。于是乎为了解决 session 共享的问题，又引入了 [[redis#基于Session实现登录流程|redis]]，接着往下看。

## **token认证**

这种方式跟 session 的方式流程差不多，不同的地方在于保存的是一个 token 值到 redis，token 一般是一串随机的字符(比如UUID)，value 一般是用户ID，并且设置一个过期时间。每次请求服务的时候带上 token 在请求头，后端接收到token 则根据 token 查一下 redis 是否存在，如果存在则表示用户已认证，如果 token 不存在则跳到登录界面让用户重新登录，登录成功后返回一个 token 值给客户端。

==优点==是多台服务器都是使用 redis 来存取 token，不存在不共享的问题，所以容易扩展。==缺点==是每次请求都需要查一下redis，会造成 redis 的压力，还有增加了请求的耗时，每个已登录的用户都要保存一个 token 在 redis，也会消耗 redis 的存储空间。

有没有更好的方式呢？接着往下看。

## **什么是JWT**

JWT (全称：Json Web Token)是一个开放标准(RFC 7519)，它定义了一种紧凑的、自包含的方式，用于作为JSON对象在各方之间安全地传输信息。该信息可以被验证和信任，因为它是数字签名的。

上面说法比较文绉绉，简单点说就是一种认证机制，让后台知道该请求是来自于受信的客户端。

首先我们先看一个流程图：

<img src="https://img-blog.csdnimg.cn/8c1fe41d316d4acbb5e9f510fa7b5d98.png" alt="image.png" style="zoom:80%;" />
流程描述一下：

1. 用户使用账号、密码登录应用，登录的请求发送到 `Authentication Server`。
2. Authentication Server 进行用户验证，然后**创建JWT字符串返回给客户端**。
3. 客户端请求接口时，在请求头带上JWT。
4. Application Server 验证 JWT 合法性，如果合法则继续调用应用接口返回结果。

可以看出与token方式有一些不同的地方，就是不需要依赖 redis，用户信息存储在客户端。所以==关键在于生成 JWT 和解析 JWT== 这两个地方。


## **JWT的数据结构**

JWT 一般是这样一个字符串，分为三个部分，以 “.” 隔开：

```text
xxxxx.yyyyy.zzzzz
```

<img src="https://img-blog.csdnimg.cn/f41df3d5cf0e414bb7e51457a57a5106.webp" alt="image.png" style="zoom:60%;" />
### **Header**
==JWT 第一部分是头部分，它是一个描述 JWT 元数据的 Json 对象==，通常如下所示。

```json
{
    "alg": "HS256",
    "typ": "JWT"
}
```

alg 属性表示签名使用的算法，默认为 HMAC SHA256（写为HS256），typ 属性表示令牌的类型，JWT 令牌统一写为JWT。
最后，使用 Base64 URL 算法将上述 JSON 对象转换为字符串保存。

### **Payload**

==JWT 第二部分是 Payload，也是一个 Json 对象==，除了包含需要传递的数据，还有七个默认的字段供选择。

- iss (issuer)：签发人/发行人
- sub (subject)：主题
- aud (audience)：用户
- exp (expiration time)：过期时间
- nbf (Not Before)：生效时间，在此之前是无效的
- iat (Issued At)：签发时间
- jti (JWT ID)：用于标识该 JWT

如果自定义字段，可以这样定义：
```json
{
    //默认字段
    "sub":"主题123",
    //自定义字段
    "name":"java技术爱好者",
    "isAdmin":"true",
    "loginTime":"2021-12-05 12:00:03"
}
```

需要注意的是，==默认情况下 JWT 是未加密的==，任何人都可以解读其内容，因此一些敏感信息不要存放于此，以防信息泄露。
JSON 对象也使用 Base64 URL 算法转换为字符串后保存，==是可以反向反编码回原样的==，这也是为什么不要在 JWT 中放敏感数据的原因

### **Signature**
```txt
header (base64URL 加密后的)
payload (base64URL 加密后的)
secret
```

==JWT 第三部分是签名。==是这样生成的，首先需要指定一个 secret，该 secret 仅仅保存在服务器中，保证不能让其他用户知道。这个部分需要 base64URL 加密后的 header 和 base64URL 加密后的 payload 使用 . 连接组成的字符串，然后通过header 中声明的加密算法 ==进行加盐secret组合加密==，然后就得出一个==签名哈希==，也就是Signature，==且无法反向解密==。

那么 Application Server 如何进行验证呢？可以利用 JWT 前两段，用同一套哈希算法和同一个 secret 计算一个签名值，然后把计算出来的签名值和收到的 JWT 第三段比较，如果相同则认证通过。


## **JWT的优点**

- json格式的通用性，所以==JWT可以跨语言支持==，比如Java、JavaScript、PHP、Node等等。
- 可以==利用Payload存储一些非敏感的信息==。
- ==便于传输==，JWT结构简单，字节占用小。
- 不需要在服务端保存会话信息，==易于应用的扩展==。

## **怎么使用JWT**

首先引入[[java依赖#jjw|Maven依赖]]

创建工具类，用于创建(生成) jwt 字符串和解析 jwt。
```java
@Component
public class JwtUtil {

    @Value("${jwt.secretKey}")
    private String secretKey;

    public String createJWT(String id, String subject, long ttlMillis, Map<String, Object> map) throws Exception {
        JwtBuilder builder = Jwts.builder()
                .setId(id)
                .setSubject(subject) // 发行者
                .setIssuedAt(new Date()) // 发行时间
                .signWith(SignatureAlgorithm.HS256, secretKey) // 签名类型 与 密钥
                .compressWith(CompressionCodecs.DEFLATE);// 对载荷进行压缩
        if (!CollectionUtils.isEmpty(map)) {
            builder.setClaims(map);
        }
        if (ttlMillis > 0) {
            builder.setExpiration(new Date(System.currentTimeMillis() + ttlMillis));
        }
        return builder.compact();
    }


    public Claims parseJWT(String jwtString) {
        return Jwts.parser().setSigningKey(secretKey)
                .parseClaimsJws(jwtString)
                .getBody();
    }
}

```

接着在application.yml配置文件配置`jwt.secretKey`。
```yml
## 用户生成jwt字符串的secretKey
jwt:
  secretKey: ak47
```

接着创建一个响应体。

```java
public class BaseResponse {

    private String code;

    private String msg;

    public static BaseResponse success() {
        return new BaseResponse("0", "成功");
    }

    public static BaseResponse fail() {
        return new BaseResponse("1", "失败");
    }
    //构造器、getter、setter方法
}

public class JwtResponse extends BaseResponse {

    private String jwtData;

    public static JwtResponse success(String jwtData) {
        BaseResponse success = BaseResponse.success();
        return new JwtResponse(success.getCode(), success.getMsg(), jwtData);
    }

    public static JwtResponse fail(String jwtData) {
        BaseResponse fail = BaseResponse.fail();
        return new JwtResponse(fail.getCode(), fail.getMsg(), jwtData);
    }
    //构造器、getter、setter方法
}

```

接着创建一个UserController：
```java
@RestController
@RequestMapping("/user")
public class UserController {

    @Resource
    private UserService userService;

    @RequestMapping(value = "/login", method = RequestMethod.POST)
    public JwtResponse login(@RequestParam(name = "userName") String userName,
                             @RequestParam(name = "passWord") String passWord){
        String jwt = "";
        try {
            jwt = userService.login(userName, passWord);
            return JwtResponse.success(jwt);
        } catch (Exception e) {
            e.printStackTrace();
            return JwtResponse.fail(jwt);
        }
    }
}

```

还有UserService：
```java
@Service
public class UserServiceImpl implements UserService {

    @Resource
    private JwtUtil jwtUtil;

    @Resource
    private UserMapper userMapper;

    @Override
    public String login(String userName, String passWord) throws Exception {
        //登录验证
        User user = userMapper.findByUserNameAndPassword(userName, passWord);
        if (user == null) {
            return null;
        }
        //如果能查出，则表示账号密码正确，生成jwt返回
        String uuid = UUID.randomUUID().toString().replace("-", "");
        HashMap<String, Object> map = new HashMap<>();
        map.put("name", user.getName());
        map.put("age", user.getAge());
        return jwtUtil.createJWT(uuid, "login subject", 0L, map);
    }
}

```

还有UserMapper.xml：
```java
@Mapper
public interface UserMapper {
    User findByUserNameAndPassword(@Param("userName") String userName, @Param("passWord") String passWord);

}

<?xml version="1.0" encoding="UTF-8" ?>
<!DOCTYPE mapper
        PUBLIC "-//mybatis.org//DTD Mapper 3.0//EN"
        "http://mybatis.org/dtd/mybatis-3-mapper.dtd">
<mapper namespace="io.github.yehongzhi.jwtdemo.mapper.UserMapper">
    <select id="findByUserNameAndPassword" resultType="io.github.yehongzhi.jwtdemo.model.User">
        select * from user where user_name = #{userName} and pass_word = #{passWord}
    </select>
</mapper>
```

user 表结构如下：

<img src="https://img-blog.csdnimg.cn/6749b9208f8f4b3eac925d44c4cb5bfb.png" alt="image.png" style="zoom:70%;" />

返回的 jwt 字符串如下：
```
eyJhbGciOiJIUzI1NiIsInppcCI6IkRFRiJ9.eNqqVspLzE1VslJ6OnHFsxnzX67coKSjlJgOFDEzqAUAAAD__w.qib2DrjRKcFnY77Cuh_b1zSzXfISOpCA-g8PlAZCWoU
```

接着我们写一个接口接收这个 jwt，并做验证。
```java
@RestController
@RequestMapping("/jwt")
public class TestController {

    @Resource
    private JwtUtil jwtUtil;

    @RequestMapping("/test")
    public Map<String, Object> test(@RequestParam("jwt") String jwt) {
        //这个步骤可以使用自定义注解+AOP编程做解析jwt的逻辑，这里为了简便就直接写在controller里
        Claims claims = jwtUtil.parseJWT(jwt);
        String name = claims.get("name", String.class);
        String age = claims.get("age", String.class);
        HashMap<String, Object> map = new HashMap<>();
        map.put("name", name);
        map.put("age", age);
        map.put("code", "0");
        map.put("msg", "请求成功");
        return map;
    }
}

```


<img src="https://img-blog.csdnimg.cn/4bded6210bd44e019add938845d67ff7.png" alt="image.png" style="zoom:70%;" />


# ASCII对照表


![image.png](https://article.biliimg.com/bfs/article/b9f9973ffae863ee7bcbe5a969c35f0d38716159.png)




![image.png](https://article.biliimg.com/bfs/article/bb79519b99966ef5754bcf475f7d3b0d38716159.png)


![image.png](https://article.biliimg.com/bfs/article/e5ad4bf2141ea8839fd142dbd6ca36cd38716159.png)


![image.png](https://article.biliimg.com/bfs/article/300744076dabd90aaa6438d33e9f09c438716159.png)


![image.png](https://article.biliimg.com/bfs/article/8e472ced103265ea4d62b6aaea9097a938716159.png)


![image.png](https://article.biliimg.com/bfs/article/0003a37e6b9053aa374ce8d64ec0d67338716159.png)

![image.png](https://article.biliimg.com/bfs/article/81c4a76fb6b22406310be29d656d60d638716159.png)

![image.png](https://article.biliimg.com/bfs/article/33c593f03fbae01e7342121e8c3f8c1a38716159.png)



ASCII 码大致由以下两部分组成：
- ASCII 非打印控制字符： ASCII 表上的数字 0-31 分配给了控制字符，用于控制像打印机等一些外围设备。
- ASCII 打印字符：数字 32-126 分配给了能在键盘上找到的字符，当查看或打印文档时就会出现。数字 127 代表 Del 命令。


# 线程池

## 线程池原理



> [!note] 为什么用线程池(动态创建动线程的缺点)
> - 动态创建进程（或线程）是比较耗费时间的，这将导致较慢的客户响应。
> - 动态创建的子进程（或子线程）通常只用来为一个客户服务（除非我们做特殊的处理），这将导致系统上产生大量的细微进程（或线程）。进程（或线程）间的切换将消耗大量CPU时间。
> - 动态创建的子进程是当前进程的完整映像。当前进程必须谨慎地管理其分配的文件描述符和堆内存等系统资源，否则子进程可能复制这些资源，从而使系统的可用资源急剧下降，进而影响服务器的性能。


我们使用线程的时候就去创建一个线程，这样实现起来非常简便，但是就会有一个问题：如果并发的线程数量很多，并且每个线程都是执行一个时间很短的任务就结束了，这样**频繁创建线程**就会大大降低系统的效率，因为频繁创建线程和销毁线程需要时间。

那么有没有一种办法使得**线程可以复用**，就是执行完一个任务，并不被销毁，而是可以继续执行其他的任务呢？

线程池是一种多线程处理形式，处理过程中将任务添加到**队列**，然后在创建线程后自动启动这些任务。线程池线程都是**后台线程**。每个线程都使用默认的堆栈大小，以默认的优先级运行，并处于多线程单元中。如果某个线程在托管代码中空闲（如正在等待某个事件）,则线程池将插入另一个辅助线程来使所有处理器保持繁忙。如果所有线程池线程都始终保持繁忙，但队列中包含挂起的工作，则线程池将在一段时间后创建另一个辅助线程但线程的数目永远不会超过最大值。超过最大值的线程可以排队，但他们要等到其他线程完成后才启动。

在各个编程语言的语种中都有线程池的概念，并且很多语言中直接提供了线程池，作为程序猿直接使用就可以了，下面给大家介绍一下线程池的实现原理：

- 线程池的组成主要分为3个部分，这三部分配合工作就可以得到一个完整的线程池：

1. `任务队列，存储需要处理的任务，由工作的线程来处理这些任务`
	- 通过线程池提供的API函数，将**一个待处理的任务添加到任务队列**，或者从任务队列中删除
	- 已处理的任务会被从任务队列中删除
	- 线程池的使用者，也就是调用线程池函数往任务队列中**添加任务的线程**就是生产者线程
2. `工作的线程（任务队列任务的消费者） ，N个`
	- 线程池中维护了**一定数量**的工作线程, 他们的作用是是**不停的读**任务队列, 从里边取出任务并处理
	- 工作的线程相当于是任务队列的消费者角色，
	- 如果任务队列为空, 工作的线程将会被阻塞 (使用条件变量/信号量阻塞)
	- 如果阻塞之后有了新的任务, 由生产者将阻塞解除, 工作线程开始工作
- `管理者线程（不处理任务队列中的任务），1个`
	- 它的任务是周期性的对任务队列中的任务数量以及处于忙状态的工作线程个数进行检测
		- 当任务过多的时候, 可以适当的创建一些新的工作线程
		- 当任务过少的时候, 可以适当的销毁一些工作的线程

![[线程池.excalidraw]]


#面试点
什么情况下会造成虚假唤醒
1. 任务可能被信号唤醒
2. 业务场景(当发布任务的时候，唤醒一个休眠的线程，但是一个正在执行的任务的线程拿到了这个任务，而唤醒的那个线程就会空指针异常)


具体实现的疑问
1. 为什么在抛出任务这个接口中需要线程池这个数据结构

# 虚拟地址空间

虚拟地址空间是一个非常抽象的概念，先根据字面意思进行解释：
- 它可以用来加载程序数据（数据可能被加载到物理内存上，空间不够就加载到虚拟内存中）
- 它对应着一段连续的内存地址，起始位置为 0。
- 之所以说虚拟是因为这个起始的0地址是被虚拟出来的， 不是物理内存的 0地址。

虚拟地址空间的大小也由操作系统决定，`32位的操作系统虚拟地址空间的大小为` $2^{32}$ 字节，也就是`4G`，64位的操作系统虚拟地址空间大小为$2^{64}$ 字节，这是一个非常大的数，感兴趣可以自己计算一下。`当我们运行磁盘上一个可执行程序, 就会得到一个进程，内核会给每一个运行的进程创建一块属于自己的虚拟地址空间，并将应用程序数据装载到虚拟地址空间对应的地址上`。

进程在运行过程中，程序内部所有的指令都是通过CPU处理完成的，CPU只进行数据运算并不具备数据存储的能力，其处理的数据都加载自物理内存，那么进程中的数据是如何进出入到物理内存中的呢？其实是通过CPU中的内存管理单元MMU（Memory Management Unit）从进程的虚拟地址空间中映射过去的。

<img src="https://subingwen.cn/linux/file-descriptor/image-20210130092825532.png" alt="image.png" style="zoom:50%;" />

## 存在的意义
通过上边的介绍大家会感觉到一头雾水， 为什么操作系统不直接将数据加载到物理内存中而是将数据加载到虚拟地址空间中，在通过CPU的MMU映射到物理内存中呢？
先来看一下如果直接将数据加载到物理内存会发生什么事情：

<img src="https://subingwen.cn/linux/file-descriptor/image-20210130093119238.png" alt="image.png" style="zoom:50%;" />

> 假设计算机的物理内存大小为1G, 进程A需要100M内存因此直接在物理内存上从0地址开始分配100M, 进程B启动需要250M内存, 因此继续在物理内存上为其分配250M内存, 并且进程A和进程B占用的内存是连续的。之后再启动其他进程继续按照这种方法进行物理内存的分配。。。
> 使用这种方式分配内存会有如下几个问题：

1. <font color=#ff0000>每个进程的地址不隔离，有安全风险</font>。
	由于程序都是直接访问物理内存，所以恶意程序可以通过内存寻址随意修改别的进程对应的内存数据，以达到破坏的目的。虽然有些时候是非恶意的，但是有些存在 bug 的程序可能不小心修改了其它程序的内存数据，就会导致其它程序的运行出现异常。

2. <font color=#ff0000>内存效率低</font>。
	如果直接使用物理内存的话，一个进程对应的内存块就是作为一个整体操作的，如果出现物理内存不够用的时候，我们一般的办法是将不常用的进程拷贝到磁盘的交换分区（虚拟内存）中，以便腾出内存，因此就需要将整个进程一起拷走，如果数据量大，在内存和磁盘之间拷贝时间就会很长，效率低下。

3. <font color=#ff0000>进程中数据的地址不确定，每次都会发生变化</font>。
	由于物理内存的使用情况一直在动态的变化，我们无法确定内存现在使用到哪里了，如果直接将程序数据加载到物理内存，内存中每次存储数据的起始地址都是不一样的，这样数据的加载都需要使用相对地址，加载效率低（静态库是使用绝对地址加载的）。

> 有了虚拟地址空间之后就可以完美的解决上边提到的所有问题了，<font color=#ff0000>虚拟地址空间就是一个中间层，相当于在程序和物理内存之间设置了一个屏障，将二者隔离开来。程序中访问的内存地址不再是实际的物理内存地址，而是一个虚拟地址，然后由操作系统将这个虚拟地址映射到适当的物理内存地址上。</font>这样，只要操作系统处理好虚拟地址到物理内存地址的映射，就可以保证不同的程序最终访问的内存地址位于不同的区域，彼此没有重叠，就可以达到内存地址空间隔离的效果。

## 分区
从操作系统层级上看，虚拟地址空间主要分为两个部分`内核区`和`用户区`。

- 内核区：
	- 内核空间为内核保留，`不允许应用程序读写该区域的内容或直接调用内核代码定义的函数`。
	- 内核总是驻留在内存中，是操作系统的一部分。
	- <font color=#ff0000>系统中所有进程对应的虚拟地址空间的内核区都会映射到同一块物理内存上</font>（系统内核只有一个)
- 用户区：存储用户程序运行中用到的各种数据。
我们先来看一下进程对应的虚拟地址空间的各个分区，再来详细介绍用户区的组成（以32位系统的虚拟地址空间为例）。

<img src="https://subingwen.cn/linux/file-descriptor/image-20210130093015907.png" alt="image.png" style="zoom:50%;" />
每个进程的虚拟地址空间都是从0地址开始的，我们在程序中打印的变量地址也其在虚拟地址空间中的地址，程序是无法直接访问物理内存的。虚拟地址空间中用户区地址范围是 0~3G，里边分为多个区块：

- `保留区`: 位于虚拟地址空间的最底部，未赋予物理地址。任何对它的引用都是非法的，程序中的空指针（NULL）指向的就是这块内存地址。
- `.text段`: 代码段也称正文段或文本段，通常用于存放程序的执行代码(即CPU执行的机器指令)，代码段一般情况下是只读的，这是对执行代码的一种保护机制。
- `.rodata`段（只读数据段）:存储程序中的常量数据，如字符串字面量、const变量等。
- `.data段`: 数据段通常用于存放程序中已初始化且初值不为0的全局变量和静态变量。数据段属于静态内存分配(静态存储区)，可读可写。
- `.bss段`: 未初始化以及初始为0的全局变量和静态变量，操作系统会将这些未初始化变量初始化为0
- `堆(heap)`：用于存放进程运行时动态分配的内存。
	- 堆中内容是匿名的，不能按名字直接访问，只能通过指针间接访问。
	- 堆向**高地址扩展**(即“向上生长”)，是不连续的内存区域。这是由于系统用链表来存储空闲内存地址，自然不连续，而链表从低地址向高地址遍历。
- `内存映射区(mmap)`：作为内存映射区加载磁盘文件，或者加载程序运作过程中需要调用的动态库。
- `栈(stack)`: 存储函数内部声明的非静态局部变量，函数参数，函数返回地址等信息，栈内存由编译器自动分配释放。栈和堆相反地址“向下生长”，分配的内存是连续的。
- `命令行参数`：存储进程执行的时候传递给`main()`函数的参数，`argc，argv[]`
- `环境变量`: 存储和进程相关的环境变量, 比如: 工作路径, 进程所有者等信息


#c语言面试点 
从上面我们可以知道每一个进程的用户空间是**私有**的，但是内核空间是**共享**的！由于各个进行之前的用户区**隔离**，各进程之前不能直接通信
进程之间通信可以通过

1. [[C语言#管道|管道]]
2. [[C语言#内存映射|内存映射]]
3. [[C语言#共享内存|共享内存]]


# 文件描述符
## 文件描述符
在Linux操作系统中的一切都被抽象成了文件，那么一个打开的文件是如何与应用程序进行对应呢？解决方案是<font color=#ff0000>使用文件描述符（file descriptor，简称fd），当在进程中打开一个现有文件或者创建一个新文件时，内核向该进程返回一个文件描述符，用于对应这个打开/新建的文件</font>。这些文件描述符都存储在内核为每个进程维护的一个文件描述符表中。

在程序设计中，一些涉及底层的程序编写往往会围绕着文件描述符展开。但是文件描述符这一概念往往只适用于UNIX、Linux这样的操作系统。

> 在Linux系统中一切皆文件，系统中一切都被抽象成了文件。对这些文件的读写都需要通过文件描述符来完成。标准C库的文件IO函数使用的文件指针`FILE*`在Linux中也需要通过文件描述符的辅助才能完成读写操作。FILE其实是一个结构体，其内部有一个成员就是文件描述符（下面结构体的第25行）。


**FILE结构体在Linux头文件中的定义**

```c
// linux c FILE结构体定义： /usr/include/libio.h
struct _IO_FILE {
  int _flags;		/* High-order word is _IO_MAGIC; rest is flags. */
#define _IO_file_flags _flags
 
  /* The following pointers correspond to the C++ streambuf protocol. */
  /* Note:  Tk uses the _IO_read_ptr and _IO_read_end fields directly. */
  char* _IO_read_ptr;	/* Current read pointer */
  char* _IO_read_end;	/* End of get area. */
  char* _IO_read_base;	/* Start of putback+get area. */
  char* _IO_write_base;	/* Start of put area. */
  char* _IO_write_ptr;	/* Current put pointer. */
  char* _IO_write_end;	/* End of put area. */
  char* _IO_buf_base;	/* Start of reserve area. */
  char* _IO_buf_end;	/* End of reserve area. */
  /* The following fields are used to support backing up and undo. */
  char *_IO_save_base; /* Pointer to start of non-current get area. */
  char *_IO_backup_base;  /* Pointer to first valid character of backup area */
  char *_IO_save_end; /* Pointer to end of non-current get area. */
 
  struct _IO_marker *_markers;
 
  struct _IO_FILE *_chain;
 
  int _fileno;			// 文件描述符
#if 0
  int _blksize;
#else
  int _flags2;
#endif
  _IO_off_t _old_offset; /* This used to be _offset but it's too small.  */
 
#define __HAVE_COLUMN /* temporary */
  /* 1+column number of pbase(); 0 is unknown. */
  unsigned short _cur_column;
  signed char _vtable_offset;
  char _shortbuf[1];
 
  /*  char* _save_gptr;  char* _save_egptr; */
 
  _IO_lock_t *_lock;
#ifdef _IO_USE_OLD_IO_FILE
};

// 在文件: /usr/include/stdio.h
typedef struct _IO_FILE FILE;
```

## 文件描述符表
前面讲到启动一个进程就会得到一个对应的虚拟地址空间，这个虚拟地址空间分为两大部分，在内核区有专门用于进程管理的模块。Linux的进程控制块PCB（process control block）本质是一个叫做`task_struct`的结构体，里边包括管理进程所需的各种信息，其中有一个结构体叫做`file` ，我们将它叫做文件描述符表，里边有一个整形索引表,用于存储文件描述符。

内核为每一个进程维护了一个文件描述符表，索引表中的值都是从0开始的，所以在不同的进程中你会看到相同的文件描述符，但是它们指向的不一定是同一个磁盘文件。

<img src="https://subingwen.cn/linux/file-descriptor/image-20210130123339157.png" alt="image.png" style="zoom:50%;" />
> 知识小科普：
> Linux中用户操作的每个终端都被视作一个设备文件, 当前操作的终端文件可以使用 `/dev/tty`表示。

- **打开的最大文件数**
	每一个进程对应的文件描述符表能够存储的打开的文件数是有限制的, 默认为1024个，这个默认值是可以修改的，支持打开的最大文件数据取决于操作系统的硬件配置。

- **默认分配的文件描述符**
	当一个进程被启动之后，内核PCB的文件描述符表中就已经分配了三个文件描述符，这三个文件描述符对应的都是当前启动这个进程的终端文件（Linux中一切皆文件，终端就是一个设备文件，在 /dev 目录中）
	- `STDIN_FILENO`：标准输入，可以通过这个文件描述符将数据输入到终端文件中，宏值为0。
	- `STDOUT_FILENO`：标准输出，可以通过这个文件描述符将数据通过终端输出出来，宏值为1。
	- `STDERR_FILENO`：标准错误，可以通过这个文件描述符将错误信息通过终端输出出来，宏值为2。
这三个默认分配的文件描述符是可以通过`close()`函数关闭掉，但是关闭之后当前进程也就不能和当前终端进行输入或者输出的信息交互了。

- **给新打开的文件分配文件描述符**

- 因为进程启动之后，文件描述符表中的`0,1,2`就被分配出去了，因此从`3`开始分配
- 在进程中每打开一个文件，就会给这个文件分配一个新的文件描述符，比如：
	- 通过`open()`函数打开 `/hello.txt`，文件描述符 3 被分配给了这个文件，保持这个打开状态，再次通过`open()`函数打开 `/hello.txt`，文件描述符 4 被分配给了这个文件，也就是说一个进程中不同的文件描述符打开的磁盘文件可能是同一个。
	- 通过`open()`函数打开 `/hello.txt`，文件描述符 3 被分配给了这个文件，将打开的文件关闭，此时文件描述符3就被释放了。再次通过`open()`函数打开 `/hello.txt`，文件描述符 3 被分配给了这个文件，也就是说打开的新文件会关联文件描述符表中最小的没有被占用的文件描述符。



> [!summary] 总结:
> 1. 每个进程对应的文件描述符表默认支持打开的最大文件数为 1024，可以修改
> 2. 每个进程的文件描述符表中都已经默认分配了三个文件描述符，对应的都是当前终端文件（/dev/tty）
> 3. 每打开新的文件，内核会从进程的文件描述符表中找到一个空闲的没有别占用的文件描述符与其进行关联
> 4. 文件描述符表中不同的文件描述符可以对应同一个磁盘文件
> 5. 每个进程文件描述符表中的文件描述符值是唯一的，不会重复



# 函数调用堆栈过程


```c++
int sum(int a,int b){
  int temp=a+b; // mov eax,dword ptr[ebp+0Ch]
  return temp; // add eax, dword ptr[ebp+8] a+b
}
int main() {

  int a=10; // mov dword ptr[a], 0Ah
  int b=20; // mov dword ptr[b], 14h
  int ret=sum(a,b);// 一个函数的调用先压参数，从右向左压栈
  std::cout<<ret<<std::endl;
  return 0;
}
```

上述过程两个问题
1. sum函数调用之后怎么知道要返回哪里？
2. 返回main函数之后，怎么知道接着从上下文哪里开始？


**栈帧**：是在程序执行过程中，用于管理函数调用和返回的一种**数据结构**。每当一个函数被调用时，都会创建一个新的栈帧，用于存储该函数的局部变量、函数参数、返回地址等信息。

![[函数堆栈调用过程.excalidraw]]

详细执行过程注释

```c++
int sum(int a,int b){
  // 进入函数体的{}之前，push ebp; mov ebp, esp ebp指向栈底
  // sub esp 4Ch 为sum开辟栈帧空间 rep stos (for循环为栈帧初始化，就是那些0xCCCCCCCC)
  int temp=a+b; // mov eax,dword ptr[ebp+0Ch]
  return temp; // add eax, dword ptr[ebp+8] a+b
  // mov dword ptr[ebp-4], eax
  // mov eax, dword ptr[ebp-4]
  // mov esp, ebp 回退栈空间 相当于析构了，但是数据还在
  // pop ebp 这里面存的就是0x0018ff40 就回到main的栈底了
}

int main() {
   int a=10; // mov dword ptr[a], 0Ah
   int b=20; // mov dword ptr[b], 14h
   int ret=sum(a,b);// 一个函数的调用先压参数，从右向左压栈
   /*
    * mov eax, dword ptr [ebp-8]
    push eax
    mov eax, dword ptr [ebp-4]
    push eax
    call sum 做的第一件事是把call sum 的下一条指令的地址压栈
    0x08124458 add esp, 8
    */

   /*
    * ret 出栈 把出栈内容，放入到CPU的PC寄存器(就是PCB也就是下一条指令的地址)中 把0x08124458放入到PC寄存器中
    * add esp, 8 (esp归位)
    * mov dword ptr [ebp-0Ch], eax
    */
   std::cout<<"Sum is "<<ret<<std::endl;
  return 0;
}
```


# posix

POSIX：**可移植操作系统接口**（Portable Operating System Interface of UNIX，缩写为 POSIX ），
POSIX 涵盖了以下内容：**系统接口、命令和实用程序、网络文件访问**，这里仅举几例（POSIX 的内容远不止这些）
## 可移植性

Linux下对文件操作有两种方式：**系统调用**（system call）和**库函数调用**（Library functions）。

### 系统调用
系统调用是通向操作系统本身的接口，是面向底层硬件的。通过系统调用，可以使得用户态运行的进程与硬件设备(如CPU、磁盘、打印机等)进行交互，是操作系统留给应用程序的一个接口。

### 库函数
**库函数**（Library function）是把函数放到库里，供别人使用的一种方式。
方法是把一些常用到的函数编完放到一个文件里，供不同的人进行调用。一般放在.lib文件中。
库函数调用则是面向应用开发的，库函数可分为两类，
1. 一类是C语言标准规定的库函数，
2. 一类是编译器特定的库函数


### 库函数API和系统调用的区别

<img src="https://img-blog.csdnimg.cn/img_convert/3627aa2c666c38ddcb0f6f8f17281f41.png" alt="image.png" style="zoom:50%;" />

如上图所示：
- 库函数是语言或应用程序的一部分，而系统调用是内核提供给应用程序的接口，属于系统的一部分
- 库函数在用户地址空间执行，系统调用是在内核地址空间执行，库函数运行时间属于用户时间，系统调用属于系统时间，库函数开销较小，系统调用开销较大
- 系统调用依赖于平台，库函数并不依赖

<img src="https://img-blog.csdnimg.cn/img_convert/290fdca294f14cbea06fd35744b53dec.png" alt="image.png" style="zoom:50%;" />

系统调用是为了方便使用操作系统的接口，而库函数则是为了人们编程的方便。
库函数调用与系统无关，不同的系统，调用库函数，库函数会调用不同的底层函数实现，因此可移植性好。


# 字节对齐



# RCU核心原理

<img src="https://img-blog.csdnimg.cn/img_convert/c6583a7b885a76e56df852499cfdd246.png" alt="image.png" style="zoom:60%;" />

## 并行程序设计演进

如何正确有效的保护共享数据是编写并行程序必须面临的一个难题，通常的手段就是同步。同步可分为**阻塞型同步**（Blocking Synchronization）和非阻塞型同步（ Non-blocking Synchronization）。

阻塞型同步是指当一个线程到达临界区时，因另外一个线程已经持有访问该共享数据的锁，从而不能获取锁资源而阻塞（睡眠），直到另外一个线程释放锁。常见的同步原语有 mutex、semaphore 等。如果同步方案采用不当，就会造成死锁（deadlock），活锁（livelock）和优先级反转（priority inversion），以及效率低下等现象。

为了降低风险程度和提高程序运行效率，业界提出了不采用锁的同步方案，依照这种设计思路设计的算法称为非阻塞型同步，其本质就是停止一个线程的执行不会阻碍系统中其他执行实体的运行。


### 先有阻塞型同步

互斥锁（英語：Mutual exclusion，缩写Mutex）是一种用于多线程编程中，防止两条线程同时对同一公共资源进行读写的机制。该目的通过将代码切片成一个一个的临界区域（critical p）达成。临界区域指的是一块对公共资源进行存取的代码。

信号量(Semaphore)，是在多线程环境下使用的一种设施，是可以用来保证两个或多个关键代码段不被并发调用，可以认为mutex是0-1信号量；

读写锁是计算机程序的并发控制的一种同步机制，它把对共享资源的访问者划分成读者和写者，读者只对共享资源进行读访问，写者则需要对共享资源进行写操作，读操作可并发重入，写操作是互斥的。


### 非阻塞型同步

当今比较流行的非阻塞型同步实现方案有三种：

1. Wait-free（无等待）
	Wait-free 是指任意线程的任何操作都可以在有限步之内结束，而不用关心其它线程的执行速度。Wait-free 是基于 per-thread 的，可以认为是 starvation-free 的。非常遗憾的是实际情况并非如此，采用 Wait-free 的程序并不能保证 starvation-free，同时内存消耗也随线程数量而线性增长。目前只有极少数的非阻塞算法实现了这一点。

	简单理解：任意时刻所有的线程都在干活；

2. Lock-free（无锁）

	Lock-Free是指能够确保执行它的所有线程中至少有一个能够继续往下执行。由于每个线程不是 starvation-free 的，即有些线程可能会被任意地延迟，然而在每一步都至少有一个线程能够往下执行，因此系统作为一个整体是在持续执行的，可以认为是 system-wide 的。所有 Wait-free 的算法都是 Lock-Free 的。

	简单理解：任意时刻至少一个线程在干活；

3. Obstruction-free（无障碍）

	Obstruction-free 是指在任何时间点，一个孤立运行线程的每一个操作可以在有限步之内结束。只要没有竞争，线程就可以持续运行。一旦共享数据被修改，Obstruction-free 要求中止已经完成的部分操作，并进行回滚。所有 Lock-Free 的算法都是 Obstruction-free 的。
	
	简单理解：只要数据有修改，就会重新获取，并且把已经完成操作回滚重来；


**lock-free（无锁）** 往往可以提供更好的性能和伸缩性保证，但实际上其优点不止于此。早期这些概念首先是在操作系统上应用的，因为一个不依赖于锁的算法，可以应用于各种场景下，而无需考虑各种错误，故障，失败等情形。比如死锁，中断，甚至CPU失效。

### 主流无锁技术

Atomic operation（原子操作），在单一、不间断的步骤中读取和更改数据的操作。需要处理器指令支持原子操作：

- test-and-set (TSR)
- compare-and-swap (CAS)
- load-link/store-conditional (ll/sc)

Spin Lock（自旋锁）是一种轻量级的同步方法，一种非阻塞锁。当lock操作被阻塞时，并不是把自己挂到一个等待队列，而是死循环CPU空转等待其他线程释放锁。

<img src="https://img-blog.csdnimg.cn/img_convert/4126f63db82618bcbb25494a64f78182.png" alt="image.png" style="zoom:60%;" />

Seqlock (顺序锁) 是Linux 2.6 内核中引入一种新型锁，它与 spin lock 读写锁非常相似，只是它为写者赋予了较高的优先级。也就是说，即使读者正在读的时候也允许写者继续运行，读者会检查数据是否有更新，如果数据有更新就会重试，因为 seqlock 对写者更有利，只要没有其他写者，写锁总能获取成功。

<img src="https://img-blog.csdnimg.cn/img_convert/d973aeab30a7b8a7ebe9b1bea5012660.png" alt="image.png" style="zoom:60%;" />


RCU(Read-Copy Update)，顾名思义就是读-拷贝修改，它是基于其原理命名的。对于被RCU保护的共享数据结构，读者不需要获得任何锁就可以访问它，但写者在访问它时首先**拷贝一个副本**，然后对副本进行修改，最后使用一个**回调**（callback）机制在适当的时机把指**向原来数据的指针替换为新的被修改的数据**。这个时机就是所有引用该数据的CPU都退出对共享数据的访问。

本文主要讲解RCU的核心原理。


## 历史背景
高性能并行程序中，数据一致性访问是一个非常重要的部分，一般都是采用锁机制（semaphore、spinlock、rwlock等）进行保护共享数据，根本的思想就是在访问临界资源时，首先访问一个全局的变量（锁），通过全局变量的状态来控制线程对临界资源的访问。但是，这种思想是**需要硬件支持**的，硬件需要配合实现全局变量（锁）的读-修改-写，现代CPU都会提供这样的原子化指令。

采用锁机制实现数据访问的一致性存在如下两个问题：

- **效率问题**。锁机制的实现需要对内存的原子化访问，这种访问操作会**破坏流水线操作**，降低了流水线效率，这是影响性能的一个因素。另外，在采用读写锁机制的情况下，写锁是排他锁，无法实现写锁与读锁的并发操作，在某些应用下会降低性能。
- **扩展性问题**。例如，当系统中CPU数量增多的时候，采用锁机制实现数据的同步访问效率偏低。并且随着CPU数量的增多，效率降低，由此可见锁机制实现的数据一致性访问扩展性差。

### 原始的RCU思想

在多线程场景下，经常我们需要并发访问一个数据结构，为了保证线程安全我们会考虑使用互斥设施来进行同步，更进一步我们会根据对这个数据结构的读写比例而选用读写锁进行优化。但是读写锁不是唯一的方式，我们可以借助于**COW**技术来做到写操作不需要加锁，也就是在读的时候正常读，写的时候，先加锁拷贝一份，然后进行写，写完就原子的更新回去，使用COW实现避免了频繁加读写锁本身的性能开销。

**优缺点**

由于 RCU 旨在最小化读取端开销，因此仅在以更高速率使用同步逻辑进行读取操作时才使用它。如果更新操作超过10%，性能反而会变差，所以应该选择另一种同步方式而不是RCU。

- 好处
	- 几乎没有读取端开销。零等待，零开销
	- 没有死锁问题
	- 没有优先级倒置问题（优先级倒置和优先级继承）
	- 无限制延迟没有问题
	- 无内存泄漏风险问题

- 缺点
	- 使用起来有点复杂
	- 对于写操作，它比其他同步技术稍慢
适用场景

<img src="https://img-blog.csdnimg.cn/img_convert/877d2627d700c2c0f2de93caa331bf42.png" alt="image.png" style="zoom:60%;" />


## 核心原理
理论基础-QSBR算法

(Quiescent State-Based Reclamation)

这个算法的核心思想就是识别出线程的不活动(quiescent)状态，那么什么时候才算是不活动的状态呢？这个状态和临界区状态是相对的，线程离开临界区就是不活动的状态了。识别出不活动状态了，还需要把状态通知出去，让其他线程知道，这整个过程可以用下面的图来描述:

<img src="https://img-blog.csdnimg.cn/img_convert/d76efc79a1ceac5d02b0866e83feaf8e.png" alt="image.png" style="zoom:60%;" />

上面有四个线程，线程1执行完更新操作后添加了释放内存的callback，此时线程2,3,4都读取的是之前的内容，等他们执行完成后分别回去调用onQuiescentState来表明自己已经不不活动了，等到最后一个线程调用onQuiescentState的时候就可以去调用注册的callback了。要实现上面这个过程其要点就是选择适合的位置执行onQuiescentState，还有就是如何知道谁是最后一个执行onQuiescentState的线程。

<img src="https://img-blog.csdnimg.cn/img_convert/f90b889763cd00f93fb36a217b070e5a.png" alt="image.png" style="zoom:60%;" />

**批量回收**，如果更新的次数比较多的话，但是每次只回调一个callback，释放一次内存就会导致内存释放跟不上回收的速度，为此需要进行批量回收，每次更新都会注册新的callback，当第一次所有的线程都进入不活动状态的时候就把当前的所有callback保存起来，等待下一次所有线程进入不活动的状态的时候就回调前一次所有的callback。

**基本架构**
Linux 内核RCU 参考QSBR算法设计一套无锁同步机制。

<img src="https://img-blog.csdnimg.cn/img_convert/19669ffe143e63130eefa4de951c44bf.png" alt="image.png" style="zoom:60%;" />

- 多个读者可以并发访问共享数据，而不需要加锁；
- 写者更新共享数据时候，需要先copy副本，在副本上修改，最终，读者只访问原始数据，因此他们可以安全地访问数据，多个写者之间是需要用锁互斥访问的（比如用自旋锁）；
- 修改资源后，需要更新共享资源，让后面读者可以访问最新的数据；
- 等旧资源上所有的读者都访问完毕后，就可以回收旧资源了；

## RCU 模型

<img src="https://img-blog.csdnimg.cn/img_convert/6373a3c02e2cbaaa572822a6ebf6a347.png" alt="image.png" style="zoom:60%;" />

- Removal：在写端临界区部分，读取（Read()），进行复制（Copy），并执行更改（Update）操作；
- Grace Period：这是一个等待期，以确保所有与执行删除的数据相关的reader访问完毕；
- Reclamation：回收旧数据；

三个重要概念

静止状态QS(Quiescent State): CPU发生了上下文切换称为经历一个quiescent state；

<img src="https://img-blog.csdnimg.cn/img_convert/e682c5ce36010358ffebdb09ad445b6d.png" alt="image.png" style="zoom:60%;" />

宽限期GP(Grace Period): grace period就是所有CPU都经历一次quiescent state所需要的等待的时间，也即系统中所有的读者完成对共享临界区的访问；

<img src="https://img-blog.csdnimg.cn/img_convert/bf90dc8e364819c8e94cd8b4e66c2100.png" alt="image.png" style="zoom:60%;" />

**读侧临界部分RCS(Read-Side Critical Section):** 保护禁止其他CPU修改的代码区域，但允许多个CPU同时读；

<img src="https://img-blog.csdnimg.cn/img_convert/2fc2a1753f728a43203b86f191e40eb6.png" alt="image.png" style="zoom:60%;" />

三个主要的角色


<img src="https://img-blog.csdnimg.cn/img_convert/cf46959d14ce028ef6de2991fd71b8f7.png" alt="image.png" style="zoom:70%;" />

- 读者reader：
	- 安全访问临界区资源；
	- 负责标识进出临界区；
- 写者updater：
	- 复制一份数据，然后更新数据；
	- 用新数据覆盖旧数据，然后进入grace period；
- 回收者reclaimer：
	- 等待在grace period之前的读者退出临界区；
	- 在宽限期结束后，负责回收旧资源；



### 三个重要机制
发布/订阅机制
- 主要用于更新数据，即使在数据被同时修改时线程也能安全浏览数据。RCU通过发布-订阅机制（Publish-Subscribe Mechanism）实现这种并发的插入操作能力；
延迟回收机制：
- 实现检查旧数据上所有RCU读者完成，用于安全删除旧数据；
多版本机制：
- 维护最近更新对象的多个版本，用于允许读者容忍并发的插入和删除新对象的多个版本；

<img src="https://img-blog.csdnimg.cn/img_convert/2fc59061cb60716cec88d3e25a06f1df.png" alt="image.png" style="zoom:60%;" />



最后总结
最后，总结一下RCU锁的核心思想：
- 读者无锁访问数据，标记进出临界区；
- 写者读取，复制，更新；
- 旧数据延迟回收；
RCU核心思想就三句话，产品经理都说简单，但Linux内核实现却不是这么简单。除了要实现基本功能，需要考虑很多复杂情况：

<img src="https://img-blog.csdnimg.cn/img_convert/b059ffae4e8463cf3ea768f93a9f6d87.png" alt="image.png" style="zoom:60%;" />

内核的RCU系统可以说是内核最复杂系统之一，为了高性能和多核扩展性，设计了非常精巧的数据结构：

<img src="https://img-blog.csdnimg.cn/img_convert/8e51983789eab7eb8bf5af1f0e310fc6.png" alt="image.png" style="zoom:60%;" />

同时巧妙实现了很多核心流程：
- 检查当前CPU是否度过QS；
- QS report(汇报宽限期度过)；
- 宽限期的发起与完成；
- rcu callbacks处理；
其中很多实现都可以说是非常精巧，结合了预处理，批量处理，延后（异步）处理，多核并发，原子操作，异常处理，多场景精细优化等多种技术，性能好，可扩展性强，稳定性强，有一定的学习和参考价值，即使你的工作不是内核编程，里面体现很多编程思想和代码设计思想，也是值得大家学习的。

