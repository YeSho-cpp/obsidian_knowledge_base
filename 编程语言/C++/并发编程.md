

## 线程基础

### 线程发起

线程发起顾名思义就是启动一个线程,C++11标准统一了线程操作,可以在定义一个线程变量后,该变量启动线程执行回调逻辑。如下即可发起一个线程

```c++
void thead_work1(std::string str) {
    std::cout << "str is " << str << std::endl;
}
//1 通过()初始化并启动一个线程
std::thread t1(thead_work1, hellostr);
```


### 线程等待
当我们启动一个线程后,线程可能没有立即执行,如果在局部作用域启动了一个线程,或者main函数中,很可能子线程没运行就被回收了,回收时会调用线程的析构函数,执行terminate操作。所以为了防止主线程退出或者局部作用域结束导致子线程被析构的情况,我们可以通过join,让主线程等待子线程启动运行,子线程运行结束后主线程再运行。

```c++
std::string hellostr = "hello world!";
//1 通过()初始化并启动一个线程
std::thread t1(thead_work1, hellostr);
//2 主线程等待子线程退出
t1.join();
```

### 仿函数作为参数
当我们用仿函数作为参数传递给线程时,也可以达到启动线程执行某种操作的含义

```c++
class background_task {
public:
    void operator()(std::string str) {
        std::cout << "str is " << str << std::endl;
    }
};
```

如果采用如下方式启动函数,那一定会报错的。
```c++
std::thread t2(background_task());
t2.join();
```

编译器错误地将 `std::thread t2(background_task())` 解析为一个函数声明,而不是创建一个 `std::thread` 对象。 函数的参数为一个函数指针,该函数指针返回值为`background_task`, 参数为void。可以理解为如下

```
"std::thread (*)(background_task (*)())"
```

修改的方式很简单

```c++
//可多加一层()
std::thread t2((background_task()));
t2.join();
//可使用{}方式初始化
std::thread t3{ background_task() };
t3.join();
```

### lambda表达式
lambda 表达式也可以作为线程的参数传递给thread

```c++
std::thread t4([](std::string  str) {
    std::cout << "str is " << str << std::endl;
},  hellostr);
t4.join();
```

### 线程detach
线程允许采用分离的方式在后台独自运行,C++ concurrent programing书中称其为守护线程。

```c++
struct func {
    int& _i;
    func(int & i): _i(i){}
    void operator()() {
        for (int i = 0; i < 3; i++) {
            _i = i;
            std::cout << "_i is " << _i << std::endl;
            std::this_thread::sleep_for(std::chrono::seconds(1));
        }
    }
};
void oops() {
        int some_local_state = 0;
        func myfunc(some_local_state);
        std::thread functhread(myfunc);
        //隐患,访问局部变量,局部变量可能会随着}结束而回收或随着主线程退出而回收
        functhread.detach();    
}
// detach 注意事项
oops();
//防止主线程退出过快,需要停顿一下,让子线程跑起来detach
std::this_thread::sleep_for(std::chrono::seconds(1));
```

上面的例子存在隐患,因为`some_local_state`是局部变量, 当oops调用结束后局部变量`some_local_state`就可能被释放了,而线程还在detach后台运行,容易出现崩溃。
所以当我们在线程中使用局部变量的时候可以采取几个措施解决局部变量的问题
- 通过智能指针传递参数,因为引用计数会随着赋值增加,可保证局部变量在使用期间不被释放,这也就是我们之前提到的伪闭包策略。
- 将局部变量的值作为参数传递,这么做需要局部变量有拷贝复制的功能,而且拷贝耗费空间和效率。
- 将线程运行的方式修改为join,这样能保证局部变量被释放前线程已经运行结束。但是这么做可能会影响运行逻辑。
比如下面的修改

```c++
void use_join() {
    int some_local_state = 0;
    func myfunc(some_local_state);
    std::thread functhread(myfunc);
    functhread.join();
}
// join 用法
use_join();
```

### 异常处理
当我们启动一个线程后,如果主线程产生崩溃,会导致子线程也会异常退出,就是调用`terminate`,如果子线程在进行一些重要的操作比如将充值信息入库等,丢失这些信息是很危险的。所以常用的做法是捕获异常,并且在异常情况下保证子线程稳定运行结束后,主线程抛出异常结束运行。如下面的逻辑

```c++
void catch_exception() {
    int some_local_state = 0;
    func myfunc(some_local_state);
    std::thread  functhread{ myfunc };
    try {
        //本线程做一些事情,可能引发崩溃
        std::this_thread::sleep_for(std::chrono::seconds(1));
    }catch (std::exception& e) {
        functhread.join();
        throw;
    }
    functhread.join();
}
```

但是用这种方式编码,会显得臃肿,可以采用RAII技术,保证线程对象析构的时候等待线程运行结束,回收资源。如果大家还记得我基于asio实现异步服务时,逻辑处理类`LogicSystem`的析构函数里等待线程退出。那我们写一个简单的线程守卫

```c++
class thread_guard {
private:
    std::thread& _t;
public:
    explicit thread_guard(std::thread& t):_t(t){}
    ~thread_guard() {
        //join只能调用一次
        if (_t.joinable()) {
            _t.join();
        }
    }
    thread_guard(thread_guard const&) = delete;
    thread_guard& operator=(thread_guard const&) = delete;
};
```

可以这么使用

```c++
void auto_guard() {
    int some_local_state = 0;
    func my_func(some_local_state);
    std::thread  t(my_func);
    thread_guard g(t);
    //本线程做一些事情
    std::cout << "auto guard finished " << std::endl;
}
auto_guard();
```

慎用隐式转换
C++中会有一些隐式转换,比如`char*` 转换为`string`等。这些隐式转换在线程的调用上可能会造成崩溃问题

```c++
void danger_oops(int som_param) {
    char buffer[1024];
    sprintf(buffer, "%i", som_param);
    //在线程内部将char const* 转化为std::string
    //指针常量  char * const  指针本身不能变
    //常量指针  const char * 指向的内容不能变
    std::thread t(print_str, 3, buffer);
    t.detach();
    std::cout << "danger oops finished " << std::endl;
}
```


当我们定义一个线程变量`thread t`时,传递给这个线程的参数`buffer`会被保存到thread的成员变量中。
而在线程对象t内部启动并运行线程时,参数才会被传递给调用函数`print_str`。
而此时`buffer`可能随着`}`运行结束而释放了。
改进的方式很简单,我们将参数传递给`thread`时显示转换为`string`就可以了,
这样`thread`内部保存的是`string`类型。
```c++
void safe_oops(int some_param) {
    char buffer[1024];
    sprintf(buffer, "%i", some_param);
    std::thread t(print_str, 3, std::string(buffer));
    t.detach();
}
```

关于为什么参数会像我说的这样保存和调用,我在之后会按照源码给大家讲一讲。

### 引用参数

当线程要调用的回调函数参数为引用类型时,需要将参数显示转化为引用对象传递给线程的构造函数,  
如果采用如下调用会编译失败

```c++
void change_param(int& param) {
    param++;
}
void ref_oops(int some_param) {
    std::cout << "before change , param is " << some_param << std::endl;
    //需使用引用显示转换
    std::thread  t2(change_param, some_param);
    t2.join();
    std::cout << "after change , param is " << some_param << std::endl;
}
```

即使函数`change_param`的参数为`int&`类型,我们传递给t2的构造函数为`some_param`,也不会达到在`change_param`函数内部修改关联到外部`some_param`的效果。因为`some_param`在传递给`thread`的构造函数后会转变为右值保存,右值传递给一个左值引用会出问题,所以编译出了问题。  
改为如下调用就可以了

```c++
void ref_oops(int some_param) {
    std::cout << "before change , param is " << some_param << std::endl;
    //需使用引用显示转换
    std::thread  t2(change_param, std::ref(some_param));
    t2.join();
    std::cout << "after change , param is " << some_param << std::endl;
}
```


### 绑定类成员函数

有时候我们需要绑定一个类的成员函数

```c++
class X
{
public:
    void do_lengthy_work() {
        std::cout << "do_lengthy_work " << std::endl;
    }
};
void bind_class_oops() {
    X my_x;
    std::thread t(&X::do_lengthy_work, &my_x);
    t.join();
}
```

这里大家注意一下,如果thread绑定的回调函数是普通函数,可以在函数前加`&`或者不加`&`,因为编译器默认将普通函数名作为函数地址,如下两种写法都正确
```c++
void thead_work1(std::string str) {
    std::cout << "str is " << str << std::endl;
}
std::string hellostr = "hello world!";
//两种方式都正确
std::thread t1(thead_work1, hellostr);
std::thread t2(&thead_work1, hellostr);
```

但是如果是绑定类的成员函数,必须添加`&`

### 使用move操作
有时候传递给线程的参数是独占的,所谓独占就是不支持拷贝赋值和构造,但是我们可以通过`std::move`的方式将参数的所有权转移给线程,如下

```c++
void deal_unique(std::unique_ptr<int> p) {
    std::cout << "unique ptr data is " << *p << std::endl;
    (*p)++;
    std::cout << "after unique ptr data is " << *p << std::endl;
}
void move_oops() {
    auto p = std::make_unique<int>(100);
    std::thread  t(deal_unique, std::move(p));
    t.join();
    //不能再使用p了,p已经被move废弃
   // std::cout << "after unique ptr data is " << *p << std::endl;
}
```



## 线程管控

### 线程归属权
我们之前介绍了线程可以通过detach在后台运行或者让开辟这个线程的父线程等待该线程完成。
但每个线程都应该有其归属权,也就是归属给某个变量管理。比如

```c++
void some_function() {}
std::thread t1(some_function);
```

t1是一个线程变量,管理一个线程,该线程执行`some_function()`
对于`std::thread C++` 不允许其执行拷贝构造和拷贝赋值, 所以只能通过移动和局部变量返回的方式将线程变量管理的线程转移给其他变量管理。
C++ 中类似的类型还有`std::mutex, std::ifstream, std::unique_ptr`。
比如下面,我们说明了线程归属权的转移方式

```c++
void some_function() {
    while (true) {
        std::this_thread::sleep_for(std::chrono::seconds(1));
    }
}
void some_other_function() {
    while (true) {
        std::this_thread::sleep_for(std::chrono::seconds(1));
    }
}
//t1 绑定some_function
std::thread t1(some_function); 
//2 转移t1管理的线程给t2,转移后t1无效
std::thread t2 =  std::move(t1);
//3 t1 可继续绑定其他线程,执行some_other_function
t1 = std::thread(some_other_function);
//4  创建一个线程变量t3
std::thread t3;
//5  转移t2管理的线程给t3
t3 = std::move(t2);
//6  转移t3管理的线程给t1
t1 = std::move(t3);
std::this_thread::sleep_for(std::chrono::seconds(2000));
```

上面的代码会引发崩溃,是因为步骤6造成的崩溃。  
让主函数睡眠2000秒,是为了告诉规避主函数退出引发崩溃的问题,因为我们在之前给大家演示过,如果线程不detach或者join,主线程退出时会引发崩溃,而我们这些线程没有join和detach,为了给大家演示是因为步骤6引发的崩溃,所以让主线程睡眠2000秒暂时不退出,但是程序仍然会崩溃,说明是步骤6导致的崩溃。

上面代码将t2管理的线程交给t3  
之后将t3管理的线程交给t1,此时t1管理线程运行着 `some_function`  
步骤6导致崩溃的原因就是将t3管理的线程交给t1,而此时t1正在管理线程运行`some_other_function`。  
所以我们可以得出一个结论,就是不要将一个线程的管理权交给一个已经绑定线程的变量,否则会触发线程的terminate函数引发崩溃。

和`std::unique_ptr`一样,我们可以在函数内部返回一个局部的`std::thread`变量。如下:

```c++
std::thread  f() {
    return std::thread(some_function);
}
void param_function(int a) {
    while (true) {
        std::this_thread::sleep_for(std::chrono::seconds(1));
    }
}
std::thread g() {
    std::thread t(param_function, 43);
}
```

因为C++ 在返回局部变量时,会优先寻找这个类的拷贝构造函数,如果没有就会使用这个类的移动构造函数。

### joining_thread
曾经有一份C++17标准的备选提案,主张引入新的类joining_thread,它与std::thread类似,但只要其执行析构函数,线程即能自动汇合,这点与scoped_thread非常像。可惜C++标准委员会未能达成共识,结果C++17标准没有引入这个类,后来它改名为`std::jthread`,依然进入了C++20标准的议程(现已被正式纳入C++20标准)。除去这些,实际上`joining_thread`类的代码相对容易编写

```c++
class joining_thread {
    std::thread  _t;
public:
    joining_thread() noexcept = default;
    template<typename Callable, typename ...  Args>
    explicit  joining_thread(Callable&& func, Args&& ...args):
        t(std::forward<Callable>(func),  std::forward<Args>(args)...){}
    explicit joining_thread(std::thread  t) noexcept: _t(std::move(t)){}
    joining_thread(joining_thread&& other) noexcept: _t(std::move(other._t)){}
    joining_thread& operator=(joining_thread&& other) noexcept
    {
        //如果当前线程可汇合,则汇合等待线程完成再赋值
        if (joinable()) {
            join();
        }
        _t = std::move(other._t);
        return *this;
    }
    joining_thread& operator=(joining_thread other) noexcept
    {
        //如果当前线程可汇合,则汇合等待线程完成再赋值
        if (joinable()) {
            join();
        }
        _t = std::move(other._t);
        return *this;
    }
    ~joining_thread() noexcept {
        if (joinable()) {
            join();
        }
    }
    void swap(joining_thread& other) noexcept {
        _t.swap(other._t);
    }
    std::thread::id   get_id() const noexcept {
        return _t.get_id();
    }
    bool joinable() const noexcept {
        return _t.joinable();
    }
    void join() {
        _t.join();
    }
    void detach() {
        _t.detach();
    }
    std::thread& as_thread() noexcept {
        return _t;
    }
    const std::thread& as_thread() const noexcept {
        return _t;
    }
};
```

使用起来比较简单,我们直接构造一个`joining_thread`对象即可。

```c++
void use_jointhread() {
    //1 根据线程构造函数构造joiningthread
    joining_thread j1([](int maxindex) {
        for (int i = 0; i < maxindex; i++) {
            std::cout << "in thread id " << std::this_thread::get_id()
                << " cur index is " << i << std::endl;
            std::this_thread::sleep_for(std::chrono::seconds(1));
        }
        }, 10);
    //2 根据thread构造joiningthread
    joining_thread j2(std::thread([](int maxindex) {
        for (int i = 0; i < maxindex; i++) {
            std::cout << "in thread id " << std::this_thread::get_id()
                << " cur index is " << i << std::endl;
            std::this_thread::sleep_for(std::chrono::seconds(1));
        }
        }, 10));
    //3 根据thread构造j3
    joining_thread j3(std::thread([](int maxindex) {
        for (int i = 0; i < maxindex; i++) {
            std::cout << "in thread id " << std::this_thread::get_id()
                << " cur index is " << i << std::endl;
            std::this_thread::sleep_for(std::chrono::seconds(1));
        }
        }, 10));
    //4 把j3赋值给j1,joining_thread内部会等待j1汇合结束后
    //再将j3赋值给j1
    j1 = std::move(j3);
ervice
}

```

### 容器存储
容器存储线程时,比如vector,如果用push_back操作势必会调用`std::thread`,这样会引发编译错误,因为`std::thread`没有拷贝构造函数。我们在之前网络编程实现`IOServicePool`或者`IOThreadPool`时初始化了多个线程存储在vector中, 采用的时emplace方式,可以直接根据线程构造函数需要的参数构造,这样就避免了调用thread的拷贝构造函数。 类似于这种

```c++
void use_vector() {
    std::vector<std::thread> threads;
    for (unsigned i = 0; i < 10; ++i) {
        threads.emplace_back(param_function, i);
    }
    for (auto& entry : threads) {
        entry.join();
    }
}
```

### 选择运行数量
借用C++标准库的`std::thread::hardware_concurrency()`函数,它的返回值是一个指标,表示程序在各次运行中可真正并发的线程数量.
我们可以模拟实现一个并行计算的功能,计算容器内所有元素的和

```c++
template<typename Iterator, typename T>
T parallel_accumulate(Iterator first, Iterator last, T init)
{
    unsigned long const length = std::distance(first, last);
    if (!length)
        return init;    //⇽-- - ①
        unsigned long const min_per_thread = 25;
    unsigned long const max_threads =
        (length + min_per_thread - 1) / min_per_thread;    //⇽-- - ②
        unsigned long const hardware_threads =
        std::thread::hardware_concurrency();
    unsigned long const num_threads =
        std::min(hardware_threads != 0 ? hardware_threads : 2, max_threads);    //⇽-- - ③
        unsigned long const block_size = length / num_threads;    //⇽-- - ④
        std::vector<T> results(num_threads);
    std::vector<std::thread>  threads(num_threads - 1);   // ⇽-- - ⑤
        Iterator block_start = first;
    for (unsigned long i = 0; i < (num_threads - 1); ++i)
    {
        Iterator block_end = block_start;
        std::advance(block_end, block_size);    //⇽-- - ⑥
            threads[i] = std::thread(//⇽-- - ⑦
                accumulate_block<Iterator, T>(),
                block_start, block_end, std::ref(results[i]));
        block_start = block_end;    //⇽-- - ⑧
    }
    accumulate_block<Iterator, T>()(
        block_start, last, results[num_threads - 1]);    //⇽-- - ⑨
        for (auto& entry : threads)
            entry.join();    //⇽-- - ⑩
            return std::accumulate(results.begin(), results.end(), init);    //⇽-- - ⑪
}
void use_parallel_acc() {
    std::vector <int> vec(10000);
    for (int i = 0; i < 10000; i++) {
        vec.push_back(i);
    }
    int sum = 0;
    sum = parallel_accumulate<std::vector<int>::iterator, int>(vec.begin(), 
        vec.end(), sum);
    std::cout << "sum is " << sum << std::endl;
}
```

上面的代码1处判断要计算的容器内元素为0个则返回。
2处计算最大开辟的线程数,我们预估每个线程计算25个数据长度。
但是我们可以通过`std::thread::hardware_concurrency`返回cpu的核数,我们期待的是开辟的线程数小于等于cpu核数,这样才不会造成线程过多时间片切换开销。
所以3处计算了适合开辟线程数的最小值。
4处计算了步长,根据步长移动迭代器然后开辟线程计算。
5处初始化了线程数-1个大小的vector,因为主线程也参与计算,所以这里-1.
6处移动步长,7处开辟线程,8处更新起始位置。
9处为主线程计算。
10 处让所有线程join
11 处最后将所有计算结果再次调用std的accumulate算出结果。

### 识别线程

所谓识别线程就是获取线程id,可以根据线程id是否相同判断是否同一个线程。  
比如我们启动了一个线程,我们可以通过线程变量的`get_id()`获取线程id

```c++
std::thread t([](){
    std::cout << "thread start" << std::endl;
});
t.get_id();
```

但是如果我们想在线程的运行函数中区分线程,或者判断哪些是主线程或者子线程,可以通过这总方式

```c++
std::thread t([](){
    std::cout << "in thread id " << 
    std::this_thread::get_id() << std::endl;
    std::cout << "thread start" << std::endl;
});
```

## 互斥与死锁

### 锁的使用
我们可以通过mutex对共享数据进行夹所,防止多线程访问共享区造成数据不一致问题。如下,我们初始化一个共享变量shared_data,然后定义了一个互斥量std::mutex,接下来启动了两个线程,分别执行use_lock增加数据,和一个lambda表达式减少数据。
结果可以看到两个线程对于共享数据的访问是独占的,单位时间片只有一个线程访问并输出日志。

```c++
std::mutex  mtx1;
int shared_data = 100;
void use_lock() {
    while (true) {
        mtx1.lock();
        shared_data++;
        std::cout << "current thread is " << std::this_thread::get_id() << std::endl;
        std::cout << "sharad data is " << shared_data << std::endl;
        mtx1.unlock();
        std::this_thread::sleep_for(std::chrono::microseconds(10));
    }
}
void test_lock() {
    std::thread t1(use_lock);
    std::thread t2([]() {
        while (true) {
            mtx1.lock();
            shared_data--;
            std::cout << "current thread is " << std::this_thread::get_id() << std::endl;
            std::cout << "sharad data is " << shared_data << std::endl;
            mtx1.unlock();
            std::this_thread::sleep_for(std::chrono::microseconds(10));
        }
        });
    t1.join();
    t2.join();
}
```

### lock_guard的使用

当然我们可以用`lock_guard`自动加锁和解锁,比如上面的函数可以等价简化为

```c++
void use_lock() {
    while (true) {
        std::lock_guard<std::mutex> lock(mtx1);
        shared_data++;
        std::cout << "current thread is " << std::this_thread::get_id() << std::endl;
        std::cout << "sharad data is " << shared_data << std::endl;
        std::this_thread::sleep_for(std::chrono::microseconds(10));
    }
}
```

`lock_guard`在作用域结束时自动调用其析构函数解锁,这么做的一个好处是简化了一些特殊情况从函数中返回的写法,比如异常或者条件不满足时,函数内部直接return,锁也会自动解开。

### 如何保证数据安全

有时候我们可以将对共享数据的访问和修改聚合到一个函数,在函数内加锁保证数据的安全性。但是对于读取类型的操作,即使读取函数是线程安全的,但是返回值抛给外边使用,存在不安全性。比如一个栈对象,我们要保证其在多线程访问的时候是安全的,可以在判断栈是否为空,判断操作内部我们可以加锁,但是判断结束后返回值就不在加锁了,就会存在线程安全问题。

比如我定义了如下栈, 对于多线程访问时判断栈是否为空,此后两个线程同时出栈,可能会造成崩溃。

```c++
template<typename T>
class threadsafe_stack1
{
private:
    std::stack<T> data;
    mutable std::mutex m;
public:
    threadsafe_stack1() {}
    threadsafe_stack1(const threadsafe_stack1& other)
    {
        std::lock_guard<std::mutex> lock(other.m);
        //①在构造函数的函数体(constructor body)内进行复制操作
        data = other.data;
    }
    threadsafe_stack1& operator=(const threadsafe_stack1&) = delete;
    void push(T new_value)
    {
        std::lock_guard<std::mutex> lock(m);
        data.push(std::move(new_value));
    }
    //问题代码
    T pop()
    {
        std::lock_guard<std::mutex> lock(m);
        auto element = data.top();
        data.pop();
        return element;
    }
    bool empty() const
    {
        std::lock_guard<std::mutex> lock(m);
        return data.empty();
    }
};
```

如下, 线程1和线程2先后判断栈都不为空,之后执行出战操作,会造成崩溃。

```c++
void test_threadsafe_stack1() {
    threadsafe_stack1<int> safe_stack;
    safe_stack.push(1);
    std::thread t1([&safe_stack]() {
        if (!safe_stack.empty()) {
            std::this_thread::sleep_for(std::chrono::seconds(1));
            safe_stack.pop();
            }
        });
    std::thread t2([&safe_stack]() {
        if (!safe_stack.empty()) {
            std::this_thread::sleep_for(std::chrono::seconds(1));
            safe_stack.pop();
        }
    });
    t1.join();
    t2.join();
}
```

解决这个问题我们可以用抛出异常的方式,比如定义一个空栈的异常

```c++
struct empty_stack : std::exception
{
    const char* what() const throw();
};
```

然后实现我们的出栈函数

```c++
T pop()
{
    std::lock_guard<std::mutex> lock(m);
    if (data.empty()) throw empty_stack();
    auto element = data.top();
    data.pop();
    return element;
}
```

这么做就需要在外层使用的时候捕获异常。这是C++ 并发编程中提及的建议。但是我觉得可以在函数pop内部再次判断栈是否为空,若为空则返回一个非法数据,这样比抛出异常好一些。但是如果T是一个复杂类型,我们很难定义一个非法值给外界知晓,这一点可以通过智能指针进行优化。之后我们再介绍更优化的方案,因为现在这个`pop`函数仍存在问题,比如`T`是一个`vector<int>`类型,那么在`pop`函数内部`element`就是`vector<int>`类型,开始`element`存储了一些int值,程序没问题,函数执行pop操作, 假设此时程序内存暴增,导致当程序使用的内存足够大时,可用的有效空间不够, 函数返回`element`时,就会就会存在`vector`做拷贝赋值时造成失败。即使我们捕获异常,释放部分空间但也会导致栈元素已经出栈,数据丢失了。这其实是内存管理不当造成的,但是C++ 并发编程一书中给出了优化方案。

```c++
struct empty_stack : std::exception
{
    const char* what() const throw();
};
template<typename T>
class threadsafe_stack
{
private:
    std::stack<T> data;
    mutable std::mutex m;
public:
    threadsafe_stack() {}
    threadsafe_stack(const threadsafe_stack& other)
    {
        std::lock_guard<std::mutex> lock(other.m);
        //①在构造函数的函数体(constructor body)内进行复制操作
        data = other.data;   
    }
    threadsafe_stack& operator=(const threadsafe_stack&) = delete;
    void push(T new_value)
    {
        std::lock_guard<std::mutex> lock(m);
        data.push(std::move(new_value));
    }
    std::shared_ptr<T> pop()
    {
        std::lock_guard<std::mutex> lock(m);
        //②试图弹出前检查是否为空栈
        if (data.empty()) throw empty_stack();
        //③改动栈容器前设置返回值
            std::shared_ptr<T> const res(std::make_shared<T>(data.top()));    
            data.pop();
        return res;
    }
    void pop(T& value)
    {
        std::lock_guard<std::mutex> lock(m);
        if (data.empty()) throw empty_stack();
        value = data.top();
        data.pop();
    }
    bool empty() const
    {
        std::lock_guard<std::mutex> lock(m);
        return data.empty();
    }
};
```

我们提供了两个版本的`pop`操作,一个是带引用类型的参数的,一个是直接`pop`出智能指针类型,这样在`pop`函数内部减少了数据的拷贝,防止内存溢出,其实这两种做法确实是相比之前直接`pop`固定类型的值更节省内存,运行效率也好很多。我们也完全可以基于之前的思想,在`pop`时如果队列为空则返回空指针,这样比抛出异常更有好一些

```c++
std::shared_ptr<T> pop()
{
    std::lock_guard<std::mutex> lock(m);
    //②试图弹出前检查是否为空栈
    if (data.empty()) return nullptr;
    //③改动栈容器前设置返回值
    std::shared_ptr<T> const res(std::make_shared<T>(data.top()));    
    data.pop();
    return res;
}
```

### 死锁怎么造成的

死锁一般是由于**调运顺序不一致**导致的,比如**两个线程循环调用**。当线程1先加锁A,再加锁B,而线程2先加锁B,再加锁A。那么在某一时刻就可能造成死锁。比如线程1对A已经加锁,线程2对B已经加锁,那么他们都希望彼此占有对方的锁,又不释放自己占有的锁导致了死锁。  
举个例子

```c++
std::mutex  t_lock1;
std::mutex  t_lock2;
int m_1 = 0;
int m_2 = 1;
void dead_lock1() {
    while (true) {
        std::cout << "dead_lock1 begin " << std::endl;
        t_lock1.lock();
        m_1 = 1024;
        t_lock2.lock();
        m_2 = 2048;
        t_lock2.unlock();
        t_lock1.unlock();
        std::this_thread::sleep_for(std::chrono::milliseconds(5));
        std::cout << "dead_lock2 end " << std::endl;
    }
}
void dead_lock2() {
    while (true) {
        std::cout << "dead_lock2 begin " << std::endl;
        t_lock2.lock();
        m_2 = 2048;
        t_lock1.lock();
        m_1 = 1024;
        t_lock1.unlock();
        t_lock2.unlock();
        std::this_thread::sleep_for(std::chrono::milliseconds(5));
        std::cout << "dead_lock2 end " << std::endl;
    }
}
```

然后我们启动两个线程

```c++
void test_dead_lock() {
    std::thread t1(dead_lock1);
    std::thread t2(dead_lock2);
    t1.join();
    t2.join();
}
```

这样运行之后在某一个时刻一定会导致死锁。  

### 死锁解决方案

#### 加锁和解锁封装为独立的函数
实际工作中避免死锁的一个方式就是将加锁和解锁的功能封装为独立的函数,  
这样能保证在独立的函数里执行完操作后就解锁,不会导致一个函数里使用多个锁的情况

```c++
//加锁和解锁作为原子操作解耦合,各自只管理自己的功能
void atomic_lock1() {
    std::cout << "lock1 begin lock" << std::endl;
    t_lock1.lock();
    m_1 = 1024;
    t_lock1.unlock();
    std::cout << "lock1 end lock" << std::endl;
}
void atomic_lock2() {
    std::cout << "lock2 begin lock" << std::endl;
    t_lock2.lock();
    m_2 = 2048;
    t_lock2.unlock();
    std::cout << "lock2 end lock" << std::endl;
}
void safe_lock1() {
    while (true) {
        atomic_lock1();
        atomic_lock2();
        std::this_thread::sleep_for(std::chrono::milliseconds(5));
    }
}
void safe_lock2() {
    while (true) {
        atomic_lock2();
        atomic_lock1();
        std::this_thread::sleep_for(std::chrono::milliseconds(5));
    }
}
void test_safe_lock() {
    std::thread t1(safe_lock1);
    std::thread t2(safe_lock2);
    t1.join();
    t2.join();
}
```

#### 同时加锁

当我们无法避免在一个函数内部使用两个互斥量,并且都要解锁的情况,那我们可以采取同时加锁的方式。我们先定义一个类,假设这个类不推荐拷贝构造,但我们也提供了这个类的拷贝构造和移动构造

```c++
class som_big_object {
public:
    som_big_object(int data) :_data(data) {}
    //拷贝构造
    som_big_object(const som_big_object& b2) :_data(b2._data) {
        _data = b2._data;
    }
    //移动构造
    som_big_object(som_big_object&& b2) :_data(std::move(b2._data)) {
    }
    //重载输出运算符
    friend std::ostream& operator << (std::ostream& os, const som_big_object& big_obj) {
        os << big_obj._data;
        return os;
    }
    //重载赋值运算符
    som_big_object& operator = (const som_big_object& b2) {
        if (this == &b2) {
            return *this;
        }
        _data = b2._data;
        return *this;
    }
    //交换数据
    friend void swap(som_big_object& b1, som_big_object& b2) {
        som_big_object temp = std::move(b1);
        b1 = std::move(b2);
        b2 = std::move(temp);
    }
private:
    int _data;
};
```

接下来我们定义一个类对上面的类做管理,为防止多线程情况下数据混乱, 包含了一个互斥量。

```c++
class big_object_mgr {
public:
    big_object_mgr(int data = 0) :_obj(data) {}
    void printinfo() {
        std::cout << "current obj data is " << _obj << std::endl;
    }
    friend void danger_swap(big_object_mgr& objm1, big_object_mgr& objm2);
    friend void safe_swap(big_object_mgr& objm1, big_object_mgr& objm2);
    friend void safe_swap_scope(big_object_mgr& objm1, big_object_mgr& objm2);
private:
    std::mutex _mtx;
    som_big_object _obj;
};
```

为了方便演示哪些交换是安全的,哪些是危险的,所以写了三个函数。

```c++
void danger_swap(big_object_mgr& objm1, big_object_mgr& objm2) {
    std::cout << "thread [ " << std::this_thread::get_id() << " ] begin" << std::endl;
    if (&objm1 == &objm2) {
        return;
    }
    std::lock_guard <std::mutex> gurad1(objm1._mtx);
    //此处为了故意制造死锁,我们让线程小睡一会
    std::this_thread::sleep_for(std::chrono::seconds(1));
    std::lock_guard<std::mutex> guard2(objm2._mtx);
    swap(objm1._obj, objm2._obj);
    std::cout << "thread [ " << std::this_thread::get_id() << " ] end" << std::endl;
}
```

`danger_swap`是危险的交换方式。比如如下调用

```c++
void  test_danger_swap() {
    big_object_mgr objm1(5);
    big_object_mgr objm2(100);
    std::thread t1(danger_swap, std::ref(objm1), std::ref(objm2));
    std::thread t2(danger_swap, std::ref(objm2), std::ref(objm1));
    t1.join();
    t2.join();
    objm1.printinfo();
    objm2.printinfo();
}
```


这种调用方式存在隐患,因为`danger_swap`函数在两个线程中使用会造成互相竞争加锁的情况。  
那就需要用锁同时锁住两个锁。
```c++
void safe_swap(big_object_mgr& objm1, big_object_mgr& objm2) {
    std::cout << "thread [ " << std::this_thread::get_id() << " ] begin" << std::endl;
    if (&objm1 == &objm2) {
        return;
    }
    std::lock(objm1._mtx, objm2._mtx);
    //领养锁管理它自动释放
    std::lock_guard <std::mutex> gurad1(objm1._mtx, std::adopt_lock);
    //此处为了故意制造死锁,我们让线程小睡一会
    std::this_thread::sleep_for(std::chrono::seconds(1));
    std::lock_guard <std::mutex> gurad2(objm2._mtx, std::adopt_lock);
    swap(objm1._obj, objm2._obj);
    std::cout << "thread [ " << std::this_thread::get_id() << " ] end" << std::endl;
}
```

比如下面的调用就是合理的

```c++
void test_safe_swap() {
    big_object_mgr objm1(5);
    big_object_mgr objm2(100);
    std::thread t1(safe_swap, std::ref(objm1), std::ref(objm2));
    std::thread t2(safe_swap, std::ref(objm2), std::ref(objm1));
    t1.join();
    t2.join();
    objm1.printinfo();
    objm2.printinfo();
}
```

当然上面加锁的方式可以简化,C++17 `scope_lock`可以对多个互斥量同时加锁,并且自动释放

```c++
//上述代码可以简化为以下方式
void safe_swap_scope(big_object_mgr& objm1, big_object_mgr& objm2) {
    std::cout << "thread [ " << std::this_thread::get_id() << " ] begin" << std::endl;
    if (&objm1 == &objm2) {
        return;
    }
    std::scoped_lock  guard(objm1._mtx, objm2._mtx);
    //等价于
    //std::scoped_lock<std::mutex, std::mutex> guard(objm1._mtx, objm2._mtx);
    swap(objm1._obj, objm2._obj);
    std::cout << "thread [ " << std::this_thread::get_id() << " ] end" << std::endl;
}
```

#### 层级锁
现实开发中常常很难规避同一个函数内部加多个锁的情况,我们要尽可能避免循环加锁,所以可以自定义一个层级锁,保证实际项目中对多个互斥量加锁时是有序的。

通过为每个互斥锁分配**一个层级值**(hierarchy value),并确保线程在获取锁时遵循层级顺序来避免死锁。层级值较小的锁被认为比层级值较大的锁具有更高的优先级。

```c++
//层级锁
class hierarchical_mutex {
public:
    explicit hierarchical_mutex(unsigned long value) :_hierarchy_value(value),
        _previous_hierarchy_value(0) {}
    hierarchical_mutex(const hierarchical_mutex&) = delete;
    hierarchical_mutex& operator=(const hierarchical_mutex&) = delete;
    void lock() {
        check_for_hierarchy_violation();
        _internal_mutex.lock();
        update_hierarchy_value();
    }
    void unlock() {
        if (_this_thread_hierarchy_value != _hierarchy_value) {
            throw std::logic_error("mutex hierarchy violated");
        }
        _this_thread_hierarchy_value = _previous_hierarchy_value;
        _internal_mutex.unlock();
    }
    bool try_lock() {
        check_for_hierarchy_violation();
        if (!_internal_mutex.try_lock()) {
            return false;
        }
        update_hierarchy_value();
        return true;
    }
private:
    std::mutex  _internal_mutex;
    //当前层级值
    unsigned long const _hierarchy_value;
    //上一次层级值
    unsigned long _previous_hierarchy_value;
    //本线程记录的层级值
    static thread_local  unsigned long  _this_thread_hierarchy_value;
    void check_for_hierarchy_violation() {
        if (_this_thread_hierarchy_value <= _hierarchy_value) {
            throw  std::logic_error("mutex  hierarchy violated");
        }
    }
    void  update_hierarchy_value() {
        _previous_hierarchy_value = _this_thread_hierarchy_value;
        _this_thread_hierarchy_value = _hierarchy_value;
    }
};
thread_local unsigned long hierarchical_mutex::_this_thread_hierarchy_value(ULONG_MAX);
void test_hierarchy_lock() {
    hierarchical_mutex  hmtx1(1000);
    hierarchical_mutex  hmtx2(500);
    std::thread t1([&hmtx1, &hmtx2]() {
        hmtx1.lock();
        hmtx2.lock();
        hmtx2.unlock();
        hmtx1.unlock();
        });
    std::thread t2([&hmtx1, &hmtx2]() {
        hmtx2.lock();
        hmtx1.lock();
        hmtx1.unlock();
        hmtx2.unlock();
        });
    t1.join();
    t2.join();
}
```

层级锁能保证我们每个线程加锁时,一定是先加权重高的锁。  
并且释放时也保证了顺序。  
主要原理就是将当前锁的权重保存在线程变量中,这样该线程再次加锁时判断线程变量的权重和锁的权重是否大于,如果满足条件则继续加锁。


## unique_lock,共享锁和递归锁

### unique_lock
unique_lock和lock_guard基本用法相同,构造时默认加锁,析构时默认解锁,但unique_lock有个好处就是可以手动解锁。这一点尤为重要,方便我们控制锁住区域的粒度(加锁的范围大小),也能支持和条件变量配套使用,至于条件变量我们之后再介绍,本文主要介绍锁的相关操作。

```c++
//unique_lock 基本用法
std::mutex mtx;
int shared_data = 0;
void use_unique() {
    //lock可自动解锁,也可手动解锁
    std::unique_lock<std::mutex> lock(mtx);
    std::cout << "lock success" << std::endl;
    shared_data++;
    lock.unlock();
}
```

我们可以通过`unique_lock`的`owns_lock`判断是否持有锁

```c++
//可判断是否占有锁
void owns_lock() {
    //lock可自动解锁,也可手动解锁
    std::unique_lock<std::mutex> lock(mtx);
    shared_data++;
    if (lock.owns_lock()) {
        std::cout << "owns lock" << std::endl;
    }
    else {
        std::cout << "doesn't own lock" << std::endl;
    }
    lock.unlock();
    if (lock.owns_lock()) {
        std::cout << "owns lock" << std::endl;
    }
    else {
        std::cout << "doesn't own lock" << std::endl;
    }
}
```


上述代码输出

```c++
owns lock
doesn't own lock
```

`unique_lock`可以延迟加锁

```c++
 //可以延迟加锁
void defer_lock() {
    //延迟加锁
    std::unique_lock<std::mutex> lock(mtx, std::defer_lock);
    //可以加锁
    lock.lock();
    //可以自动析构解锁,也可以手动解锁
    lock.unlock();
}
```

那我们写一段代码综合运用`owns_lock`和`defer_lock`

```c++
//同时使用owns和defer
void use_own_defer() {
    std::unique_lock<std::mutex>  lock(mtx);
    // 判断是否拥有锁
    if (lock.owns_lock())
    {
        std::cout << "Main thread has the lock." << std::endl;
    }
    else
    {
        std::cout << "Main thread does not have the lock." << std::endl;
    }
    std::thread t([]() {
        std::unique_lock<std::mutex> lock(mtx, std::defer_lock);
        // 判断是否拥有锁
        if (lock.owns_lock())
        {
            std::cout << "Thread has the lock." << std::endl;
        }
        else
        {
            std::cout << "Thread does not have the lock." << std::endl;
        }
        // 加锁
        lock.lock();
        // 判断是否拥有锁
        if (lock.owns_lock())
        {
            std::cout << "Thread has the lock." << std::endl;
        }
        else
        {
            std::cout << "Thread does not have the lock." << std::endl;
        }
        // 解锁
        lock.unlock();
        });
    t.join();
}
```

上述代码回依次输出, 但是程序会阻塞,因为子线程会卡在加锁的逻辑上,因为主线程未释放锁,而主线程又等待子线程退出,导致整个程序卡住。

```c++
Main thread has the lock.
Thread does not have the lock.
```

和`lock_guard`一样,`unique_lock`也支持领养锁

```c++
//同样支持领养操作
void use_own_adopt() {
    mtx.lock();
    std::unique_lock<std::mutex> lock(mtx, std::adopt_lock);
    if (lock.owns_lock()) {
        std::cout << "owns lock" << std::endl;
    }
    else {
        std::cout << "does not have the lock" << std::endl;
    }
    lock.unlock();
}
```

尽管是领养的,但是打印还是会出现`owns lock`,因为不管如何锁被加上,就会输出`owns lock`。
既然`unique_lock`支持领养操作也支持延迟加锁,那么可以用两种方式实现前文`lock_guard`实现的`swap`操作。

```c++
//之前的交换代码可以可以用如下方式等价实现
int a = 10;
int b = 99;
std::mutex  mtx1;
std::mutex  mtx2;
void safe_swap() {
    std::lock(mtx1, mtx2);
    std::unique_lock<std::mutex> lock1(mtx1, std::adopt_lock);
    std::unique_lock<std::mutex> lock2(mtx2, std::adopt_lock);
    std::swap(a, b);
    //错误用法
    //mtx1.unlock();
    //mtx2.unlock();
}
void safe_swap2() {
    std::unique_lock<std::mutex> lock1(mtx1, std::defer_lock);
    std::unique_lock<std::mutex> lock2(mtx2, std::defer_lock);
    //需用lock1,lock2加锁
    std::lock(lock1, lock2);
    //错误用法
    //std::lock(mtx1, mtx2);
    std::swap(a, b);
}
```

大家注意一旦`mutex`被`unique_lock`管理,加锁和释放的操作就交给`unique_lock`,不能调用`mutex`加锁和解锁,因为锁的使用权已经交给`unique_lock`了。
我们知道`mutex`是不支持移动和拷贝的,但是`unique_lock`支持移动,当一个`mutex`被转移给`unique_lock`后,可以通过unique_ptr转移其归属权.

```c++
//转移互斥量所有权
//互斥量本身不支持move操作,但是unique_lock支持
std::unique_lock <std::mutex>  get_lock() {
    std::unique_lock<std::mutex>  lock(mtx);
    shared_data++;
    return lock;
}
void use_return() {
    std::unique_lock<std::mutex> lock(get_lock());
    shared_data++;
}
```


锁的粒度表示加锁的精细程度,一个锁的粒度要足够大,保证可以锁住要访问的共享数据。
同时一个锁的粒度要足够小,保证非共享数据不被锁住影响性能。
而`unique_ptr`则很好的支持手动解锁。

```c++
void precision_lock() {
    std::unique_lock<std::mutex> lock(mtx);
    shared_data++;
    lock.unlock();
    //不设计共享数据的耗时操作不要放在锁内执行
    std::this_thread::sleep_for(std::chrono::seconds(1));
    lock.lock();
    shared_data++;
}
```


#### 共享锁

试想这样一个场景,对于一个DNS服务,我们可以根据域名查询服务对应的ip地址,它很久才更新一次,比如新增记录,删除记录或者更新记录等。平时大部分时间都是提供给外部查询,对于查询操作,即使多个线程并发查询不加锁也不会有问题,但是当有线程修改DNS服务的ip记录或者增减记录时,其他线程不能查询,需等待修改完再查询。或者等待查询完,线程才能修改。也就是说读操作并不是互斥的,同一时间可以有多个线程同时读,但是写和读是互斥的,写与写是互斥的,简而言之,写操作需要独占锁。而读操作需要共享锁。

要想使用共享锁,需使用共享互斥量`std::shared_mutex`,`std::shared_mutex`是C++17标准提出的。  
C++14标准可以使用`std::shared_time_mutex`,
`std::shared_mutex` 和 `std::shared_timed_mutex` 都是用于实现多线程并发访问共享数据的互斥锁,但它们之间存在一些区别：
1. `std::shared_mutex`：
	- 提供了`lock()`, `try_lock()`, 和 `try_lock_for()` 以及 `try_lock_until()` 函数,这些函数都可以用于获取互斥锁。``
	- 提供了`try_lock_shared()` 和 `lock_shared()` 函数,这些函数可以用于获取共享锁。``
	- 当`std::shared_mutex`被锁定后,其他尝试获取该锁的线程将会被阻塞,直到该锁被解锁。

2. `std::shared_timed_mutex`：
	- 与 `std::shared_mutex` 类似,也提供了 `lock()`, `try_lock()`, 和 `try_lock_for()` 以及 `try_lock_until()` 函数用于获取互斥锁。``
	- 与 `std::shared_mutex` 不同的是,它还提供了 `try_lock_shared()` 和 `lock_shared()` 函数用于获取共享锁,这些函数在尝试获取共享锁时具有超时机制。``
	- 当 `std::shared_timed_mutex` 被锁定后,其他尝试获取该锁的线程将会被阻塞,直到该锁被解锁,这与 `std::shared_mutex` 相同。然而,当尝试获取共享锁时,如果不能立即获得锁,`std::shared_timed_mutex` 会设置一个超时,超时过后如果仍然没有获取到锁,则操作将返回失败。

因此,`std::shared_timed_mutex` 提供了额外的超时机制,这使得它在某些情况下更适合于需要处理超时的并发控制。然而,如果不需要超时机制,可以使用更简单的 `std::shared_mutex`。
C++11标准没有共享互斥量,可以使用boost提供的`boost::shared_mutex`。
如果我们想构造共享锁,可以使用`std::shared_lock`,如果我们想构造独占锁, 可以使用`std::lock_gurad`.
我们用一个类`DNService`代表DNS服务,查询操作使用共享锁,而写操作使用独占锁,可以是如下方式的。

```c++
class DNService {
public:
    DNService() {}
    //读操作采用共享锁
    std::string QueryDNS(std::string dnsname) {
        std::shared_lock<std::shared_mutex> shared_locks(_shared_mtx);
        auto iter = _dns_info.find(dnsname);
        if (iter != _dns_info.end()) {
            return iter->second;
        }
        return "";
    }
    //写操作采用独占锁
    void AddDNSInfo(std::string dnsname, std::string dnsentry) {
        std::lock_guard<std::shared_mutex>  guard_locks(_shared_mtx);
        _dns_info.insert(std::make_pair(dnsname, dnsentry));
    }
private:
    std::map<std::string, std::string> _dns_info;
    mutable std::shared_mutex  _shared_mtx;
};
```


- `QueryDNS` 用来查询dns信息,多个线程可同时访问。  
- `AddDNSInfo` 用来添加dns信息,属独占锁,同一时刻只有一个线程在修改。

### 递归锁

有时候我们在实现接口的时候内部加锁,接口内部调用完结束自动解锁。会出现一个接口调用另一个接口的情况,如果用普通的`std::mutex`就会出现卡死,因为嵌套加锁导致卡死。但是我们可以使用递归锁。
但我个人并不推荐递归锁,可以从设计源头规避嵌套加锁的情况,我们可以将**接口相同的功能抽象出来**,统一加锁。下面的设计演示了如何使用递归锁

```c++
class RecursiveDemo {
public:
    RecursiveDemo() {}
    bool QueryStudent(std::string name) {
        std::lock_guard<std::recursive_mutex>  recursive_lock(_recursive_mtx);
        auto iter_find = _students_info.find(name);
        if (iter_find == _students_info.end()) {
            return false;
        }
        return true;
    }
    void AddScore(std::string name, int score) {
        std::lock_guard<std::recursive_mutex>  recursive_lock(_recursive_mtx);
        if (!QueryStudent(name)) {
            _students_info.insert(std::make_pair(name, score));
            return;
        }
        _students_info[name] = _students_info[name] + score;
    }
    //不推荐采用递归锁,使用递归锁说明设计思路并不理想,需优化设计
    //推荐拆分逻辑,将共有逻辑拆分为统一接口
    void AddScoreAtomic(std::string name, int score) {
        std::lock_guard<std::recursive_mutex>  recursive_lock(_recursive_mtx);
        auto iter_find = _students_info.find(name);
        if (iter_find == _students_info.end()) {
            _students_info.insert(std::make_pair(name, score));
            return;
        }
        _students_info[name] = _students_info[name] + score;
        return;
    }
private:
    std::map<std::string, int> _students_info;
    std::recursive_mutex   _recursive_mtx;
};
```

- 我们可以看到AddScore函数内部调用了QueryStudent, 所以采用了递归锁。
- 但是我们同样可以改变设计,将两者公有的部分抽离出来生成一个新的接口`AddScoreAtomic.`
- `AddScoreAtomic`可以不适用递归锁,照样能完成线程安全操作的目的。


## 并发三剑客future, promise和async

### async用法

`std::async` 是一个用于异步执行函数的模板函数,它返回一个 `std::future` 对象,该对象用于获取函数的返回值。
以下是一个使用 `std::async` 的示例：
```c++
#include <iostream>
#include <future>
#include <chrono>
// 定义一个异步任务
std::string fetchDataFromDB(std::string query) {
    // 模拟一个异步任务,比如从数据库中获取数据
    std::this_thread::sleep_for(std::chrono::seconds(5));
    return "Data: " + query;
}
int main() {
    // 使用 std::async 异步调用 fetchDataFromDB
    std::future<std::string> resultFromDB = std::async(std::launch::async, fetchDataFromDB, "Data");
    // 在主线程中做其他事情
    std::cout << "Doing something else..." << std::endl;
    // 从 future 对象中获取数据
    std::string dbData = resultFromDB.get();
    std::cout << dbData << std::endl;
    return 0;
}
```

在这个示例中,`std::async` 创建了一个新的线程(或从内部线程池中挑选一个线程)并自动与一个 `std::promise` 对象相关联。`std::promise` 对象被传递给 `fetchDataFromDB` 函数,函数的返回值被存储在 `std::future` 对象中。在主线程中,我们可以使用 `std::future::get` 方法从 `std::future` 对象中获取数据。注意,在使用 `std::async` 的情况下,我们必须使用 `std::launch::async` 标志来明确表明我们希望函数异步执行。

上面的例子输出
```c++
Doing something else...
Data: Data
```


### async的启动策略

`std::async`函数可以接受几个不同的启动策略,这些策略在`std::launch`枚举中定义。除了`std::launch::async`之外,还有以下启动策略：

1. `std::launch::deferred`：这种策略意味着任务将在调用`std::future::get()`或`std::future::wait()`函数时延迟执行。换句话说,任务将在需要结果时同步执行。
2. `std::launch::async | std::launch::deferred`：这种策略是上面两个策略的组合。任务可以在一个单独的线程上异步执行,也可以延迟执行,具体取决于实现。

默认情况下,`std::async`使用`std::launch::async | std::launch::deferred`策略。这意味着任务可能异步执行,也可能延迟执行,具体取决于实现。需要注意的是,不同的编译器和操作系统可能会有不同的默认行为。
### future的wait和get

`std::future::get()` 和 `std::future::wait()` 是 C++ 中用于处理异步任务的两个方法,它们的功能和用法有一些重要的区别。

1. **std::future::get()**:

`std::future::get()` 是一个阻塞调用,用于获取 `std::future` 对象表示的值或异常。如果异步任务还没有完成,`get()` 会阻塞当前线程,直到任务完成。如果任务已经完成,`get()` 会立即返回任务的结果。重要的是,`get()` 只能调用一次,因为它会移动或消耗掉 `std::future` 对象的状态。一旦 `get()` 被调用,`std::future` 对象就不能再被用来获取结果。

1. **std::future::wait()**:

`std::future::wait()` 也是一个阻塞调用,但它与 `get()` 的主要区别在于 `wait()` 不会返回任务的结果。它只是等待异步任务完成。如果任务已经完成,`wait()` 会立即返回。如果任务还没有完成,`wait()` 会阻塞当前线程,直到任务完成。与 `get()` 不同,`wait()` 可以被多次调用,它不会消耗掉 `std::future` 对象的状态。

总结一下,这两个方法的主要区别在于：

- `std::future::get()` 用于获取并返回任务的结果,而 `std::future::wait()` 只是等待任务完成。
- `get()` 只能调用一次,而 `wait()` 可以被多次调用。
- 如果任务还没有完成,`get()` 和 `wait()` 都会阻塞当前线程,但 `get()` 会一直阻塞直到任务完成并返回结果,而 `wait()` 只是在等待任务完成。

你可以使用std::future的wait_for()或wait_until()方法来检查异步操作是否已完成。这些方法返回一个表示操作状态的std::future_status值。

```c++
if(fut.wait_for(std::chrono::seconds(0)) == std::future_status::ready) {  
    // 操作已完成  
} else {  
    // 操作尚未完成  
}
```

### 将任务和future关联

`std::packaged_task`和`std::future`是C++11中引入的两个类,它们用于处理异步任务的结果。

`std::packaged_task`是一个可调用目标,它包装了一个任务,该任务可以在另一个线程上运行。它可以捕获任务的返回值或异常,并将其存储在`std::future`对象中,以便以后使用。

`std::future`代表一个异步操作的结果。它可以用于从异步任务中获取返回值或异常。

以下是使用`std::packaged_task`和`std::future`的基本步骤：

1. 创建一个`std::packaged_task`对象,该对象包装了要执行的任务。
2. 调用`std::packaged_task`对象的`get_future()`方法,该方法返回一个与任务关联的`std::future`对象。
3. 在另一个线程上调用`std::packaged_task`对象的`operator()`,以执行任务。
4. 在需要任务结果的地方,调用与任务关联的`std::future`对象的`get()`方法,以获取任务的返回值或异常。

以下是一个简单的示例代码：

```c++
int my_task() {
    std::this_thread::sleep_for(std::chrono::seconds(5));
    std::cout << "my task run 5 s" << std::endl;
    return 42;
}
void use_package() {
    // 创建一个包装了任务的 std::packaged_task 对象  
    std::packaged_task<int()> task(my_task);
    // 获取与任务关联的 std::future 对象  
    std::future<int> result = task.get_future();
    // 在另一个线程上执行任务  
    std::thread t(std::move(task));
    t.detach(); // 将线程与主线程分离,以便主线程可以等待任务完成  
    // 等待任务完成并获取结果  
    int value = result.get();
    std::cout << "The result is: " << value << std::endl;
}
```

在上面的示例中,我们创建了一个包装了任务的`std::packaged_task`对象,并获取了与任务关联的`std::future`对象。然后,我们在另一个线程上执行任务,并等待任务完成并获取结果。最后,我们输出结果。

我们可以使用 std::function 和 std::package_task 来包装带参数的函数。std::package_task 是一个模板类,它包装了一个可调用对象,并允许我们将其作为异步任务传递。

### promise 用法

C++11引入了`std::promise`和`std::future`两个类,用于实现异步编程。`std::promise`用于在某一线程中设置某个值或异常,而`std::future`则用于在另一线程中获取这个值或异常。
下面是`std::promise`的基本用法：

```c++
#include <iostream>
#include <thread>
#include <future>
void set_value(std::promise<int> prom) {
    // 设置 promise 的值
    prom.set_value(10);
}
int main() {
    // 创建一个 promise 对象
    std::promise<int> prom;
    // 获取与 promise 相关联的 future 对象
    std::future<int> fut = prom.get_future();
    // 在新线程中设置 promise 的值
    std::thread t(set_value, std::move(prom));
    // 在主线程中获取 future 的值
    std::cout << "Waiting for the thread to set the value...\n";
    std::cout << "Value set by the thread: " << fut.get() << '\n';
    t.join();
    return 0;
}
```

程序输出
```c++
Waiting for the thread to set the value...
promise set value successValue set by the thread:
10
```

在上面的代码中,我们首先创建了一个`std::promise<int>`对象,然后通过调用`get_future()`方法获取与之相关联的`std::future<int>`对象。然后,我们在新线程中通过调用`set_value()`方法设置`promise`的值,并在主线程中通过调用`fut.get()`方法获取这个值。注意,在调用`fut.get()`方法时,如果`promise`的值还没有被设置,则该方法会阻塞当前线程,直到值被设置为止。

除了`set_value()`方法外,`std::promise`还有一个`set_exception()`方法,用于设置异常。该方法接受一个`std::exception_ptr`参数,该参数可以通过调用`std::current_exception()`方法获取。下面是一个例子：

```c++
#include <iostream>
#include <thread>
#include <future>
void set_exception(std::promise<void> prom) {
    try {
        // 抛出一个异常
        throw std::runtime_error("An error occurred!");
    } catch(...) {
        // 设置 promise 的异常
        prom.set_exception(std::current_exception());
    }
}
int main() {
    // 创建一个 promise 对象
    std::promise<void> prom;
    // 获取与 promise 相关联的 future 对象
    std::future<void> fut = prom.get_future();
    // 在新线程中设置 promise 的异常
    std::thread t(set_exception, std::move(prom));
    // 在主线程中获取 future 的异常
    try {
        std::cout << "Waiting for the thread to set the exception...\n";
        fut.get();
    } catch(const std::exception& e) {
        std::cout << "Exception set by the thread: " << e.what() << '\n';
    }
    t.join();
    return 0;
}
```

上述代码输出 
```c++
Waiting for the thread to set the exception...
Exception set by the thread: An error occurred!
```

当然我们使用promise时要注意一点,如果promise被释放了,而其他的线程还未使用与promise关联的future,当其使用这个future时会报错。如下是一段错误展示

```c++
void use_promise_destruct() {
    std::thread t;
    std::future<int> fut;
    {
        // 创建一个 promise 对象
        std::promise<int> prom;
        // 获取与 promise 相关联的 future 对象
        fut = prom.get_future();
        // 在新线程中设置 promise 的值
         t = std::thread(set_value, std::move(prom));
    }
    // 在主线程中获取 future 的值
    std::cout << "Waiting for the thread to set the value...\n";
    std::cout << "Value set by the thread: " << fut.get() << '\n';
    t.join();
}
```

随着局部作用域`}`的结束,`prom`可能被释放也可能会被延迟释放,  
如果立即释放则`fut.get()`获取的值会报`error_value`的错误。
### 共享类型的future

当我们需要多个线程等待同一个执行结果时,需要使用std::shared_future
以下是一个适合使用`std::shared_future`的场景,多个线程等待同一个异步操作的结果：
假设你有一个异步任务,需要多个线程等待其完成,然后这些线程需要访问任务的结果。在这种情况下,你可以使用`std::shared_future`来共享异步任务的结果。
线程池做的要是并发,且无序的,互斥性很大,强关联不适合线程池
```c++
void myFunction(std::promise<int>&& promise) {
    // 模拟一些工作
    std::this_thread::sleep_for(std::chrono::seconds(1));
    promise.set_value(42); // 设置 promise 的值
}
void threadFunction(std::shared_future<int> future) {
    try {
        int result = future.get();
        std::cout << "Result: " << result << std::endl;
    }
    catch (const std::future_error& e) {
        std::cout << "Future error: " << e.what() << std::endl;
    }
}
void use_shared_future() {
    std::promise<int> promise;
    std::shared_future<int> future = promise.get_future();
    std::thread myThread1(myFunction, std::move(promise)); // 将 promise 移动到线程中
    // 使用 share() 方法获取新的 shared_future 对象  
    std::thread myThread2(threadFunction, future);
    std::thread myThread3(threadFunction, future);
    myThread1.join();
    myThread2.join();
    myThread3.join();
}
```

在这个示例中,我们创建了一个`std::promise<int>`对象`promise`和一个与之关联的`std::shared_future<int>`对象`future`。然后,我们将`promise`对象移动到另一个线程`myThread1`中,该线程将执行`myFunction`函数,并在完成后设置`promise`的值。我们还创建了两个线程`myThread2`和`myThread3`,它们将等待`future`对象的结果。如果`myThread1`成功地设置了`promise`的值,那么`future.get()`将返回该值。这些线程可以同时访问和等待`future`对象的结果,而不会相互干扰。

但是大家要注意,如果一个`future`被移动给两个`shared_future`是错误的。

```c++
void use_shared_future() {
    std::promise<int> promise;
    std::shared_future<int> future = promise.get_future();
    std::thread myThread1(myFunction, std::move(promise)); // 将 promise 移动到线程中
    std::thread myThread2(threadFunction, std::move(future));
    std::thread myThread3(threadFunction, std::move(future));
    myThread1.join();
    myThread2.join();
    myThread3.join();
}
```

这种用法是错误的,一个`future`通过隐式构造传递给`shared_future`之后,这个`shared_future`被移动传递给两个线程是不合理的,因为第一次移动后`shared_future`的生命周期被转移了,接下来`myThread3`构造时用的`std::move(future)`future已经失效了,会报错,一般都是`no state` 之类的错误。

### 异常处理

`std::future` 是C++的一个模板类,它用于表示一个可能还没有准备好的异步操作的结果。你可以通过调用 `std::future::get` 方法来获取这个结果。如果在获取结果时发生了异常,那么 `std::future::get` 会重新抛出这个异常。

以下是一个例子,演示了如何在 `std::future` 中获取异常：

```c++
#include <iostream>
#include <future>
#include <stdexcept>
#include <thread>
void may_throw()
{
    // 这里我们抛出一个异常。在实际的程序中,这可能在任何地方发生。
    throw std::runtime_error("Oops, something went wrong!");
}
int main()
{
    // 创建一个异步任务
    std::future<void> result(std::async(std::launch::async, may_throw));
    try
    {
        // 获取结果(如果在获取结果时发生了异常,那么会重新抛出这个异常)
        result.get();
    }
    catch (const std::exception &e)
    {
        // 捕获并打印异常
        std::cerr << "Caught exception: " << e.what() << std::endl;
    }
    return 0;
}
```

在这个例子中,我们创建了一个异步任务 `may_throw`,这个任务会抛出一个异常。然后,我们创建一个 `std::future` 对象 `result` 来表示这个任务的结果。在 `main` 函数中,我们调用 `result.get()` 来获取任务的结果。如果在获取结果时发生了异常,那么 `result.get()` 会重新抛出这个异常,然后我们在 `catch` 块中捕获并打印这个异常。

上面的例子输出 
```c++
Caught exception: Oops, something went wrong!
```


### 线程池

我们可以利用上面提到的`std::packaged_task`和`std::promise`构建线程池,提高程序的并发能力。  
先了解什么是线程池：

线程池是一种多线程处理形式,它处理过程中将任务添加到队列,然后在创建线程后自动启动这些任务。线程池线程都是后台线程。每个线程都使用默认的堆栈大小,以默认的优先级运行,并处于多线程单元中。如果某个线程在托管代码中空闲(如正在等待某个事件),则线程池将插入另一个辅助线程来使所有处理器保持繁忙。如果所有线程池线程都始终保持繁忙,但队列中包含挂起的工作,则线程池将在一段时间后创建另一个辅助线程但线程的数目永远不会超过最大值。超过最大值的线程可以排队,但他们要等到其他线程完成后才启动。
线程池可以避免在处理短时间任务时创建与销毁线程的代价,它维护着多个线程,等待着监督管理者分配可并发执行的任务,从而提高了整体性能。

下面是我提供的一套线程池源码,目前用在公司的项目中

```c++
#ifndef __THREAD_POOL_H__
#define __THREAD_POOL_H__
#include <atomic>
#include <condition_variable>
#include <future>
#include <iostream>
#include <mutex>
#include <queue>
#include <thread>
#include <vector>
class ThreadPool  {
public:
    ThreadPool(const ThreadPool&) = delete;
    ThreadPool& operator=(const ThreadPool&) = delete;
    static ThreadPool& instance() {
        static ThreadPool ins;
        return ins;
    }
    using Task = std::packaged_task<void()>;
    ~ThreadPool() {
        stop();
    }
    template <class F, class... Args>
    auto commit(F&& f, Args&&... args) -> std::future<decltype(f(args...))> {
        using RetType = decltype(f(args...));
        if (stop_.load())
            return std::future<RetType>{};
        auto task = std::make_shared<std::packaged_task<RetType()>>(
            std::bind(std::forward<F>(f), std::forward<Args>(args)...));
        std::future<RetType> ret = task->get_future();
        {
            std::lock_guard<std::mutex> cv_mt(cv_mt_);
            tasks_.emplace([task] { (*task)(); });
        }
        cv_lock_.notify_one();
        return ret;
    }
    int idleThreadCount() {
        return thread_num_;
    }
private:
    ThreadPool(unsigned int num = 5)
        : stop_(false) {
            {
                if (num < 1)
                    thread_num_ = 1;
                else
                    thread_num_ = num;
            }
            start();
    }
    void start() {
        for (int i = 0; i < thread_num_; ++i) {
            pool_.emplace_back([this]() {
                while (!this->stop_.load()) {
                    Task task;
                    {
                        std::unique_lock<std::mutex> cv_mt(cv_mt_);
                        this->cv_lock_.wait(cv_mt, [this] {
                            return this->stop_.load() || !this->tasks_.empty();
                        });
                        if (this->tasks_.empty())
                            return;
                        task = std::move(this->tasks_.front());
                        this->tasks_.pop();
                    }
                    this->thread_num_--;
                    task();
                    this->thread_num_++;
                }
            });
        }
    }
    void stop() {
        stop_.store(true);
        cv_lock_.notify_all();
        for (auto& td : pool_) {
            if (td.joinable()) {
                std::cout << "join thread " << td.get_id() << std::endl;
                td.join();
            }
        }
    }
private:
    std::mutex               cv_mt_;
    std::condition_variable  cv_lock_;
    std::atomic_bool         stop_;
    std::atomic_int          thread_num_;
    std::queue<Task>         tasks_;
    std::vector<std::thread> pool_;
};
```

## 函数式编程

前文介绍了`async`用法,很多朋友说用的不多,我对`async`的理解就是开辟一个一次性的线程执行并行任务,主线程可以通过`future`在合适的时机执行等待汇总结果。本文通过并行和函数式编程,演示快速排序提升效率的一种方式。

### 快速排序

快速排序(Quick Sort)是一种高效的排序算法,采用分治法的思想进行排序。以下是快速排序的基本步骤：

1. 选择一个基准元素(pivot)：从数组中选择一个元素作为基准元素。选择基准元素的方式有很多种,常见的是选择数组的第一个元素或最后一个元素。
2. 分区(partitioning)：重新排列数组,把比基准元素小的元素放在它的左边,把比基准元素大的元素放在它的右边。在这个过程结束时,基准元素就处于数组的最终位置。
3. 递归排序子数组：递归地对基准元素左边和右边的两个子数组进行快速排序。

以下是一个基本的快速排序的C++实现：
```c++
//c++ 版本的快速排序算法
template<typename T>
void quick_sort_recursive(T arr[], int start, int end) {
    if (start >= end) return;
    T key = arr[start];
    int left = start, right = end;
    while(left < right) {
        while (arr[right] >= key && left < right) right--;
        while (arr[left] <= key && left < right) left++;
        std::swap(arr[left], arr[right]);
    }
    if (arr[left] < key) {
        std::swap(arr[left], arr[start]);
    }
    quick_sort_recursive(arr, start, left - 1);
    quick_sort_recursive(arr, left + 1, end);
}
template<typename T>
void quick_sort(T arr[], int len) {
    quick_sort_recursive(arr, 0, len - 1);
}
```

排序演示

假设一开始序列{xi}是：5,3,7,6,4,1,0,2,9,10,8。
此时,ref=5,i=1,j=11,从后往前找,第一个比5小的数是x8=2,因此序列为：2,3,7,6,4,1,0,5,9,10,8。
此时i=1,j=8,从前往后找,第一个比5大的数是x3=7,因此序列为：2,3,5,6,4,1,0,7,9,10,8。
此时,i=3,j=8,从第8位往前找,第一个比5小的数是x7=0,因此：2,3,0,6,4,1,5,7,9,10,8。
此时,i=3,j=7,从第3位往后找,第一个比5大的数是x4=6,因此：2,3,0,5,4,1,6,7,9,10,8。
此时,i=4,j=7,从第7位往前找,第一个比5小的数是x6=1,因此：2,3,0,1,4,5,6,7,9,10,8。
此时,i=4,j=6,从第4位往后找,直到第6位才有比5大的数,这时,i=j=6,ref成为一条分界线,它之前的数都比它小,之后的数都比它大,对于前后两部分数,可以采用同样的方法来排序。

调用比较简单

```c++
void test_quick_sort() {
    int num_arr[] = { 5,3,7,6,4,1,0,2,9,10,8 };
    int length = sizeof(num_arr) / sizeof(int);
     quick_sort(num_arr, length );
    std::cout << "sorted result is ";
    for (int i = 0; i < length; i++) {
        std::cout << " " << num_arr[i];
    }
    std::cout << std::endl;    
}
```

这种实现方式比较依赖存储数据的数据结构,比如上面是通过数组存储的,那如果我想实现list容器中元素的排序怎么办？我既不想关注存储的容器,也不想关注存储的类型,想实现一套通用的比较规则？那就需要函数式编程来解决

### 函数式编程

C++函数式编程是一种编程范式,它将计算视为数学上的函数求值,并避免改变状态和使用可变数据。在函数式编程中,程序是由一系列函数组成的,每个函数都接受输入并产生输出,而且没有任何副作用。
在C++中,函数式编程可以使用函数指针、函数对象(functor)和lambda表达式等机制来实现。这些机制允许您编写可以像普通函数一样调用的代码块,并将它们作为参数传递给其他函数或作为返回值返回。
C++11引入了一些新功能,如constexpr函数和表达式模板,这些功能使得在C++中进行函数式编程更加容易和直观。
我们用函数式编程修改上面的快速排序

```c++
template<typename T>
std::list<T> sequential_quick_sort(std::list<T> input)
{
    if (input.empty())
    {
        return input;
    }
    std::list<T> result;
    //  ① 将input中的第一个元素放入result中,并且将这第一个元素从input中删除
    result.splice(result.begin(), input, input.begin());  
    //  ② 取result的第一个元素,将来用这个元素做切割,切割input中的列表。
    T const& pivot = *result.begin();    
    //  ③std::partition 是一个标准库函数,用于将容器或数组中的元素按照指定的条件进行分区,
    // 使得满足条件的元素排在不满足条件的元素之前。
    // 所以经过计算divide_point指向的是input中第一个大于等于pivot的元素
        auto divide_point = std::partition(input.begin(), input.end(),
            [&](T const& t) {return t < pivot; });    
    // ④ 我们将小于pivot的元素放入lower_part中
    std::list<T> lower_part;
    lower_part.splice(lower_part.end(), input, input.begin(),
        divide_point);  
    // ⑤我们将lower_part传递给sequential_quick_sort 返回一个新的有序的从小到大的序列
    //lower_part 中都是小于divide_point的值
        auto new_lower(
            sequential_quick_sort(std::move(lower_part)));    
    // ⑥我们剩余的input列表传递给sequential_quick_sort递归调用,input中都是大于divide_point的值。
        auto new_higher(
            sequential_quick_sort(std::move(input)));    
        //⑦到此时new_higher和new_lower都是从小到大排序好的列表
        //将new_higher 拼接到result的尾部
        result.splice(result.end(), new_higher);    
        //将new_lower 拼接到result的头部
        result.splice(result.begin(), new_lower);   
        return result;
}
```

用如下方式调用
```c++
void test_sequential_quick() {
    std::list<int> numlists = { 6,1,0,7,5,2,9,-1 };
    auto sort_result = sequential_quick_sort(numlists);
    std::cout << "sorted result is ";
    for (auto iter = sort_result.begin(); iter != sort_result.end(); iter++) {
        std::cout << " " << (*iter);
    }
    std::cout << std::endl;
}
```

这个函数是一个使用快速排序算法对链表进行排序的实现。快速排序是一种常用的排序算法,它的基本思想是选择一个基准元素,然后将数组分为两部分,一部分是小于基准元素的元素,另一部分是大于基准元素的元素。然后对这两部分再分别进行快速排序。这个函数使用了C++的模板,可以处理任何数据类型的链表。函数的主要步骤包括：

1. 将链表的第一个元素作为基准元素,并将其从链表中删除。
2. 使用std::partition函数将链表分为两部分,一部分是小于基准元素的元素,另一部分是大于或等于基准元素的元素。
3. 对这两部分分别进行递归排序。\n4. 将排序后的两部分和基准元素合并,返回排序后的链表。

### 并行方式

我们提供并行方式的函数式编程,可以极大的利用cpu多核的优势,这在并行计算中很常见。
```c++
//并行版本
template<typename T>
std::list<T> parallel_quick_sort(std::list<T> input)
{
    if (input.empty())
    {
        return input;
    }
    std::list<T> result;
    result.splice(result.begin(), input, input.begin());
    T const& pivot = *result.begin();
    auto divide_point = std::partition(input.begin(), input.end(),
        [&](T const& t) {return t < pivot; });
    std::list<T> lower_part;
    lower_part.splice(lower_part.end(), input, input.begin(),
        divide_point);
    // ①因为lower_part是副本,所以并行操作不会引发逻辑错误,这里可以启动future做排序
    std::future<std::list<T>> new_lower(
        std::async(&parallel_quick_sort<T>, std::move(lower_part)));
    // ②
    auto new_higher(
        parallel_quick_sort(std::move(input)));    
        result.splice(result.end(), new_higher);    
        result.splice(result.begin(), new_lower.get());    
        return result;
}
```

测试调用如下
```c++
void test_sequential_quick() {
    std::list<int> numlists = { 6,1,0,7,5,2,9,-1 };
    auto sort_result = sequential_quick_sort(numlists);
    std::cout << "sorted result is ";
    for (auto iter = sort_result.begin(); iter != sort_result.end(); iter++) {
        std::cout << " " << (*iter);
    }
    std::cout << std::endl;
}
```

我们对`lower_part`的排序调用了`std::async`并行处理。而`higher_part`则是串行执行的。这么做提高了计算的并行能力,但有人会问如果数组的大小为1024,那么就是2的10次方,需要启动10个线程执行,这仅是对一个1024大小的数组的排序,如果有多个数组排序,开辟线程会不会很多？其实不用担心这个,因为`async`的实现方式在上一节中已经提及了,是通过`std::launch::async`或者`std::launch::deffered`完成的。编译器会计算当前能否开辟线程,如果能则使用`std::launch::async`模式开辟线程,如果不能则采用`std::launch::deffered`串行执行。当然,我们也可以通过我们上文提及的线程池方式实现并行计算

### ThreadPool方式的并行排序

```c++
//线程池版本
//并行版本
template<typename T>
std::list<T> thread_pool_quick_sort(std::list<T> input)
{
    if (input.empty())
    {
        return input;
    }
    std::list<T> result;
    result.splice(result.begin(), input, input.begin());
    T const& pivot = *result.begin();
    auto divide_point = std::partition(input.begin(), input.end(),
        [&](T const& t) {return t < pivot; });
    std::list<T> lower_part;
    lower_part.splice(lower_part.end(), input, input.begin(),
        divide_point);
    // ①因为lower_part是副本,所以并行操作不会引发逻辑错误,这里投递给线程池处理
    auto new_lower = ThreadPool::commit(&parallel_quick_sort<T>, std::move(lower_part));
    // ②
    auto new_higher(
        parallel_quick_sort(std::move(input)));
    result.splice(result.end(), new_higher);
    result.splice(result.begin(), new_lower.get());
    return result;
}
```

通过如下方式测试
```c++
void test_thread_pool_sort() {
    std::list<int> numlists = { 6,1,0,7,5,2,9,-1 };
    auto sort_result = thread_pool_quick_sort(numlists);
    std::cout << "sorted result is ";
    for (auto iter = sort_result.begin(); iter != sort_result.end(); iter++) {
        std::cout << " " << (*iter);
    }
    std::cout << std::endl;
}
```

到此我们实现了多种版本的快速排序,并不是鼓励读者造轮子,而是提供一种并行处理的思想,相信读者在后续的工作中在合适的时机采用并行处理的方式,可以极大的提高程序处理问题的效率。

## Actor和CSP设计模式

本文介绍两种并发设计中常用的设计模式,包括Actor和CSP模式。传统的并发设计经常都是通过共享内存加锁保证逻辑安全,这种模式有几个缺点,包括1 频繁加锁影响性能,2 耦合度高。后来大家提出了Actor和CSP设计模式。

### Actor设计模式
简单点说,actor通过**消息传递**的方式与外界通信。消息传递是**异步**的。每个actor都有一个邮箱,该邮箱接收并缓存其他actor发过来的消息,actor一次只能同步处理一个消息,处理消息过程中,除了可以接收消息,不能做任何其他操作。
每一个类独立在一个线程里称作Actor,Actor之间通过队列通信,比如Actor1 发消息给Actor2, Actor2 发消息给Actor1都是投递到对方的队列中。好像给对方发邮件,对方从邮箱中取出一样。如下图

<img src="https://cdn.llfc.club/1696556496577.jpg" alt="image.png" style="zoom:80%;" />

Actor模型的另一个好处就是可以**消除共享状态**,因为它每次只能处理一条消息,所以actor内部可以安全的处理状态,而不用考虑锁机制。

<img src="https://cdn.llfc.club/img_2f50c511653189037c3ac1a36c7962a2.png" alt="image.png" style="zoom:80%;" />
我们在网络编程中对于逻辑层的处理就采用了将要处理的逻辑消息封装成包投递给逻辑队列,逻辑类从队列中消费的思想,其实就是一种Actor设计模式。Erlang是天然支持Actor的语言。

actor相比单逻辑线程就是它相当于有多个逻辑线程,把逻辑分了类,一个了类属于一个Actor,耦合低,这是对比单逻辑线程的优点。

### CSP模式
CSP 是 Communicating Sequential Process 的简称,中文可以叫做通信顺序进程,是一种并发编程模型,是一个很强大的并发数据模型,是上个世纪七十年代提出的,用于描述两个独立的并发实体通过共享的通讯 **channel**(管道)进行通信的并发模型。相对于Actor模型,CSP中channel是第一类对象,它**不关注发送消息的实体**,而关注与发送消息时使用的channel。go是天然支持csp模式的语言。

CSP和Actor类似,只不过CSP将消息投递给channel,至于谁从channel中取数据,发送的一方是不关注的。简单的说Actor在发送消息前是直到接收方是谁,而接受方收到消息后也知道发送方是谁,更像是邮件的通信模式。而csp是**完全解耦合**的。

<img src="https://cdn.llfc.club/csp.png" alt="image.png" style="zoom:80%;" />
无论Actor还是CSP,他们都有一个共同的特性”Do not communicate by sharing memory; instead, share memory by communicating”

### go风格的csp

我们通过生产者和消费者模型给大家演示csp模式的使用方式,用go来做示例

```go
package main
import (
    "cspdemo/message"
    "fmt"
    "os"
    "os/signal"
    "syscall"
)
var closeChan chan struct{}
var sigs chan os.Signal
func init() {
    //类似于auto
    sigs = make(chan os.Signal)
    //具体类型初始化
    closeChan = make(chan struct{})
    signal.Notify(sigs, syscall.SIGINT, syscall.SIGTERM)
    //可以理解为C++ 的匿名函数,或者js的匿名函数,此处通过go原语启动一个协程并行执行
    go func() {
        sig := <-sigs
        fmt.Println("receive signal is ", sig)
        close(closeChan)
        message.ConsumerInst().Exit()
        message.ProducerInst().Exit()
    }()
}
func main() {
    fmt.Println("Main Process begin!")
    <-closeChan
    message.ConsumerInst().Join()
    message.ProducerInst().Join()
    fmt.Println("Main Process exit!")
}
```

在上面的代码中我们启动了一个协程监听Ctrl+C等退出操作,当收到Ctrl+C的信号后,会关闭closeChan这个channel。这样主函数中`<-closeChan`就会从channel中取出数据。然后等待消费者和生产者退出。

接下来我们将生产者和消费者的实现放入message包,先看下message公共数据的定义

```c++
package message
const MAX_COUNT = 200
var msgChan = make(chan int, MAX_COUNT)
```

上面的代码中我们定义了一个channel,大小为200,大家可以理解为仓库的大小为200,生产者向仓库中投递数据如果达到200就会阻塞。直到有消费者从中消费数据,如果消费者发现channel中数据为0,则阻塞。

```go
package message
import (
    "context"
    "fmt"
    "sync"
    "time"
)
var producer *Producer = nil
var producer_once sync.Once
func init() {
    // Consumer1 = new(Consumer)
    //类似于C++ std::call_once
    producer_once.Do(func() {
        producer = new(Producer)
        producer._exited = make(chan struct{})
        producer._ctx, producer._cancel = context.WithCancel(context.Background())
        producer.StartWork()
    })
}
func ProducerInst() *Producer {
    return producer
}
type Producer struct {
    _exited chan struct{}
    _ctx    context.Context
    _cancel context.CancelFunc
}
func (producer *Producer) Join() {
    <-producer._exited
    fmt.Println("producer exited")
}
func (producer *Producer) Exit() {
    producer._cancel()
}
func (producer *Producer) StartWork() {
    go func() {
        i := 0
        for {
            i++
            select {
            case <-producer._ctx.Done():
                {
                    close(producer._exited)
                    return
                }
            case msgChan <- i:
                fmt.Println("producer produce number is ", i)
            }
            time.Sleep(50 * time.Millisecond)
        }
    }()
}
```

我们通过init函数中只调用一次的方式初始化了`producer`,之后生成了一个名为`_exited`的channel,用来通知Join返回。  
同样我们还初始化了一个可以取消的context,主要是在Exit函数内调用cancel取消上下文,会触发`StartWork`中`producer._ctx.Done()`进而终止生产工作,再发出退出信号,达到优雅退出的效果。

类似的消费者也是相似逻辑

```go
package message
import (
    "context"
    "fmt"
    "sync"
    "time"
)
var consumer *Consumer = nil
var consumer_once sync.Once
func init() {
    // Consumer1 = new(Consumer)
    //类似于C++ std::call_once
    consumer_once.Do(func() {
        consumer = new(Consumer)
        consumer._exited = make(chan struct{})
        consumer._ctx, consumer._cancel = context.WithCancel(context.Background())
        consumer.StartWork()
    })
}
func ConsumerInst() *Consumer {
    return consumer
}
type Consumer struct {
    _exited chan struct{}
    _ctx    context.Context
    _cancel context.CancelFunc
}
func (consumer *Consumer) Join() {
    <-consumer._exited
    fmt.Println("consumer exited")
}
func (consumer *Consumer) Exit() {
    consumer._cancel()
}
func (consumer *Consumer) StartWork() {
    go func() {
        i := 0
        for {
            select {
            case <-consumer._ctx.Done():
                {
                    close(consumer._exited)
                    return
                }
            case i = <-msgChan:
                fmt.Println("consumer consum number is ", i)
            }
            time.Sleep(100 * time.Millisecond)
        }
    }()
}
```


### C++ 风格的csp

C++是万能的,我们可以用C++实现一个类似于go的channel,采用csp模式解耦合,实现类似的生产者和消费者问题

```c++
#include <iostream>
#include <queue>
#include <mutex>
#include <condition_variable>
template <typename T>
class Channel {
private:
    std::queue<T> queue_;
    std::mutex mtx_;
    std::condition_variable cv_producer_;
    std::condition_variable cv_consumer_;
    size_t capacity_;
    bool closed_ = false;
public:
    Channel(size_t capacity = 0) : capacity_(capacity) {}
    bool send(T value) {
        std::unique_lock<std::mutex> lock(mtx_);
        cv_producer_.wait(lock, [this]() {
            // 对于无缓冲的channel,我们应该等待直到有消费者准备好
            return (capacity_ == 0 && queue_.empty()) || queue_.size() < capacity_ || closed_;
            });
        if (closed_) {
            return false;
        }
        queue_.push(value);
        cv_consumer_.notify_one();
        return true;
    }
    bool receive(T& value) {
        std::unique_lock<std::mutex> lock(mtx_);
        cv_consumer_.wait(lock, [this]() { return !queue_.empty() || closed_; });
        if (closed_ && queue_.empty()) {
            return false;
        }
        value = queue_.front();
        queue_.pop();
        cv_producer_.notify_one();
        return true;
    }
    void close() {
        std::unique_lock<std::mutex> lock(mtx_);
        closed_ = true;
        cv_producer_.notify_all();
        cv_consumer_.notify_all();
    }
};
// 示例使用
int main() {
    Channel<int> ch(10);  // 10缓冲的channel
    std::thread producer([&]() {
        for (int i = 0; i < 5; ++i) {
            ch.send(i);
            std::cout << "Sent: " << i << std::endl;
        }
        ch.close();
        });
    std::thread consumer([&]() {
        std::this_thread::sleep_for(std::chrono::milliseconds(500)); // 故意延迟消费者开始消费
        int val;
        while (ch.receive(val)) {
            std::cout << "Received: " << val << std::endl;
        }
        });
    producer.join();
    consumer.join();
    return 0;
}
```

简单来说就是通过条件变量实现通信的阻塞和同步的。

### 利用csp思想实现取款逻辑
《C++并发编程实战》一书中提及了用csp思想实现atm机取款逻辑,我根据书中思想,整理了通信的示意图,书中部分代码存在问题,也一并修复了。

<img src="https://cdn.llfc.club/1696562243686.jpg" alt="image.png" style="zoom:80%;" />

主函数实现

```c++
// Actor.cpp : 此文件包含 "main" 函数。程序执行将在此处开始并结束。
//
#include <iostream>
#include "message.h"
#include "withdraw_msg.h"
#include "atm.h"
#include "dispatcher.h"
#include "bank_matchine.h"
#include "interface_matchine.h"
int main()
{
    bank_machine bank;
    interface_machine interface_hardware;
    atm machine(bank.get_sender(), interface_hardware.get_sender());
    std::thread bank_thread(&bank_machine::run, &bank);
    std::thread if_thread(&interface_machine::run, &interface_hardware);
    std::thread atm_thread(&atm::run, &machine);
    messaging::sender atmqueue(machine.get_sender());
    bool quit_pressed = false;
    while (!quit_pressed)
    {
        char c = getchar();
        switch (c)
        {
        case '0':
        case '1':
        case '2':
        case '3':
        case '4':
        case '5':
        case '6':
        case '7':
        case '8':
        case '9':
            atmqueue.send(digit_pressed(c));
            break;
        case 'b':
            atmqueue.send(balance_pressed());
            break;
        case 'w':
            atmqueue.send(withdraw_pressed(50));
            break;
        case 'c':
            atmqueue.send(cancel_pressed());
            break;
        case 'q':
            quit_pressed = true;
            break;
        case 'i':
            atmqueue.send(card_inserted("acc1234"));
            break;
        }
    }
    bank.done();
    machine.done();
    interface_hardware.done();
    atm_thread.join();
    bank_thread.join();
    if_thread.join();
}
```

主函数中启动了三个线程,分别处理bank,`machine`以及`interface`的操作。  
由于代码复杂解析来只列举atm类的实现

```c++
#pragma once
#include "dispatcher.h"
#include <functional>
#include <iostream>
class atm
{
    messaging::receiver incoming;
    messaging::sender bank;
    messaging::sender interface_hardware;
    void (atm::* state)();
    std::string account;
    unsigned withdrawal_amount;
    std::string pin;
    void process_withdrawal()
    {
        incoming.wait().handle<withdraw_ok, std::function<void(withdraw_ok const& msg)>,
            messaging::dispatcher >(
                [&](withdraw_ok const& msg)
                {
                    interface_hardware.send(
                        issue_money(withdrawal_amount));
                    bank.send(
                        withdrawal_processed(account, withdrawal_amount));
                    state = &atm::done_processing;
                }, "withdraw_ok").handle<withdraw_denied, std::function<void(withdraw_denied const& msg)>>(
                        [&](withdraw_denied const& msg)
                        {
                            interface_hardware.send(display_insufficient_funds());
                            state = &atm::done_processing;
                    }, "withdraw_denied").handle<cancel_pressed, std::function<void(cancel_pressed const& msg)>>(
                        [&](cancel_pressed const& msg)
                        {
                            bank.send(
                                cancel_withdrawal(account, withdrawal_amount));
                            interface_hardware.send(
                                display_withdrawal_cancelled());
                            state = &atm::done_processing;
                        }, "cancel_pressed"
                    );
    }
    void process_balance()
    {
        incoming.wait()
            .handle<balance, std::function<void(balance const& msg)>,
            messaging::dispatcher>(
                [&](balance const& msg)
                {
                    interface_hardware.send(display_balance(msg.amount));
                    state = &atm::wait_for_action;
                },"balance"
                ).handle < cancel_pressed, std::function<void(cancel_pressed const& msg) >>(
                    [&](cancel_pressed const& msg)
                    {
                        state = &atm::done_processing;
                    }, "cancel_pressed"
                );
    }
    void wait_for_action()
    {
        interface_hardware.send(display_withdrawal_options());
        incoming.wait()
            .handle<withdraw_pressed, std::function<void(withdraw_pressed const& msg)>,
            messaging::dispatcher>(
                [&](withdraw_pressed const& msg)
                {
                    withdrawal_amount = msg.amount;
                    bank.send(withdraw(account, msg.amount, incoming));
                    state = &atm::process_withdrawal;
                }, "withdraw_pressed"
        ).handle < balance_pressed, std::function<void(balance_pressed const& msg) >>(
                    [&](balance_pressed const& msg)
                    {
                        bank.send(get_balance(account, incoming));
                        state = &atm::process_balance;
                    }, "balance_pressed"
                    ).handle<cancel_pressed, std::function<void(cancel_pressed const& msg) >>(
                        [&](cancel_pressed const& msg)
                        {
                            state = &atm::done_processing;
                        }, "cancel_pressed"
                    );
    }
    void verifying_pin()
    {
        incoming.wait()
            .handle<pin_verified, std::function<void(pin_verified const& msg)>,
            messaging::dispatcher>(
                [&](pin_verified const& msg)
                {
                    state = &atm::wait_for_action;
                }, "pin_verified"
                ).handle<pin_incorrect, std::function<void(pin_incorrect const& msg)>>(
                [&](pin_incorrect const& msg)
                {
                    interface_hardware.send(
                        display_pin_incorrect_message());
                    state = &atm::done_processing;
                }, "pin_incorrect"
                ).handle<cancel_pressed, std::function<void(cancel_pressed const& msg)>>(
                        [&](cancel_pressed const& msg)
                        {
                            state = &atm::done_processing;
                        }, "cancel_pressed"
                );
    }
    void getting_pin()
    {
        incoming.wait().handle<digit_pressed, std::function<void(digit_pressed const& msg)>,
            messaging::dispatcher>(
                [&](digit_pressed const& msg)
                {
                    unsigned const pin_length = 6;
                    pin += msg.digit;
                    if (pin.length() == pin_length)
                    {
                        bank.send(verify_pin(account, pin, incoming));
                        state = &atm::verifying_pin;
                    }
                }, "digit_pressed"
                ).handle<clear_last_pressed, std::function<void(clear_last_pressed const& msg)>>(
                [&](clear_last_pressed const& msg)
                {
                    if (!pin.empty())
                    {
                        pin.pop_back();
                    }
                }, "clear_last_pressed"
                ).handle<cancel_pressed, std::function<void(cancel_pressed const& msg)>>(
                        [&](cancel_pressed const& msg)
                        {
                            state = &atm::done_processing;
                        }, "cancel_pressed"
                );
    }
    void waiting_for_card()
    {
        interface_hardware.send(display_enter_card());
        incoming.wait().handle<card_inserted, std::function<void(card_inserted const& msg)>,
            messaging::dispatcher>(
                [&](card_inserted const& msg)
                {
                    account = msg.account;
                    pin = "";
                    interface_hardware.send(display_enter_pin());
                    state = &atm::getting_pin;
                }, "card_inserted"
        );
    }
    void done_processing()
    {
        interface_hardware.send(eject_card());
        state = &atm::waiting_for_card;
    }
    atm(atm const&) = delete;
    atm& operator=(atm const&) = delete;
public:
    atm(messaging::sender bank_,
        messaging::sender interface_hardware_) :
        bank(bank_), interface_hardware(interface_hardware_)
    {}
    void done()
    {
        get_sender().send(messaging::close_queue());
    }
    void run()
    {
        state = &atm::waiting_for_card;
        try
        {
            for (;;)
            {
                (this->*state)();
            }
        }
        catch (messaging::close_queue const&)
        {
        }
    }
    messaging::sender get_sender()
    {
        return incoming;
    }
};
```

atm 主要功能就是通过状态机不断地切换状态监听想要处理的函数。

本文讲述了Actor设计模式和CSP设计模式,并通过go和C++等语言给大家展示了csp并发设计的demo,最后通过讲解《C++并发编程实战》中取款的案例,展示了csp的用法。

## 原子操作和内存模型

### 改动序列

在一个C++程序中,每个对象都具有一个**改动序列**,它由所有线程在对象上的全部**写操作构成**,其中第一个写操作即为对象的初始化。 大部分情况下,这个序列会随程序的多次运行而发生变化,但是在程序的任意一次运行过程中,所含的全部线程都必须形成**相同的改动序列**。

改动序列基本要求如下
1. 只要某线程看到过某个对象,则该线程的后续读操作必须获得相对新近的值,并且,该线程就同一对象的后续写操作,必然出现在改动序列后方。
2. 如果某线程先向一个对象写数据,过后再读取它,那么必须读取前面写的值。
3. 若在改动序列中,上述读写操作之间还有别的写操作,则必须读取最后写的值。 
4. 在程序内部,对于同一个对象,全部线程都必须就其形成相同的改动序列,并且在所有对象上都要求如此. 
5. 多个对象上的改动序列只是相对关系,线程之间不必达成一致


### 原子类型

标准原子类型的定义位于头文件`<atomic>`内。我们可以通过`atomic<>`定义一些原子类型的变量,如`atomic<bool>`,`atomic<int>` 这些类型的操作全是原子化的。

从C++17开始,所有的原子类型都包含一个静态常量表达式成员变量,`std::atomic::is_always_lock_free`。这个成员变量的值表示在任意给定的目标硬件上,原子类型X是否始终以无锁结构形式实现。如果在所有支持该程序运行的硬件上,原子类型X都以无锁结构形式实现,那么这个成员变量的值就为true；否则为false。

只有一个原子类型不提供`is_lock_free()`成员函数：`std::atomic_flag` 。类型`std::atomic_flag`的对象在**初始化时清零**,随后即可通过成员函数`test_and_set()`查值并设置成立,或者由`clear()`清零。整个过程只有这两个操作。其他的`atomic<>`的原子类型都可以基于其实现。
`std::atomic_flag`的`test_and_set`成员函数是一个原子操作,他会先检查`std::atomic_flag`当前的状态是否被设置过,

1. 如果没被设置过(比如初始状态或者清除后),将`std::atomic_flag`当前的状态设置为`true`,并返回`false`。
2. 如果被设置过则直接返回`ture`。

对于`std::atomic<T>`类型的原子变量,还支持`load()`和`store()`、`exchange()`、`compare_exchange_weak()`和`compare_exchange_strong()`等操作。

### 内存次序

对于原子类型上的每一种操作,我们都可以提供额外的参数,从枚举类`std::memory_order`取值,用于设定所需的内存次序语义(memory-ordering semantics)。

- 枚举类std::memory_order具有6个可能的值,
	- 包括`std::memory_order_relaxed`、`std:: memory_order_acquire`、`std::memory_order_consume`、`std::memory_order_acq_rel`、`std::memory_order_release`和 `std::memory_order_seq_cst`。
- 存储(`store`)操作,可选用的内存次序有`std::memory_order_relaxed`、`std::memory_order_release`或`std::memory_order_seq_cst`。
- 载入(`load`)操作,可选用的内存次序有`std::memory_order_relaxed`、`std::memory_order_consume`、`std::memory_order_acquire`或`std::memory_order_seq_cst`。
- “读-改-写”(`read-modify-write`)操作,可选用的内存次序有`std::memory_order_relaxed`、`std::memory_order_consume`、`std::memory_order_acquire`、`std::memory_order_release`、`std::memory_order_acq_rel`或`std::memory_order_seq_cst`。
- 原子操作默认使用的是`std::memory_order_seq_cst`次序。

这六种内存顺序相互组合可以实现三种顺序模型 (ordering model)
- `Sequencial consistent ordering.` 实现同步, 且保证全局顺序一致 (single total order) 的模型. 是一致性最强的模型, 也是默认的顺序模型. 
- `Acquire-release ordering.` 实现同步, 但不保证保证全局顺序一致的模型. 
- `Relaxed ordering.` 不能实现同步, 只保证原子性的模型.


### 实现自旋锁

自旋锁是一种在多线程环境下保护共享资源的同步机制。它的基本思想是,当一个线程尝试获取锁时,如果锁已经被其他线程持有,那么该线程就会不断地循环检查锁的状态,直到成功获取到锁为止。

那我们用这个`std:atomic_flag`实现一个自旋锁。

```c++
#include <iostream>
#include <atomic>
#include <thread>

class SpinLock {
public:
    void lock() {
        //1 处
        while (flag.test_and_set(std::memory_order_acquire)); // 自旋等待,直到成功获取到锁
    }

    void unlock() {
        //2 处
        flag.clear(std::memory_order_release); // 释放锁
    }

private:
    std::atomic_flag flag = ATOMIC_FLAG_INIT;
};
```

我们实现一个测试函数

```c++
void TestSpinLock() {
    SpinLock spinlock;
    std::thread t1([&spinlock]() {
        spinlock.lock();
        for (int i = 0; i < 3; i++) {
            std::cout << "*";
            }
        std::cout << std::endl;
        spinlock.unlock();
        });


    std::thread t2([&spinlock]() {
        spinlock.lock();
        for (int i = 0; i < 3; i++) {
            std::cout << "?";
        }
        std::cout << std::endl;
        spinlock.unlock();
        });


    t1.join();
    t2.join();
}
```

在主函数执行上述代码会看到如下输出
```
***
???
```

- 在多线程调用时,仅有一个线程在同一时刻进入`test_and_set`,因为`atomic_flag`初始状态为false,所以`test_and_set`将`atomic_flag`设置为`true`,并且返回`false`。
- 比如线程A调用了`test_and_set`返回`false`,这样`lock`函数返回,线程A继续执行加锁区域的逻辑。此时线程B调用`test_and_set`,`test_and_set`会返回true,导致线程B在`while`循环中循环等待,达到自旋检测标记的效果。当线程A直行至2处调用`clear`操作后,`atomic_flag`被设置为清空状态,线程B调用`test_and_set`会将状态设为成立并返回false,B线程执行加锁区域的逻辑。

我们看到在设置时使用`memory_order_acquire`内存次序,在清除时使用了`memory_order_release`内存次序。

### 宽松内存序

为了给大家介绍不同的字节序,我们先从最简单的字节序`std::memory_order_relaxed`(宽松字节序)介绍。 因为字节序是为了实现改动序列的,所以为了理解字节序还要结合改动序列讲起。

我们先看一个CPU和内存结构图

<img src="https://cdn.llfc.club/1697539893049.jpg" alt="image.png" style="zoom:70%;" />
- 其中StoreBuffer就是一级Cache, Catche是二级Cache,Memory是三级Cache。
- 每个标识CPU的块就是core,上图画的就是4核结构。每两个core**构成一个bank**,共享一个cache。四个core共享memory。
- 每个CPU所作的store均会写到store buffer中,每个CPU会在任何时刻将store buffer中结果写入到cache或者memory中。

那该如何保证数据一致性？这就要提及MESI一致性协议。
MESI 协议,是一种叫作写失效(Write Invalidate)的协议。在写失效协议里,只有一个CPU核心负责写入数据,其他的核心,只是同步读取到这个写入。在这个 CPU 核心写入 cache 之后,它会去广播一个“失效”请求告诉所有其他的 CPU 核心。

MESI 协议对应的四个不同的标记,分别是：
- M：代表已修改(Modified)
- E：代表独占(Exclusive)
- S：代表共享(Shared)
- I：代表已失效(Invalidated)
"已修改"用来告诉其他cpu已经修改完成,其他cpu可以向cache中写入数据。
"独占"表示数据只是加载到当前CPU核的store buffer中,其他的CPU核,并没有加载对应的数据到自己的store buffer里。
这个时候,如果要向独占的 store buffer 写入数据,我们可以自由地写入数据,而不需要告知其他 CPU 核。
那么对应的,共享状态就是在多核中同时加载了同一份数据。所以在共享状态下想要修改数据要先向所有的其他CPU核心广播一个请求,要求先把其他CPU核心里面的cache,都变成无效的状态,然后再更新当前cache里面的数据。

我们可以这么理解,如果变量a此刻在各个cpu的StoreBuffer中,那么CPU1核修改这个a的值,放入cache时通知其他CPU核写失效,因为同一时刻仅有一个CPU核可以写数据,但是其他CPU核是可以读数据的,那么其他核读到的数据可能是CPU1核修改之前的。这就涉及我们提到的改动序列了。

#并发面试点
在无锁数据结构中,特别是使用CAS操作时,CPU的空转开销可能源于缓存一致性协议的开销。假设多个线程试图使用CAS操作来修改同一个变量：
假设有两个线程,分别运行在不同的CPU核心上,试图使用CAS操作来修改同一个共享变量：
1. **初始状态**：共享变量在两个CPU核心的缓存中,状态为`Shared`。
2. **线程A尝试写入**：线程A使用CAS操作尝试修改共享变量。如果成功,该缓存行在线程A所在核心的缓存中变为`Modified`状态,并广播失效请求,使其他核心中的该缓存行变为`Invalid`。
3. **线程B尝试写入**：线程B尝试使用CAS操作修改共享变量,因为它的缓存行已经无效,需要从主存重新加载最新值,并再次尝试CAS操作。
4. **反复重试**：如果线程B在加载最新值后,又立即尝试CAS操作,而线程A已经再次修改了共享变量,线程B的CAS操作将再次失败,需要再次重试。这导致了忙等待。
**忙等待与锁的比较**
- **锁**：当线程尝试获取锁而失败时,它通常会被挂起,等待锁释放。这种情况下,线程不消耗CPU时间片,直到锁可用。
- **无锁**：在无锁数据结构中,线程在CAS操作失败时,会立即重试。这种忙等待(spinning)会消耗CPU时间片,直到操作成功。

**低竞争场景** (几乎没有空转开销)
```c++
atomic<int> counter{0};

// 两个线程很少同时操作
Thread A: counter++  // 成功
Thread B: ...做其他事...
Thread A: ...做其他事...
Thread B: counter++  // 成功
```

**高竞争场景** (产生严重的空转开销)
```c++
atomic<int> counter{0};

// 多个线程频繁操作同一个变量
Thread A: counter++ // 成功
Thread B: counter++ // 失败,重试
Thread C: counter++ // 失败,重试
Thread D: counter++ // 失败,重试
```


这里给大家简单介绍两个改动序列的术语

1. "`synchronizes-with`":同步, "A synchronizes-with B" 的意思就是A和B同步,简单来说如果多线程环境下,有一个线程先修改了变量m,我们将这个操作叫做A,之后有另一个线程读取变量m,我们将这个操作叫做B,那么B一定读取A修改m之后的最新值。也可以称作A"happens-before"B,即A操作的结果对B操作可见。 
2. "`happens-before`":先行,"A happens-before B" 的意思是如果A操作先于B操作,那么A操作的结果对B操作可见。"happens-before"包含很多种境况,不仅仅是我们上面提到的"synchronizes-with",之后给大家一个脑图详细说明"happens-before"的几种情况。


我们接下来谈谈`std::memory_order_relaxed`。

关于`std::memory_order_relaxed`具备如下几个功能：
1. 作用于原子变量
2. 不具有`synchronizes-with`关系
3. 对于同一个原子变量,在同一个线程中具有`happens-before`关系, 在同一线程中不同的原子变量不具有`happens-before`关系,可以乱序执行。
4. 多线程情况下不具有`happens-before`关系。

由上述可知,如果采用最松散的内存顺序模型,在一个线程中,如果某个表达式已经看到原子变量的某个值a,则该表达式的后续表达式只能看到a或者比a更新的值。
我们看下面的代码

```c++
std::atomic<bool> x, y;
std::atomic<int> z;

void write_x_then_y() {
    x.store(true, std::memory_order_relaxed);  // 1
    y.store(true, std::memory_order_relaxed);  // 2
}

void read_y_then_x() {
    while (!y.load(std::memory_order_relaxed)) { // 3
        std::cout << "y load false" << std::endl;
    }

    if (x.load(std::memory_order_relaxed)) { //4
        ++z;
    }

}
```


上面的代码封装了两个函数,`write_x_then_y`负责将x和y存储为true。`read_y_then_x`负责读取x和y的值。
接下来我们写如下函数调用上面的两个函数
```c++
void TestOrderRelaxed() {
    std::thread t1(write_x_then_y);
    std::thread t2(read_y_then_x);
    t1.join();
    t2.join();
    assert(z.load() != 0); // 5
}
```

上面的代码assert断言z不为0,但有时运行到5处z会等于0触发断言。
我们从两个角度分析

1. 从cpu架构分析
	假设线程t1运行在CPU1上,t2运行在CPU3上,那么t1对x和y的操作,t2是看不到的。
	比如当线程t1运行至1处将x设置为true,t1运行至2处将y设置为true。这些操作仅在CPU1的`store buffer`中,还未放入cache和memory中,CPU2自然不知道。
	如果CPU1先将y放入memory,那么CPU2就会读取y的值为true。那么t2就会运行至3处从while循环退出,进而运行至4处,此时CPU1还未将x的值写入memory,
	t2读取的x值为false,进而线程t2运行结束,然后CPU1将x写入true, t1结束运行,最后主线程运行至5处,因为z为0,所以触发断言。 
2. 从宽松内存序分析 
	因为`memory_order_relaxed`是宽松的内存序列,它**只保证操作的原子性**,并不能保证多个变量之间的**顺序性**,也不能保证同一个变量在不同线程之间的可见顺序。
	比如t1可能先运行2处代码再运行1处代码,因为我们的代码会被编排成指令执行,编译器在不破坏语义的情况下(2处和1处代码无耦合,可调整顺序),2可能先于1执行(叫做**指令重排**,是为了优化性能)。如果这样,t2运行至3处退出while循环,继续运行4处,此时t1还未执行1初代码,则t2运行4处条件不成立不会对z做增加,t2结束。这样也会导致z为0引发断言。


画个图说明上述情况

<img src="https://cdn.llfc.club/1697596279730.jpg" alt="image.png" style="zoom:80%;" />
我们在看一个例子

```c++
void TestOderRelaxed2() {
    std::atomic<int> a{ 0 };
    std::vector<int> v3, v4;
        std::thread t1([&a]() {
            for (int i = 0; i < 10; i += 2) {
                a.store(i, std::memory_order_relaxed);
            }    
        });

        std::thread t2([&a]() {
            for (int i = 1; i < 10; i += 2)
                a.store(i, std::memory_order_relaxed);
            });


        std::thread t3([&v3, &a]() {
            for (int i = 0; i < 10; ++i)
                v3.push_back(a.load(std::memory_order_relaxed));
            });

        std::thread t4([&v4, &a]() {
            for (int i = 0; i < 10; ++i)
                v4.push_back(a.load(std::memory_order_relaxed));
            });

        t1.join();
        t2.join(); 
        t3.join(); 
        t4.join();

        for (int i : v3) {
            std::cout << i << " ";
        }

        std::cout << std::endl;
        for (int i : v4) {
            std::cout << i << " ";
        }
        std::cout << std::endl;
}
```

线程t1向a中存储偶数,线程t2向a中存储奇数。线程t3从a读取数据写入v3中,线程t4从线程a中读取数据写入v4中。这四个线程并发执行,最后打印v3和v4的数据。 如果机器性能足够好我们看到的可能是这种输出

```c++
9 9 9 9 9 9 9 9 9 9
9 9 9 9 9 9 9 9 9 9
```

也可能是这种
```c++
0 1 7 6 8 9 9 9 9 9 
0 2 1 4 5 7 6 8 9 9
```

但我们能确定的是如果v3中7先于6,8,9等,那么v4中也是7先于6,8,9。
因为多个线程仅操作了a变量,通过`memory_order_relaxed`的方式仅能保证对a的操作是原子的(同一时刻仅有一个线程写a的值,但是可能多个线程读取a的值)。
但是多个线程之间操作不具备同步关系,也就是线程t1将a改为7,那么线程t3不知道a改动的最新值为7,它读到a的值为1。只是要过一阵子可能会读到7或者a变为7之后又改动的其他值。
但是t3,t4两个线程读取a的次序是一致的,比如t3和t4都读取了7和9,t3读到7在9之前,那么t4也读取到7在9之前。
因为我们`memory_order_relaxed`保证了多线程对同一个变量的原子操作的安全性,只是可见性会有延迟罢了。

### 先行(Happens-before)

Happens-before是一个非常重要的概念. 如前文我们提及： 如果操作 a “happens-before” 操作 b, 则操作 a 的结果对于操作 b 可见. happens-before 的关系可以建立在用一个线程的两个操作之间, 也可以建立在不同的线程的两个操作之间。

#### 顺序先行(sequenced-before)
单线程情况下前面的语句先执行,后面的语句后执行。操作a先于操作b,那么操作b可以看到操作a的结果。我们称操作a顺序先行于操作b。也就是"a sequenced-before b"。
这种情况下"a happens before b"
比如下面
```c++
int main(){
    //操作a
    int m = 100;
    //操作b
    std::cout << "m is " << std::endl;
}
```

上面操作b 能读取m的值为100.
"`sequencde-before"`具备传递性,比如操作 `a “sequenced-before”` 操作 b, 且操作 b “sequenced-before” 操作 m, 则操作 a “sequenced-before” 操作 m.

<img src="https://cdn.llfc.club/1697601383740.jpg" alt="image.png" style="zoom:70%;" />

#### 线程间先行

线程间先行又叫做"inter-thread-happens-before",这是多线程情况的"happens-before".
我们前面提到的"synchronizes-with" 可以构成 "happens-before"。
如果线程1中的操作 a “synchronizes-with” 线程 2 中的操作 b, 则操作 a “inter-thread happens-before” 操作 b.

<img src="https://cdn.llfc.club/1697609727864.jpg" alt="image.png" style="zoom:60%;" />

此外 synchronizes-with 还可以 “后接” 一个sequenced-before关系组合成inter-thread happens-before 的关系:
比如操作 a “synchronizes-with” 操作b, 且操作 b “sequenced-before” 操作 m, 则操作 a “inter-thread happens-before” 操作 m.

<img src="https://cdn.llfc.club/1697609586958.jpg" alt="image.png" style="zoom:60%;" />
那同样的道理, Inter-thread happens-before 关系则可以 “前接” 一个 sequenced-before 关系以延伸它的范围; 而且 inter-thread happens-before 关系具有传递性:
1. 如果操作 a “sequenced-before” 操作 k, 且操作 k “inter-thread happens-before” 操作 b, 则操作 a “inter-thread happens-before” 操作 b.

	<img src="https://cdn.llfc.club/1697610467141.jpg" alt="image.png" style="zoom:60%;" />
2. 如果操作 a “inter-thread happens-before” 操作 k, 且操作 k “inter-thread happens-before” 操作 b, 则操作 a “inter-thread happens-before” 操作 b.

	<img src="https://cdn.llfc.club/1697610652291.jpg" alt="image.png" style="zoom:60%;" />


#### 依赖关系
依赖关系有 carries dependency 和 dependency-ordered before.
单线程情况下a “sequenced-before” b, 且 b 依赖 a 的数据, 则 a “carries a dependency into” b. 称作a将依赖关系带给b, 也理解为b依赖于a。
看下面的代码
```c++
void TestDependency() {
    // 1 处
    std::string str = "hello world!";
    // 2 处
    int i = 3;
    // 3 处
    std::cout << str[i] << std::endl;
}
```

函数`TestDependency`内部打印`str[i]`的值。3处代码需要依赖1处和2处两个变量的值,所以达成依赖关系。
我们看单线程情况下按顺序执行1,2,3处代码,1 “sequenced-before” 3,且3依赖1的数据,则 1 "carries a dependency into" 3
同样的道理2"sequenced-before" 3, 且3依赖2 的数据,则2 "carries a dependency into" 3.
"carries a dependency into" 也被归为"happens-before"。

<img src="https://cdn.llfc.club/1697614479597.jpg" alt="image.png" style="zoom:60%;" />


2. 多线程情况下
线程1执行操作A(比如对i自增),线程2执行操作B(比如根据i访问字符串下表的元素), 如果线程1先于线程2执行,且操作A的结果对操作B可见,我们将这种叫做 A "dependency-ordered before" B. 有人会说这不是前面说到的A "synchronizes with " B吗？你可以这么理解。就当作他们达到的效果是一致的,只不过A "dependency-ordered before" B 更细化一点,表述了一种依赖,比如操作A仅仅对i增加,而没有对字符串修改。而操作B需要通过i访问字符串数据。那操作B实际上是依赖于A的。


### Happens-before不代表指令执行顺序

Happens-before不代表指令实际执行顺序,C++编译器可以对不相关的指令任意编排达到优化效果,Happens-before仅是C++语义层面的描述,表示 a "Happens-before" b仅能说明a操作的结果对b操作可见。

看这样一段代码
```c++
int  Add() {
    int a = 0, b = 0;
    //1 处
    a++; 
    // 2 处
    b++;
    // 3 处
    return  a + b;
}
```
单线程执行上述代码,操作1一定是happens-before操作2的(a "sequenced-before" b),就是我们理解的 a++ 先于 b++。
但是计算机的指令可能不是这样,一条C++语句对于多条计算机指令。
有可能是先将b值放入寄存器eax做加1,再将a的值放入寄存器edx做加1,然后再将eax寄存器的值写回a,将edx写回b。
因为对于计算机来说1处操作和2处操作的顺序对于3处来说并无影响。只要3处返回a+b之前能保证a和b的值是增加过的即可。
那我们语义上的"Happens-before"有意义吗？ 是有意义的,因为如果 a "sequenced-before" b, 那么无论指令如何编排,最终写入内存的顺序一定是a先于b。

只不过C++编译器不断优化尽可能不造成指令编排和语义理解的差异,上面C++的代码转换为汇编指令如下
```c++
    int a = 0, b = 0;
00A1C8F5  mov         dword ptr [a],0  
00A1C8FC  mov         dword ptr [b],0  
    //1 处
    a++; 
00A1C903  mov         eax,dword ptr [a]  
00A1C906  add         eax,1  
00A1C909  mov         dword ptr [a],eax  
    // 2 处
    b++;
00A1C90C  mov         eax,dword ptr [b]  
00A1C90F  add         eax,1  
00A1C912  mov         dword ptr [b],eax  
    return  a + b;
00A1C915  mov         eax,dword ptr [a]  
00A1C918  add         eax,dword ptr [b]
```

可以看到C++编译器尽可能不造成语义理解和指令编排上的歧义。

### 脑图
我们将"happens-before" 的几种情况做成脑图,方便理解 

<img src="https://cdn.llfc.club/Happens-before%E8%84%91%E5%9B%BE%20%281%29.png" alt="image.png" style="zoom:80%;" />

我们画一个框将"happens-before" 的几种情况框起来

<img src="https://cdn.llfc.club/1697694671481.jpg" alt="image.png" style="zoom:80%;" />


## 通过内存顺序实现内存模型

### memory_order_seq_cst

`memory_order_seq_cst`代表全局一致性顺序,可以用于 `store`, `load` 和 `read-modify-write` 操作, 实现 `sequencial consistent` 的顺序模型. 在这个模型下, 所有线程看到的所有操作都有一个一致的顺序, 即使这些操作可能针对不同的变量, 运行在不同的线程.

我们看一下之前写的代码

```c++
std::atomic<bool> x, y;
std::atomic<int> z;

void write_x_then_y() {
    x.store(true, std::memory_order_relaxed);  // 1
    y.store(true, std::memory_order_relaxed);  // 2
}

void read_y_then_x() {
    while (!y.load(std::memory_order_relaxed)) { // 3
        std::cout << "y load false" << std::endl;
    }

    if (x.load(std::memory_order_relaxed)) { //4
        ++z;
    }

}

void TestOrderRelaxed() {

    std::thread t1(write_x_then_y);
    std::thread t2(read_y_then_x);
    t1.join();
    t2.join();
    assert(z.load() != 0); // 5
}
```

上面的代码`load`和`store`都采用的是`memory_order_relaxed`。线程t1按次序执行1和2,但是线程t2看到的可能是y为true,x为false。进而导致`TestOrderRelaxed`触发断言z为0. 如果换成`memory_order_seq_cst`则能保证所有线程看到的执行顺序是一致的。

```c++
void write_x_then_y() {
    x.store(true, std::memory_order_seq_cst);  // 1
    y.store(true, std::memory_order_seq_cst);  // 2
}

void read_y_then_x() {
    while (!y.load(std::memory_order_seq_cst)) { // 3
        std::cout << "y load false" << std::endl;
    }

    if (x.load(std::memory_order_seq_cst)) { //4
        ++z;
    }

}

void TestOrderSeqCst() {

    std::thread t1(write_x_then_y);
    std::thread t2(read_y_then_x);
    t1.join();
    t2.join();
    assert(z.load() != 0); // 5
}
```

上面的代码x和y采用的是`memory_order_seq_cst`, 所以当线程t2执行到3处并退出循环时我们可以断定y为true,因为是全局一致性顺序,所以线程t1已经执行完2处将y设置为true,那么线程t1也一定执行完1处代码并对t2可见,所以当t2执行至4处时x为true,那么会执行z++保证z不为零,从而不会触发断言。

实现`sequencial consistent`模型有一定的开销. 现代CPU通常有多核, 每个核心还有自己的缓存. 为了做到全局顺序一致, 每次写入操作都必须同步给其他核心. 为了减少性能开销, 如果不需要全局顺序一致, 我们应该考虑使用更加宽松的顺序模型.

### memory_order_relaxed

memory_order_relaxed 可以用于 store, load 和 read-modify-write 操作, 实现 relaxed 的顺序模型. 前文我们介绍过这种模型下, 只能保证操作的原子性和修改顺序 (modification order) 一致性, 无法实现 synchronizes-with 的关系。

```c++  
void TestOrderRelaxed() {
    std::atomic<bool> rx, ry;

    std::thread t1([&]() {
        rx.store(true, std::memory_order_relaxed); // 1
        ry.store(true, std::memory_order_relaxed); // 2
        });


    std::thread t2([&]() {
        while (!ry.load(std::memory_order_relaxed)); //3
        assert(rx.load(std::memory_order_relaxed)); //4
        });

    t1.join();
    t2.join();
}
```

上面的代码在一定程度上会触发断言。因为线程t1执行完1,2之后,有可能2操作的结果先放入内存中被t2看到,此时t2执行退出3循环进而执行4,此时t2看到的rx值为false触发断言。
我们称2和3不构成同步关系,2 "not synchronizes with" 3
如果能保证2的结果立即被3看到, 那么称 2 "synchronizes with " 3。
如果2同步于3还有一层意思就是 如果在线程t1中1先于2(sequence before), 那么1先行于3。那我们可以理解t2执行到3处时,可以获取到t1执行1操作的结果,也就是rx为true.
t2线程中3先于4(sequence before),那么1操作先行于4. 也就是1操作的结果可以立即被4获取。进而不会触发断言。
怎样保证2同步于3是解决问题的关键,我们引入 Acquire-Release 内存顺序。


### Acquire-Release

在`acquire-release`模型中, 会使用memory_order_acquire, memory_order_release 和 memory_order_acq_rel这三种内存顺序. 它们的用法具体是这样的:
对原子变量的load可以使用`memory_order_acquire`内存顺序. 这称为acquire操作.
对原子变量的store可以使用`memory_order_release`内存顺序. 这称为release操作.
read-modify-write操作即读(load)又写(store), 它可以使用memory_order_acquire, memory_order_release和memory_order_acq_rel:
1. 如果使用`memory_order_acquire`, 则作为acquire操作;
2. 如果使用`memory_order_release`, 则作为release操作;
3. 如果使用`memory_order_acq_rel`, 则同时为两者.


`Acquire-release`可以实现`synchronizes-with`的关系. 如果一个acquire操作在同一个原子变量上读取到了一个release操作写入的值, 则这个release操作 “synchronizes-with”这个acquire操作.

我们可以通过`Acquire-release`修正`TestOrderRelaxed`函数以达到同步的效果
```c++
void TestReleaseAcquire() {
    std::atomic<bool> rx, ry;

    std::thread t1([&]() {
        rx.store(true, std::memory_order_relaxed); // 1
        ry.store(true, std::memory_order_release); // 2
        });


    std::thread t2([&]() {
        while (!ry.load(std::memory_order_acquire)); //3
        assert(rx.load(std::memory_order_relaxed)); //4
        });

    t1.join();
    t2.join();
}
```


上面的例子中我们看到`ry.store`使用的是`std::memory_order_release`, `ry.load`使用的是`std::memory_order_relaxed`.
t1执行到2将ry设置为true, 因为使用了Acquire-release 顺序， 所以t2 执行到3时读取ry为true， 因此2和3可以构成同步关系。
又因为单线程t1内 1 sequence before 2,所以1 happens-before 3. 因为单线程t2内 3 sequence before 4. 所以 1 happens-before 4.

### Release sequences

我们再考虑一种情况，多个线程对同一个变量release操作，另一个线程对这个变量acquire，那么只有一个线程的release操作喝这个acquire线程构成同步关系。
看下面的代码 ：

```C++
void ReleasAcquireDanger2() {
    std::atomic<int> xd{0}, yd{ 0 };
    std::atomic<int> zd;

    std::thread t1([&]() {
        xd.store(1, std::memory_order_release);  // (1)
        yd.store(1, std::memory_order_release); //  (2)
        });

    std::thread t2([&]() {
        yd.store(2, std::memory_order_release);  // (3)
        });


    std::thread t3([&]() {
        while (!yd.load(std::memory_order_acquire)); //（4）
        assert(xd.load(std::memory_order_acquire) == 1); // (5)
        });

    t1.join();
    t2.join();
    t3.join();
}
```

我们可以看到t3在yd为true的时候才会退出，那么导致yd为true的有两种情况，一种是1，另一种是2，所以5处可能触发断言。
并不是只有在acquire操作读取到release操作写入的值时才能构成 synchronizes-with 关系. 为了说这种情况, 我们需要引入release sequence这个概念.
针对一个原子变量M的release操作A完成后, 接下来M上可能还会有一连串的其他操作. 如果这一连串操作是由
1. 同一线程上的写操作
2. 任意线程上的read-modify-write操作这两种构成的, 则称这一连串的操作为以release操作A为首的 release sequence. 这里的写操作和read-modify-write操作可以使用任意内存顺序.

如果一个acquire操作在同一个原子变量上读到了一个release操作写入的值, 或者读到了以这个release操作为首的release sequence写入的值, 那么这个release操作“synchronizes-with”这个acquire操作.

看下面的代码

```C++
void ReleaseSequence() {
    std::vector<int> data;
    std::atomic<int> flag{ 0 };

    std::thread t1([&]() {
        data.push_back(42);  //(1)
        flag.store(1, std::memory_order_release); //(2)
        });

    std::thread t2([&]() {
        int expected = 1;
        while (!flag.compare_exchange_strong(expected, 2, std::memory_order_relaxed)) // (3)
            expected = 1;
        });

    std::thread t3([&]() {
        while (flag.load(std::memory_order_acquire) < 2); // (4)
        assert(data.at(0) == 42); // (5)
        });

    t1.join();
    t2.join();
    t3.join();
}
```

我们考虑t3要想退出首先flag要等于2，那么就要等到t2将flag设置为2，而flag设置为2又要等到t1将flag设置为1. 所以我们捋一下顺序 `2->3->4`

t1中操作2是release操作，以2为开始，其他线程(t2)的读改写在release操作之后，我们称之为release sequence，t3要读取release sequence写入的值，所以我们称t1的release操作"synchronizes with"t3的acquire操作。

### memory_order_consume

`memory_order_consume` 其实是 `acquire-release` 模型的一部分,但是它比较特殊,它涉及到数据间相互依赖的关系. 就是前文我们提及的`carries dependency`和 `dependency-ordered before`.

我们复习一下
如果操作a“sequenced-before”b, 且b依赖a的数据, 则a“carries a dependency into”b. 一般来说, 如果a的值用作b的一个操作数, 或者b读取到了a写入的值, 都可以称为b依赖于a

```c++
p++;   // (1)
i++;   // (2)
p[i]   // (3)
```

(1) "sequenced-before" (2), (2) "sequenced-before" (3), 而(1)和(2)的值作为(3)的下表运算符`[]`的操作数。
我们可以称(1)"carries a dependency into" (3), (2)"carries a dependency into" (3), 但是(1)和(2)不是依赖关系。
memory_order_consume可以用于load操作. 使用memory_order_consume的load称为consume操作. 如果一个consume操作在同一个原子变量上读到了一个release操作写入的值, 或以其为首的release sequence写入的值, 则这个release操作“dependency-ordered before”这个consume操作.
看下面这个例子

```c++
void ConsumeDependency() {
    std::atomic<std::string*> ptr;
    int data;
    std::thread t1([&]() {
        std::string* p = new std::string("Hello World"); // (1)
        data = 42; // (2)
        ptr.store(p, std::memory_order_release); // (3)
        });

    std::thread t2([&]() {
        std::string* p2;
        while (!(p2 = ptr.load(std::memory_order_consume))); // (4)
        assert(*p2 == "Hello World"); // (5)
        assert(data == 42); // (6)
        });
        
    t1.join();
    t2.join();
}
```


t2执行到(4)处时，需要等到ptr非空才能退出循环，这就依赖t1执行完(3)操作。
因此(3)"dependency-ordered before"(4), 根据前文我们介绍了dependency等同于synchronizes ，所以(3)"inter-thread happens-before".（4）
因为(2)"sequenced before"(3), 所以(2)"happens-before"(4)
因为(4)"sequenced before"(5), 所以(2)"happens-before"(5)
因为(5)"sequenced before"(6), 所以(2)"happens-before"(6)
所以(6)处断言不会触发，同样的道理(5)处断言也不会触发。


### 单例模式改良

还记得我们之前用智能指针双重检测方式实现的单例模式吗？我当时说过是存在线程安全问题的，看看下面这段单例模式

```c++
//利用智能指针解决释放问题
class SingleAuto
{
private:
    SingleAuto()
    {
    }
    SingleAuto(const SingleAuto&) = delete;
    SingleAuto& operator=(const SingleAuto&) = delete;
public:
    ~SingleAuto()
    {
        std::cout << "single auto delete success " << std::endl;
    }
    static std::shared_ptr<SingleAuto> GetInst()
    {
        // 1 处
        if (single != nullptr)
        {
            return single;
        }
        // 2 处
        s_mutex.lock();
        // 3 处
        if (single != nullptr)
        {
            s_mutex.unlock();
            return single;
        }
        // 4处
        single = std::shared_ptr<SingleAuto>(new SingleAuto);
        s_mutex.unlock();
        return single;
    }
private:
    static std::shared_ptr<SingleAuto> single;
    static std::mutex s_mutex;
};
```

我们写一段代码测试一下

```c++
std::shared_ptr<SingleAuto> SingleAuto::single = nullptr;
std::mutex SingleAuto::s_mutex;

void TestSingle() {
    std::thread t1([]() {
        std::cout << "thread t1 singleton address is 0X: " << SingleAuto::GetInst() << std::endl;
        });

    std::thread t2([]() {
        std::cout << "thread t2 singleton address is 0X: " << SingleAuto::GetInst() << std::endl;
        });

    t2.join();
    t1.join();
}
```

虽然可以正常输出两次的地址都是同一个，但是我们的单例会存在安全隐患。 1处和4处代码存在线程安全问题，因为4处代码在之前的文章中我谈过，new一个对象再赋值给变量时会存在多个指令顺序

第一种情况
```c++
1 为对象allocate一块内存空间
2 调用construct构造对象
3 将构造到的对象地址返回
```

第二种情况

```c++
1 为对象allocate一块内存空间
2 先将开辟的空间地址返回
3 调用construct构造对象
```

如果是第二种情况，在4处还未构造对象就将地址返回赋值给single，而此时有线程运行至1处判断single不为空直接返回单例实例，如果该线程调用这个单例的成员函数就会崩溃。
为了解决这个问题，我们可以通过内存模型来解决

```c++
//利用智能指针解决释放问题
class SingleMemoryModel
{
private:
    SingleMemoryModel()
    {
    }
    SingleMemoryModel(const SingleMemoryModel&) = delete;
    SingleMemoryModel& operator=(const SingleMemoryModel&) = delete;
public:
    ~SingleMemoryModel()
    {
        std::cout << "single auto delete success " << std::endl;
    }
    static std::shared_ptr<SingleMemoryModel> GetInst()
    {
        // 1 处
        if (_b_init.load(std::memory_order_acquire))
        {
            return single;
        }
        // 2 处
        s_mutex.lock();
        // 3 处
        if (_b_init.load(std::memory_order_relaxed))
        {
            s_mutex.unlock();
            return single;
        }
        // 4处
        single = std::shared_ptr<SingleMemoryModel>(new SingleMemoryModel);
        _b_init.store(true, std::memory_order_release);
        s_mutex.unlock();
        return single;
    }
private:
    static std::shared_ptr<SingleMemoryModel> single;
    static std::mutex s_mutex;
    static std::atomic<bool> _b_init ;
};

std::shared_ptr<SingleMemoryModel> SingleMemoryModel::single = nullptr;
std::mutex SingleMemoryModel::s_mutex;
std::atomic<bool> SingleMemoryModel::_b_init = false;
```

然后我们测试

```c++
void TestSingleMemory() {
    std::thread t1([]() {
        std::cout << "thread t1 singleton address is 0x: " << SingleMemoryModel::GetInst() << std::endl;
        });

    std::thread t2([]() {
        std::cout << "thread t2 singleton address is 0x: " << SingleMemoryModel::GetInst() << std::endl;
        });

    t2.join();
    t1.join();
}
```

也可以看到输出的地址一致，但是我们这个改进的版本防止了线程安全问题。

## 无锁并发队列
### 环形队列

我们要实现无锁并发，经常会用到一种结构无锁队列，而无锁队列和我们经常使用的队列颇有不同，它采用的是环状的队列结构，为什么成环呢？主要有两个好处，一个是成环的队列**大小是固定**的，另外一个我们通过移动头和尾就能实现数据的插入和取出。

我们看下图是一个环形队列的基本结构

<img src="https://cdn.llfc.club/4a6ee05475ca071cc608c9eb35920af.png" alt="image.png" style="zoom:60%;" />

图1表示队列为空的时候，头节点和尾节点交会在一起，指向同一个扇区。
图2表示当我们你插入一个数字1后，队列大小为1，此时tail指针移动到下一个扇区，head指向头部，1被存储在头部了。
图3表示当我们将数字1出队后，head指针向后移动一个扇区，此时head和tail指向同一个扇区，表示队列又为空了。那有人会问队列中数字1为什么不清空呢？其实不用清空，因为当我们插入新数据时就可以覆盖掉1这个无效的数据。
比如我们继续3图，连续插入几个数字，将队列填满。

<img src="https://cdn.llfc.club/1698926107471.jpg" alt="image.png" style="zoom:60%;" />
图4说明的就是当我们连续插入了几个数字，插入数据9的时候将原来1的数据覆盖了，所以环形队列删除数据的时候我们不用让数据出队，只要移动head指针即可。
另外我们从图4也能看出，此时tail指向的位置正好是head的前一个位置，这种情况表示队列满了。

### 用锁实现环形队列

我们可以用锁实现上述环形队列，在push和pop时分别加锁，并通过head和tail计算队列是否为满或者空。
代码比较简单，可以看看下面的写法

```c++
#include <iostream>
#include <mutex>
#include <memory>

template<typename T, size_t Cap>
class CircularQueLk :private std::allocator<T> {
public:
    CircularQueLk() :_max_size(Cap + 1),_data(std::allocator<T>::allocate(_max_size)), _head(0), _tail(0) {}
    CircularQueLk(const CircularQueLk&) = delete;
    CircularQueLk& operator = (const CircularQueLk&) volatile = delete;
    CircularQueLk& operator = (const CircularQueLk&) = delete;

    ~CircularQueLk() {
        //循环销毁
        std::lock_guard<std::mutex>  lock(_mtx);
        //调用内部元素的析构函数
        while (_head != _tail) {
            std::allocator<T>::destroy(_data + _head);
            _head = （_head+1）% _max_size;
        }
        //调用回收操作
        std::allocator<T>::deallocate(_data, _max_size);
    }

    //先实现一个可变参数列表版本的插入函数最为基准函数
    template <typename ...Args>
    bool emplace(Args && ... args) {
        std::lock_guard<std::mutex> lock(_mtx);
        //判断队列是否满了
        if ((_tail + 1) % _max_size == _head) {
            std::cout << "circular que full ! " << std::endl;
            return false;
        }
        //在尾部位置构造一个T类型的对象，构造参数为args...
        std::allocator<T>::construct(_data + _tail, std::forward<Args>(args)...);
        //更新尾部元素位置
        _tail = (_tail + 1)% _max_size;
        return true;
    }

    //push 实现两个版本，一个接受左值引用，一个接受右值引用

    //接受左值引用版本
    bool push(const T& val) {
        std::cout << "called push const T& version" << std::endl;
        return emplace(val);
    }

    //接受右值引用版本，当然也可以接受左值引用，T&&为万能引用
    // 但是因为我们实现了const T&
    bool push(T&& val) {
        std::cout << "called push T&& version" << std::endl;
        return emplace(std::move(val));
    }

    //出队函数
    bool pop(T& val) {
        std::lock_guard<std::mutex> lock(_mtx);
        //判断头部和尾部指针是否重合，如果重合则队列为空
        if (_head == _tail) {
            std::cout << "circular que empty ! " << std::endl;
            return false;
        }
        //取出头部指针指向的数据
        val = std::move(_data[_head]);
        //更新头部指针
        _head = (_head + 1) % _max_size;
        return true;
    }
private:
    size_t _max_size;
    T* _data;
    std::mutex _mtx;
    size_t _head = 0;
    size_t _tail = 0;
};
```

测试也比较简单，我们写一个函数，初始化队列大小为5，测试队列push满的情况和pop直到为空的情况

```c++
void TestCircularQue() {
    //最大容量为10
    CircularQueLk<MyClass, 5> cq_lk;
    MyClass mc1(1);
    MyClass mc2(2);
    cq_lk.push(mc1);
    cq_lk.push(std::move(mc2));
    for (int i = 3; i <= 5; i++) {
        MyClass mc(i);
        auto res = cq_lk.push(mc);
        if (res == false) {
            break;
        }
    }

    cq_lk.push(mc2);

    for (int i = 0; i < 5; i++) {
        MyClass mc1;
        auto res = cq_lk.pop(mc1);
        if (!res) {
            break;
        }
        std::cout << "pop success, " << mc1 << std::endl;
    }

    auto res = cq_lk.pop(mc1);
}
```

结果如下
```c++
called push const T& version
called push T&& version
called push const T& version
called push const T& version
called push const T& version
called push const T& version
circular que full !

pop success, MyClass Data is 1
pop success, MyClass Data is 2
pop success, MyClass Data is 3
pop success, MyClass Data is 4
pop success, MyClass Data is 5
circular que empty !
```

### 无锁队列

那如果我们用原子变量而不是用锁实现环形队列，那就是无锁并发的队列了。还记得我们之前提到的原子变量的读改写操作吗？
```c++
bool std::atomic<T>::compare_exchange_weak(T &expected, T desired);
bool std::atomic<T>::compare_exchange_strong(T &expected, T desired);
```

`compare_exchange_strong`会比较原子变量`atomic<T>`的值和`expected`的值是否相等，如果相等则执行交换操作，将`atomic<T>`的值换为`desired`并且返回true,否则将expected的值修改为bool变量的值，并且返回false.

其伪代码可以这么理解
```c++
template <typename T>
bool atomic<T>::compare_exchange_strong(T &expected, T desired) {
    std::lock_guard<std::mutex> guard(m_lock);
    if (m_val == expected) // m_val相当于atomic<T>的值
        return m_val = desired, true;
    else
        return expected = m_val, false;
}
```

`compare_exchange_weak`功能比`compare_exchange_strong`弱一些，他不能保证`atomic<T>`的值和`expected`的值相等时也会做交换，很可能原子变量和预期值相等也会返回false，所以使用要多次循环使用。

我们们定义一个类`CircularQueSeq`, 其内容和之前我们定义的类CircularQueLk差不多，只不过将类的成员变量mutex换成atomic类型的原子变量, 我们可以利用自旋锁的思路将锁替换为原子变量循环检测的方式，进而达到锁住互斥逻辑的效果。

大家可以先看一下全部的代码感受一下

```c++
template<typename T, size_t Cap>
class CircularQueSeq :private std::allocator<T> {
public:
    CircularQueSeq() :_max_size(Cap + 1), _data(std::allocator<T>::allocate(_max_size)), _atomic_using(false),_head(0), _tail(0) {}
    CircularQueSeq(const CircularQueSeq&) = delete;
    CircularQueSeq& operator = (const CircularQueSeq&) volatile = delete;
    CircularQueSeq& operator = (const CircularQueSeq&) = delete;

    ~CircularQueSeq() {
        //循环销毁
        bool use_expected = false;
        bool use_desired = true;
        do
        {
            use_expected = false;
            use_desired = true;
        }
        while (!_atomic_using.compare_exchange_strong(use_expected, use_desired));
        //调用内部元素的析构函数
        while (_head != _tail) {
            std::allocator<T>::destroy(_data + _head);
            _head = （_head+1）% _max_size;
        }
        //调用回收操作
        std::allocator<T>::deallocate(_data, _max_size);

        do
        {
            use_expected = true;
            use_desired = false;
        }
        while (!_atomic_using.compare_exchange_strong(use_expected, use_desired));
    }

    //先实现一个可变参数列表版本的插入函数最为基准函数
    template <typename ...Args>
    bool emplace(Args && ... args) {

        bool use_expected = false;
        bool use_desired = true;
        do
        {
            use_expected = false;
            use_desired = true;
        }
        while (!_atomic_using.compare_exchange_strong(use_expected, use_desired));

        //判断队列是否满了
        if ((_tail + 1) % _max_size == _head) {
            std::cout << "circular que full ! " << std::endl;
            do
            {
                use_expected = true;
                use_desired = false;
            }
            while (!_atomic_using.compare_exchange_strong(use_expected, use_desired));
            return false;
        }
        //在尾部位置构造一个T类型的对象，构造参数为args...
        std::allocator<T>::construct(_data + _tail, std::forward<Args>(args)...);
        //更新尾部元素位置
        _tail = (_tail + 1) % _max_size;

        do
        {
            use_expected = true;
            use_desired = false;
        }
        while (!_atomic_using.compare_exchange_strong(use_expected, use_desired));

        return true;
    }

    //push 实现两个版本，一个接受左值引用，一个接受右值引用

    //接受左值引用版本
    bool push(const T& val) {
        std::cout << "called push const T& version" << std::endl;
        return emplace(val);
    }

    //接受右值引用版本，当然也可以接受左值引用，T&&为万能引用
    // 但是因为我们实现了const T&
    bool push(T&& val) {
        std::cout << "called push T&& version" << std::endl;
        return emplace(std::move(val));
    }

    //出队函数
    bool pop(T& val) {

        bool use_expected = false;
        bool use_desired = true;
        do
        {
            use_desired = true;
            use_expected = false;
        } while (!_atomic_using.compare_exchange_strong(use_expected, use_desired));
        //判断头部和尾部指针是否重合，如果重合则队列为空
        if (_head == _tail) {
            std::cout << "circular que empty ! " << std::endl;
            do
            {
                use_expected = true;
                use_desired = false;
            }
            while (!_atomic_using.compare_exchange_strong(use_expected, use_desired));
            return false;
        }
        //取出头部指针指向的数据
        val = std::move(_data[_head]);
        //更新头部指针
        _head = (_head + 1) % _max_size;

        do
        {
            use_expected = true;
            use_desired = false;
        }while (!_atomic_using.compare_exchange_strong(use_expected, use_desired));
        return true;
    }
private:
    size_t _max_size;
    T* _data;
    std::atomic<bool> _atomic_using;
    size_t _head = 0;
    size_t _tail = 0;
};
```

我们可以看到`emplace`函数以及`pop`函数等将锁替换为原子变量。采用`do while`的方式就是因为`compare_exchange_strong`比较原子变量和`use_expected`的值不同的时候会使`use_expected`改变，所以我们需要在再次循环之前重置`use_expected`和`use_desired`的值。

我们可以写一个函数在单线程情况下下测试一下

```c++
void TestCircularQueSeq()
{
    CircularQueSeq<MyClass, 3> cq_seq;
    for(int i = 0; i < 4; i++)
    {
        MyClass mc1(i);
        auto res = cq_seq.push(mc1);
        if(!res)
        {
            break;
        }
    }

    for(int i = 0; i < 4; i++)
    {
        MyClass mc1;
        auto res = cq_seq.pop(mc1);
        if(!res)
        {
            break;
        }

        std::cout << "pop success, " << mc1 << std::endl;
    }

    for (int i = 0; i < 4; i++)
    {
        MyClass mc1(i);
        auto res = cq_seq.push(mc1);
        if (!res)
        {
            break;
        }
    }

    for (int i = 0; i < 4; i++)
    {
        MyClass mc1;
        auto res = cq_seq.pop(mc1);
        if (!res)
        {
            break;
        }

        std::cout << "pop success, " << mc1 << std::endl;
    }
}
```

运行结果

```c++
called push const T& version
called push const T& version
called push const T& version
called push const T& version
circular que full !
pop success, MyClass Data is 0
pop success, MyClass Data is 1
pop success, MyClass Data is 2
circular que empty !
called push const T& version
called push const T& version
called push const T& version
called push const T& version
circular que full !
pop success, MyClass Data is 0
pop success, MyClass Data is 1
pop success, MyClass Data is 2
circular que empty !
```

多线程情况下也能保证安全是因为原子变量循环检测保证有且只有一个线程修改成功。读取也是这样。

### 单一原子变量的弊端

我们考虑上述单一原子变量的弊端
多个线程push和pop操作耦合读太高，同一时刻仅有一个线程pop或者push，而且互斥逻辑的精度不够。影响效率。
我们需要考虑将pop和push操作**解耦**，我们采用的是环形队列，将`tail`和`head`作为原子变量可以实现精细控制。
比如我们做push操作的时候，一个线程更新万`tail`标签和数据后，其他线程就可以pop或者push了，精细控制的好处就是效率提升。
我们定义一个新的类CircularQueLight，类的基本数据结构和CircularQueSeq差不多。

```c++
template<typename T, size_t Cap>
class CircularQueLight: private std::allocator<T>
{
public:
    CircularQueLight():_max_size(Cap + 1),
    _data(std::allocator<T>::allocate(_max_size))
    , _head(0), _tail(0) {}

    CircularQueLight(const CircularQueLight&) = delete;
    CircularQueLight& operator = (const CircularQueLight&) volatile = delete;
    CircularQueLight& operator = (const CircularQueLight&) = delete;
private:
    size_t _max_size;
    T* _data;
    std::atomic<size_t>  _head;
    std::atomic<size_t> _tail;
};
```

我们将`_head`和`_tail`替换为原子变量。
接下来我们考虑`pop`逻辑
```c++
    bool pop(T& val) {

        size_t h;
        do
        {
            h = _head.load();  //1 处
            //判断头部和尾部指针是否重合，如果重合则队列为空
            if(h == _tail.load())
            {
                return false;
            }
            val = _data[h]; // 2处

        } while (!_head.compare_exchange_strong(h, 
            (h+1)% _max_size)); //3 处

        return true;
    }
```

在pop逻辑里我们在1处load获取头部head的值，在2处采用了复制的方式将头部元素取出赋值给val，而不是通过`std::move`，因为多个线程同时`pop`最后只有一个线程成功执行3处代码退出，而失败的则需要继续循环，从更新后的head处`pop`元素。所以不能用`std::move`，否则会破坏原有的队列数据。

接下来我们来做push的函数逻辑

```c++
    bool push(T& val)
    {
        size_t t;
        do
        {
            t = _tail.load(); //1
            //判断队列是否满
            if( (t+1)%_max_size == _head.load())
            {
                return false;
            }

            _data[t] = val; //2

        } while (!_tail.compare_exchange_strong(t,
            (t + 1) % _max_size)); //3

        return true;
    }
```

push函数的逻辑乍一看和pop一样，但是我们会发现多线程push的情况存在线程安全问题。
比如我们线程1 `push(1)` 而线程2 `push(2)`. 很有可能的顺序是
1.1 -> 1.2 -> 2.1 -> 2.2 -> 1.3

这样我们看到的效果就是`_data[t]`被存储为2了，而实际情况应该是被存储为1，因为线程1的原子变量生效，而线程2的原子变量不满足需继续循环。所以`_data[t]`必须修改为1.
那我们改进一下`push`的函数

```c++
  bool push(T& val)
    {
        size_t t;
        do
        {
            t = _tail.load();  //1
            //判断队列是否满
            if( (t+1)%_max_size == _head.load())
            {
                return false;
            }



        } while (!_tail.compare_exchange_strong(t,
            (t + 1) % _max_size));  //3

        _data[t] = val; //2

        return true;
    }
```

我们将2处的代码移动到循环之外，这样能保证多个线程push，仅有一个线程生效时，他写入的数据一定是本线程要写入到tail的数据，而此时tail被缓存在t里，那是一个线程本地变量，所以在这种情况下我们能确定即使多个线程运行到2处，他们的t值也是不同的，并不会产生线程安全问题。

毕竟多个线程push数据时对资源的竞争仅限tail。
但是这种push操作仍然会有安全问题
我们思考这种情况

<img src="https://cdn.llfc.club/1699154222424.jpg" alt="image.png" style="zoom:60%;" />

此时head和tail都指向1这个位置，当我们执行`push(9)`时，按照我们的逻辑会先执行3再执行2.
也就是会先将tail移动，然后更新1的值为9.
那如果我们更新了tail之后，还没来的及更新1为9，那么此时如果有其他的线程读取head的值，会读取到1，而不是9.
从多线程安全角度来讲这是不安全的，我们理想的情况是一个线程写完数据后另一个线程读取的就是之前写入的最新值。
为了解决这个问题，我们可以增加另一个原子变量`_tail_update`来标记尾部数据是否修改完成，如果尾部数据没有修改完成，此时其他线程pop时获取的数据就是不安全的，所以pop要返回false。

先实现push版本

```c++
    bool push(const T& val)
    {
        size_t t;
        do
        {
            t = _tail.load();  //1
            //判断队列是否满
            if( (t+1)%_max_size == _head.load())
            {
                return false;
            }



        } while (!_tail.compare_exchange_strong(t,
            (t + 1) % _max_size));  //3

        _data[t] = val; //2
        size_t tailup;
        do
        {
            tailup = t;

        } while (_tail_update.compare_exchange_strong(tailup, 
            (tailup + 1) % _max_size));
        return true;
    }
```

再实现pop版本

```c++
    bool pop(T& val) {

        size_t h;
        do
        {
            h = _head.load();  //1 处
            //判断头部和尾部指针是否重合，如果重合则队列为空
            if(h == _tail.load())
            {
                return false;
            }

            //判断如果此时要读取的数据和tail_update是否一致，如果一致说明尾部数据未更新完
            if(h == _tail_update.load())
            {
                return false;
            }
            val = _data[h]; // 2处

        } while (!_head.compare_exchange_strong(h, 
            (h+1)% _max_size)); //3 处

        return true;
    }
```

pop版本也是，先判断队列是否为空，再判断h是否和`_tail_update`的值相等，如果相等说明有写数据的没更新完，直接返回false或者循环等待也行，为了方便我们直接返回false即可。

因为我们知道原子操作默认采用的是`memory_order_seq_cst`内存顺序，性能上不是最优的，我们可以用`acquire`和`release`的内存顺序实现同步的效果。

### 优化性能

我们用acquire和release模型优化上述代码，实现同步。最简单的方式就是将load的地方变为`memory_order_relaxed`，`compare_exchange_strong`的地方变为`memory_order_release`

我们先看pop操作

```c++
    bool pop(T& val) {

        size_t h;
        do
        {
            h = _head.load(std::memory_order_relaxed);  //1 处
            //判断头部和尾部指针是否重合，如果重合则队列为空
            if (h == _tail.load(std::memory_order_acquire)) //2处
            {
                std::cout << "circular que empty ! " << std::endl;
                return false;
            }

            //判断如果此时要读取的数据和tail_update是否一致，如果一致说明尾部数据未更新完
            if (h == _tail_update.load(std::memory_order_acquire)) //3处
            {
                return false;
            }
            val = _data[h]; // 2处

        } while (!_head.compare_exchange_strong(h,
            (h + 1) % _max_size, std::memory_order_release, std::memory_order_relaxed)); //4 处
        std::cout << "pop data success, data is " << val << std::endl;
        return true;
    }
```

两个线程协同工作，一个线程先push，另一个线程后pop，那么对于tail部分和_tail_update，我们要保证push的结果`_data[t] = val;`先于pop的结果`val = _data[h];`
所以push线程中对于_tail_update的compare_exchange_strong操作采用`memory_order_release`方式。
pop线程对于_tail_update的load操作采用`memory_order_acquire`。
如果一个线程先pop，另一个线程先push，那么对于head部分，我们要保证pop的结果`val = _data[h];`先于pop的结果`_data[t] = val;`。

### 思考

- 优势
	- 无锁高并发. 虽然存在循环重试, 但是这只会在相同操作并发的时候出现. push 不会因为与pop并发而重试, 反之亦然.

- 缺陷
	- 这样队列只应该存储**标量**, 如果存储类对象时，多个push线程只有一个线程push成功，而拷贝复制的开销很大，其他线程会循环重试，每次重试都会有开销。


## 利用栅栏实现同步

前文我们通过原子操作实战实现了无锁队列，今天完善一下无锁的原子操作剩余的知识，包括Relaese和Acquire内存序在什么情况下是存在危险的，以及我们可以利用栅栏机制实现同步等等。

### 线程可见顺序

我们提到过除了`memory_order_seq_cst`顺序，其他的顺序都不能保证原子变量修改的值在其他多线程中看到的顺序是一致的。
但是可以通过同步机制保证一个线程对原子变量的修改对另一个线程可见。通过“Syncronizes With” 的方式达到先行的效果。
但是我们说的先行是指 “A Syncronizes With B ”， 如果A的结果被B读取，则A先行于B。
有时候我们线程1对A的store操作采用release内存序，而线程2对B的load采用acquire内存序，并不能保证A 一定比 B先执行。因为两个线程并行执行无法确定先后顺序，我们指的先行不过是说如果B读取了A操作的结果，则称A先行于B。


我们看下面的一段案例

```c++
#include <iostream>
#include <atomic>
#include <thread>
#include <cassert>
std::atomic<bool> x, y;
std::atomic<int> z;

void write_x()
{
    x.store(true, std::memory_order_release); //1
}
void write_y()
{
    y.store(true, std::memory_order_release); //2
}
void read_x_then_y()
{
    while (!x.load(std::memory_order_acquire));
    if (y.load(std::memory_order_acquire))   //3
        ++z;
}
void read_y_then_x()
{
    while (!y.load(std::memory_order_acquire));
    if (x.load(std::memory_order_acquire))   //4
        ++z;
}
```

我们写一个函数测试，函数TestAR中初始化x和y为false， 启动4个线程a,b,c,d，分别执行write_x, write_y, read_x_then_y, read_y_then_x.

```c++
void TestAR()
{
    x = false;
    y = false;
    z = 0;
    std::thread a(write_x);
    std::thread b(write_y);
    std::thread c(read_x_then_y);
    std::thread d(read_y_then_x);
    a.join();
    b.join();
    c.join();
    d.join();
    assert(z.load() != 0); //5
    std::cout << "z value is " << z.load() << std::endl;
}
```

有的读者可能会觉5处的断言不会被触发，他们认为c和d肯定会有一个线程对z执行++操作。他们的思路是这样的。 
1. 如果c线程执行read_x_then_y没有对z执行加加操作，那么说明c线程读取的x值为true, y值为false。
2. 之后d线程读取时，如果保证执行到4处说明y为true，等d线程执行4处代码时x必然为true。
3. 他们的理解是如果x先被store为true，y后被store为true，c线程看到y为false时x已经为true了，那么d线程y为true时x也早就为true了，所以z一定会执行加加操作。

上述理解是不正确的，我们提到过即便是releas和acquire顺序也不能保证多个线程看到的一个变量的值是一致的，更不能保证看到的多个变量的值是一致的。

变量x和y的载入操作3和4有可能都读取false值（与宽松次序的情况一样），因此有可能令断言触发错误。变量x和y分别由不同线程写出，所以两个释放操作都不会影响到对方线程。

看下图

<img src="https://cdn.llfc.club/1699748355232.jpg" alt="image.png" style="zoom:60%;" />
无论x和y的store顺序谁先谁后，线程c和线程d读取的x和y顺序都不一定一致。
从CPU的角度我们可以这么理解

<img src="https://cdn.llfc.club/1699750613188.jpg" alt="image.png" style="zoom:60%;" />

在一个4核CPU结构的主机上，a,b,c,d分别运行在不同的CPU内核上。
a执行`x.store(true)`先被线程c读取，而此时线程b对y的store还没有被c读取到新的值，所以此时c读取的x为true，y为false。
同样的道理，d可以读取b修改y的最新值，但是没来的及读取x的最新值，那么读取到y为true，x为false。
即使我们采用release和acquire方式也不能保证全局顺序一致。如果一个线程对变量执行release内存序的store操作，另一个线程不一定会马上读取到。这个大家要理解。

### 栅栏

有时候我们可以通过栅栏保证指令编排顺序。
看下面一段代码

```C++
#include <atomic>
#include <thread>
#include <assert.h>
std::atomic<bool> x,y;
std::atomic<int> z;
void write_x_then_y()
{
    x.store(true,std::memory_order_relaxed); // 1
    y.store(true,std::memory_order_relaxed);   // 2
}
void read_y_then_x()
{
    while(!y.load(std::memory_order_relaxed));  // 3
    if(x.load(std::memory_order_relaxed))  // 4
        ++z;
}
int main()
{
    x=false;
    y=false;
    z=0;
    std::thread a(write_x_then_y);
    std::thread b(read_y_then_x);
    a.join();
    b.join();
    assert(z.load()!=0);  //5
}
```

上面的代码我们都采用的是`memory_order_relaxed`, 所以无法保证a线程将x,y修改后b线程看到的也是先修改x，再修改y的值。b线程可能先看到y被修改为true，x后被修改为true，那么b线程执行到4处时x可能为false导致z不会加加，5处断言会被触发。

那我们之前做法可以解决这个问题

```c++
void write_x_then_y3()
{
    x.store(true, std::memory_order_relaxed); // 1
    y.store(true, std::memory_order_release);   // 2
}

void read_y_then_x3()
{
    while (!y.load(std::memory_order_acquire));  // 3
    if (x.load(std::memory_order_relaxed))  // 4
        ++z;
}
```

可以通过`std::memory_order_release`和`std::memory_order_acquire`形成同步关系。
线程a执行`write_x_then_y3`，线程b执行`read_y_then_x3`，如果线程b执行到4处，说明y已经被线程a设置为true。
线程a执行到2，也必然执行了1，因为是`memory_order_release`的内存顺序，所以线程a能2操作之前的指令在2之前被写入内存。
同样的道理，线程b在3处执行的是`memory_order_acquire`的内存顺序，所以能保证4不会先于3写入内存，这样我们能知道1一定先行于4.
进而推断出z会加加，所以不会触发`assert(z.load() != 0);`的断言。
其实我们可以通过栅栏机制保证指令的写入顺序。栅栏的机制和`memory_order_release`类似。

```c++
void write_x_then_y_fence()
{
    x.store(true, std::memory_order_relaxed);  //1
    std::atomic_thread_fence(std::memory_order_release);  //2
    y.store(true, std::memory_order_relaxed);  //3
}

void read_y_then_x_fence()
{
    while (!y.load(std::memory_order_relaxed));  //4
    std::atomic_thread_fence(std::memory_order_acquire); //5
    if (x.load(std::memory_order_relaxed))  //6
        ++z;
}
```

我们写一个函数测试上面的逻辑
```c++
void TestFence()
{
    x = false;
    y = false;
    z = 0;
    std::thread a(write_x_then_y_fence);
    std::thread b(read_y_then_x_fence);
    a.join();
    b.join();
    assert(z.load() != 0);   //7
}
```

7处的断言也不会触发。我们可以分析一下，
线程a运行`write_x_then_y_fence`，线程b运行`read_y_then_x_fence`.
当线程b执行到5处时说明4已经结束，此时线程a看到y为true，那么线程a必然已经执行完3.
尽管4和3我们采用的是`std::memory_order_relaxed`顺序，但是通过逻辑关系保证了3的结果同步给4，进而"3 happens-before 4"
因为我们采用了栅栏`std::atomic_fence`所以，5处能保证6不会先于5写入内存，(memory_order_acquire保证其后的指令不会先于其写入内存)
2处能保证1处的指令先于2写入内存，进而"1 happens-before 6", 1的结果会同步给 6
所以"atomic_thread_fence"其实和"release-acquire"相似，都是保证`memory_order_release`之前的指令不会排到其后，`memory_order_acquire`之后的指令不会排到其之前。 


## 基于锁实现线程安全的队列与栈

### 线程安全的栈

实现一个线程安全的栈，我们能想到的是基于锁控制push和pop操作，比如下面的逻辑

```c++
#include <exception>
#include <mutex>
#include <stack>
#include <condition_variable>

struct empty_stack : std::exception
{
    const char* what() const throw();
};
 
template<typename T>
class threadsafe_stack
{
private:
    std::stack<T> data;
    mutable std::mutex m;
public:
    threadsafe_stack() {}

    threadsafe_stack(const threadsafe_stack& other)
    {
        std::lock_guard<std::mutex> lock(other.m);
        data = other.data;
    }

    threadsafe_stack& operator=(const threadsafe_stack&) = delete;

    void push(T new_value)
    {
        std::lock_guard<std::mutex> lock(m);
        data.push(std::move(new_value));    // ⇽-- - 1
    }

    std::shared_ptr<T> pop()
    {
        std::lock_guard<std::mutex> lock(m);
        if (data.empty()) throw empty_stack();  //  ⇽-- - 2
            std::shared_ptr<T> const res(
                std::make_shared<T>(std::move(data.top())));   // ⇽-- - 3
            data.pop();   // ⇽-- - 4
            return res;
    }

    void pop(T& value)
    {
        std::lock_guard<std::mutex> lock(m);
        if (data.empty()) throw empty_stack();
        value = std::move(data.top());   // ⇽-- - 5
            data.pop();   // ⇽-- - 6
    }

    bool empty() const
    {
        std::lock_guard<std::mutex> lock(m);
        return data.empty();
    }
};
```


我们实现了push操作和pop操作
1. push操作里加锁，然后将数据通过`std::move`的方式移动放入stack中。我们思考如果1处因为机器内存不足push导致异常，此种情况并不会对栈已有的数据产生危险。
但是vector容器大家要考虑，因为vector存在内存不足时将数据拷贝转移到新空间的过程。那么对于vector这种动态扩容的容器该如何保证容器内数据在移动过程中出现了异常仍能不丢失呢？
我想到的一个方式就是管理vector的capacity，每次push的时候要判断一下vector的size和capacity是否相等，如果相等则手动扩容并将数据转移到新的vector，再释放旧有的vector。

但是同样会存在一个问题就是会造成内存溢出，因为vector的capacity会随着数据增加而增加，当vector中没有数据的时候capacity仍然很大。这种方式也可以通过swap的方式将当前大容量的vector和一个空的vector做交换，快速清空内存。这些操作和思路需结合实际开发情况而定。

1. pop提供了两个版本，一个是返回智能指针一个是返回bool类型，这两种我们分析，比如3处和4处也很可能因为内存不足导致构造智能指针失败，或者5处赋值失败，这种情况下抛出异常并不会影响栈内数据，因为程序没走到4和6处就抛出异常了。
    
2. pop函数内部判断栈是否空，如果为空则抛出异常，这种情况我们不能接受，异常是用来处理和预判突发情况的，对于一个栈为空这种常见现象，仅需根据返回之后判断为空再做尝试或放弃出栈即可。
    
为了解决栈为空就抛出异常的问题，我们可以做如下优化

```c++
template<typename  T>
class threadsafe_stack_waitable
{
private:
    std::stack<T> data;
    mutable std::mutex m;
    std::condition_variable cv;
public:
    threadsafe_stack_waitable() {}

    threadsafe_stack_waitable(const threadsafe_stack_waitable& other)
    {
        std::lock_guard<std::mutex> lock(other.m);
        data = other.data;
    }

    threadsafe_stack_waitable& operator=(const threadsafe_stack_waitable&) = delete;

    void push(T new_value)
    {
        std::lock_guard<std::mutex> lock(m);
        data.push(std::move(new_value));    // ⇽-- - 1
        cv.notify_one();
    }

    std::shared_ptr<T> wait_and_pop()
    {
        std::unique_lock<std::mutex> lock(m);
        cv.wait(lock, [this]()   
            {
                if(data.empty())
                {
                    return false;
                }
                return true;
            }); //  ⇽-- - 2


        std::shared_ptr<T> const res(
            std::make_shared<T>(std::move(data.top())));   // ⇽-- - 3
        data.pop();   // ⇽-- - 4
        return res;
    }

    void wait_and_pop(T& value)
    {
        std::unique_lock<std::mutex> lock(m);
        cv.wait(lock, [this]()
            {
                if (data.empty())
                {
                    return false;
                }
                return true;
            });

        value = std::move(data.top());   // ⇽-- - 5
        data.pop();   // ⇽-- - 6
    }

    bool empty() const
    {
        std::lock_guard<std::mutex> lock(m);
        return data.empty();
    }

    bool try_pop(T& value)
    {
        std::lock_guard<std::mutex> lock(m);
        if(data.empty())
        {
            return false;
        }

        value = std::move(data.top());
        data.pop();
        return true;
    }

    std::shared_ptr<T> try_pop()
    {
        std::lock_guard<std::mutex> lock(m);
        if(data.empty())
        {
            return std::shared_ptr<T>();
        }

        std::shared_ptr<T> res(std::make_shared<T>(std::move(data.top())));
        data.pop();
        return res;
    }

};
```


我们将pop优化为四个版本，四个版本又可以分为两个大类，两个大类分别为`try_pop`版本和`wait_and_pop`版本。
try_pop版本不阻塞等待队列有数据才返回，而是直接返回，`try_pop`又有两个版本，分别返回bool值和指针值。如果队列为空返回false或者空指针。
wait_and_pop版本阻塞等待队列有数据才返回，同样有两个版本，分别返回bool值和指针值。
但是上面的代码我们分析，假设此时栈为空，有一个线程A从队列中消费数据，调用`wait_and_pop`挂起, 此时另一个线程B向栈中放入数据调用push操作，notify一个线程消费队列中的数据。
此时A从`wait_and_pop`唤醒，但是在执行3或者5处时，因为内存不足引发了异常，我们之前分析过，即使引发异常也不会影响到栈内数据，所以对于栈的数据来说是安全的，但是线程A异常后，其他线程无法从队列中消费数据，除非线程B再执行一次push。因为我们采用的是`notify_one`的方式，所以仅有一个线程被激活，如果被激活的线程异常了，就不能保证该数据被其他线程消费了，解决这个问题，可以采用几个方案。
1. `wai_and_pop`失败的线程修复后再次取一次数据。
2. 将`notify_one`改为`notify_all`，这样能保证通知所有线程。但是`notify_all`将导致所有线程竞争，并不可取。
3. 我们可以通过栈存储智能指针的方式进行，因为智能指针在赋值的时候不会引发异常。
稍后我们提供的线程安全队列的版本使用的就是第三种优化。


### 线程安全队列

队列和栈最大的不同就是队列为先入先出，有了线程安全的栈的开发思路，我们很快实现一个支持线程安全的队列

```c++
#include <mutex>
#include <queue>

template<typename T>
class threadsafe_queue
{
private:

    mutable std::mutex mut;
    std::queue<T> data_queue;
    std::condition_variable data_cond;

public:
    threadsafe_queue()
    {}

    void push(T new_value)
    {
        std::lock_guard<std::mutex> lk(mut);
        data_queue.push(std::move(new_value));
        data_cond.notify_one();    //⇽-- - ①
    }

    void wait_and_pop(T& value)    //⇽-- - ②
    {
        std::unique_lock<std::mutex> lk(mut);
        data_cond.wait(lk, [this] {return !data_queue.empty(); });
        value = std::move(data_queue.front());
        data_queue.pop();
    }

    std::shared_ptr<T> wait_and_pop()   // ⇽-- - ③
    {
        std::unique_lock<std::mutex> lk(mut);
        data_cond.wait(lk, [this] {return !data_queue.empty(); });   // ⇽-- - ④
        std::shared_ptr<T> res(
            std::make_shared<T>(std::move(data_queue.front())));
        data_queue.pop();
        return res;
    }

    bool try_pop(T& value)
    {
        std::lock_guard<std::mutex> lk(mut);
        if (data_queue.empty())
            return false;
        value = std::move(data_queue.front());
        data_queue.pop();
        return true;
    }

    std::shared_ptr<T> try_pop()
    {
        std::lock_guard<std::mutex> lk(mut);
        if (data_queue.empty())
            return std::shared_ptr<T>();    //⇽-- - ⑤
        std::shared_ptr<T> res(
            std::make_shared<T>(std::move(data_queue.front())));
        data_queue.pop();
        return res;
    }

    bool empty() const
    {
        std::lock_guard<std::mutex> lk(mut);
        return data_queue.empty();
    }
};
```

关于异常情况的分析和栈一样，上面的队列版本不存在异常导致数据丢失的问题。但是同样面临线程执行`wait_and_pop`时如果出现了异常，导致数据被滞留在队列中，其他线程也无法被唤醒的情况。
为了解决这种情况，我们前文提到了采用智能指针的方式，重新实现一下线程安全队列

```c++
template<typename T>
class threadsafe_queue_ptr
{
private:
    mutable std::mutex mut;
    std::queue<std::shared_ptr<T>> data_queue;
    std::condition_variable data_cond;
public:
    threadsafe_queue_ptr()
    {}
    void wait_and_pop(T& value)
    {
        std::unique_lock<std::mutex> lk(mut);
        data_cond.wait(lk, [this] {return !data_queue.empty(); });
        value = std::move(*data_queue.front());    //⇽-- - 1
            data_queue.pop();
    }
    bool try_pop(T& value)
    {
        std::lock_guard<std::mutex> lk(mut);
        if (data_queue.empty())
            return false;
        value = std::move(*data_queue.front());   // ⇽-- - 2
            data_queue.pop();
        return true;
    }
    std::shared_ptr<T> wait_and_pop()
    {
        std::unique_lock<std::mutex> lk(mut);
        data_cond.wait(lk, [this] {return !data_queue.empty(); });
        std::shared_ptr<T> res = data_queue.front();   // ⇽-- - 3
            data_queue.pop();
        return res;
    }
    std::shared_ptr<T> try_pop()
    {
        std::lock_guard<std::mutex> lk(mut);
        if (data_queue.empty())
            return std::shared_ptr<T>();
        std::shared_ptr<T> res = data_queue.front();   // ⇽-- - 4
            data_queue.pop();
        return res;
    }
    void push(T new_value)
    {
        std::shared_ptr<T> data(
            std::make_shared<T>(std::move(new_value)));   // ⇽-- - 5
            std::lock_guard<std::mutex> lk(mut);
        data_queue.push(data);
        data_cond.notify_one();
    }
    bool empty() const
    {
        std::lock_guard<std::mutex> lk(mut);
        return data_queue.empty();
    }
};
```


在5处，我们push数据时需要先构造智能指针，如果构造的过程失败了也就不会push到队列中，不会污染队列中的数据。
2，3处和4，5处我们仅仅时将智能指针取出来赋值给一个新的智能指针并返回。关于智能指针的赋值不会引发异常这一点在C++并发编程中提及，这一点我觉得有些存疑，我觉得书中表述的意思应该是指针在64位机器占用8个字节，所有智能指针共享引用计数所以在复制时仅为8字节开销，降低了内存消耗。
所以推荐大家存储数据放入容器中时尽量用智能指针，这样能保证复制和移动过程中开销较小，也可以实现一定意义的数据共享。
但是我们分析上面的代码，队列push和pop时采用的是一个mutex，导致push和pop等操作串行化，我们要考虑的是优化锁的精度，提高并发，那有什么办法吗？
我们分析，队列和栈最本质的区别是队列是首尾操作。我们可以考虑将push和pop操作分化为分别对尾和对首部的操作。**对首和尾分别用不同的互斥量管理**就可以实现真正意义的并发了。
我们引入虚位节点的概念，表示一个空的节点，没有数据，是一个无效的节点，初始情况下，队列为空，head和tail节点都指向这个虚位节点。

<img src="https://cdn.llfc.club/1700371510300.jpg" alt="image.png" style="zoom:60%;" />
当我们push一个数据，比如为MyClass类型的数据后，tail向后移动一个位置，并且仍旧指向这个虚位节点。
如下图

<img src="https://cdn.llfc.club/1700371711311.jpg" alt="image.png" style="zoom:60%;" />

接下来我们实现这个版本的并发安全队列

```c++
template<typename T>
class threadsafe_queue_ht
{
private:
    struct node
    {
        std::shared_ptr<T> data;
        std::unique_ptr<node> next;
    };
    std::mutex head_mutex;
    std::unique_ptr<node> head;
    std::mutex tail_mutex;
    node* tail;
    std::condition_variable data_cond;

    node* get_tail()
    {
        std::lock_guard<std::mutex> tail_lock(tail_mutex);
        return tail;
    }
    std::unique_ptr<node> pop_head()   
    {
        std::unique_ptr<node> old_head = std::move(head);
        head = std::move(old_head->next);
        return old_head;
    }
        std::unique_lock<std::mutex> wait_for_data()   
    {
        std::unique_lock<std::mutex> head_lock(head_mutex);
        data_cond.wait(head_lock,[&] {return head.get() != get_tail(); }); //5
        return std::move(head_lock);   
    }
        std::unique_ptr<node> wait_pop_head()
        {
            std::unique_lock<std::mutex> head_lock(wait_for_data());   
                return pop_head();
        }
        std::unique_ptr<node> wait_pop_head(T& value)
        {
            std::unique_lock<std::mutex> head_lock(wait_for_data());  
                value = std::move(*head->data);
            return pop_head();
        }


        std::unique_ptr<node> try_pop_head()
        {
            std::lock_guard<std::mutex> head_lock(head_mutex);
            if (head.get() == get_tail())
            {
                return std::unique_ptr<node>();
            }
            return pop_head();
        }
        std::unique_ptr<node> try_pop_head(T& value)
        {
            std::lock_guard<std::mutex> head_lock(head_mutex);
            if (head.get() == get_tail())
            {
                return std::unique_ptr<node>();
            }
            value = std::move(*head->data);
            return pop_head();
        }
public:

    threadsafe_queue_ht() :  // ⇽-- - 1
        head(new node), tail(head.get())
    {}

    threadsafe_queue_ht(const threadsafe_queue_ht& other) = delete;
    threadsafe_queue_ht& operator=(const threadsafe_queue_ht& other) = delete;

    std::shared_ptr<T> wait_and_pop() //  <------3
    {
        std::unique_ptr<node> const old_head = wait_pop_head();
        return old_head->data;
    }

    void wait_and_pop(T& value)  //  <------4
    {
        std::unique_ptr<node> const old_head = wait_pop_head(value);
    }


    std::shared_ptr<T> try_pop()
    {
        std::unique_ptr<node> old_head = try_pop_head();
        return old_head ? old_head->data : std::shared_ptr<T>();
    }
    bool try_pop(T& value)
    {
        std::unique_ptr<node> const old_head = try_pop_head(value);
        return old_head;
    }
    bool empty()
    {
        std::lock_guard<std::mutex> head_lock(head_mutex);
        return (head.get() == get_tail());
    }

    void push(T new_value)  //<------2
    {
        std::shared_ptr<T> new_data(
            std::make_shared<T>(std::move(new_value)));
        std::unique_ptr<node> p(new node);
        node* const new_tail = p.get();
        std::lock_guard<std::mutex> tail_lock(tail_mutex);
        tail->data = new_data;
        tail->next = std::move(p);
        tail = new_tail;
    }
};
```

node为节点类型，包含data和next两个成员。 data为智能指针类型存储T类型的数据。next为指向下一个节点的智能指针，以此形成链表。
上述代码我们的head是一个node类型的智能指针。而tail为node类型的普通指针，读者也可以用智能指针。
在1处构造函数那里，我们将head和tail初始指向的位置设置为虚位节点。
在2处我们push数据的时候先构造T类型的智能指针存储数据new_data，然后我们构造了一个新的智能指针p, p取出裸指针就是新的虚位节点new_tail，我们将new_data赋值给现在的尾节点，并且让尾节点的next指针指向p, 然后将tail更新为我们新的虚位节点。
3，4处都是`wait_and_pop`的不同版本，内部调用了`wait_pop_head`，`wait_pop_head`内部先调用`wait_for_data`判断队列是否为空，这里判断是否为空主要是判断head是否指向虚位节点。如果不为空则返回`unique_lock`，我们显示的调用了move操作，返回`unique_lock`仍保留对互斥量的锁住状态。
回到`wait_pop_head`中，接下来执行pop_head将数据pop出来。
值得注意的是`get_tail()`返回tail节点，那么我们思考如果此时有多个线程push数据，tail节点已经变化了，我们此时在5处的判断可能是基于push之前的tail信息，但是不影响逻辑，因为如果head和tail相等则线程挂起，等待通知，如果不等则继续执行，push操作只会将tail向后移动不会导致逻辑问题。
pop_head中我们将head节点移动给一个old_head变量，然后将`old_head`的next节点更新为新的head。这里我觉得可以简化写为`head=head->next`.

### 实现线程安全的查找表

前文介绍了线程安全的队列和栈，本文继续介绍线程安全的查找结构，实现一个类似线程安全的map结构，但是map基于红黑树实现，假设我们要增加或者删除节点，设计思路是依次要删除或增加节点的父节点，然后修改子节点数据 。尽管这种思路可行，但是难度较大，红黑树节点的插入要修改多个节点的关系。另外加锁的流程也是锁父节点，再锁子节点，尽管在处理子节点时我们已经处理完父节点，可以对父节点解锁，继续对子节点加锁，这种情况锁的粒度也不是很精细，考虑用散列表实现。

### 散列表

散列表（Hash table，也叫哈希表），是根据键（Key）而直接访问在存储器存储位置的数据结构。 也就是说，它通过计算出一个键值的函数，将所需查询的数据映射到表中一个位置来让人访问，这加快了查找速度。 这个映射函数称做散列函数，存放记录的数组称做散列表。
举个例子：
假如我们一共有 50 人参加学校的数学竞赛，然后我们为每个学生分配一个编号，依次是 1 到 50.

如果我们想要快速知道编号对应学生的信息，我们就可以用一个数组来存放学生的信息，编号为 1 的放到数组下标为 1 的位置，编号为 2 的放到数组下标为 2 的位置，依次类推。

现在如果我们想知道编号为 20 的学生的信息，我们只需要把数组下标为 20 的元素取出来就可以了，时间复杂度为 O(1)，是不是效率非常高呢。
但是这些学生肯定来自不同的年级和班级，为了包含更详细的信息，我们在原来编号前边加上年级和班级的信息，比如030211 ，03表示年级，02表示班级，11原来的编号，这样我们该怎么存储学生的信息，才能够像原来一样使用下标快速查找学生的信息呢？

思路还是和原来一样，我们通过编号作为下标来储存，但是现在编号多出了年级和班级的信息怎么办呢，我们只需要截取编号的后两位作为数组下标来储存就可以了。

这个过程就是典型的**散列思想**。其中，参赛学生的编号我们称之为键(key)，我们用它来标识一个学生。然后我们通过一个方法（比如上边的截取编号最后两位数字）把编号转变为数组下标，这个方法叫做散列函数（哈希函数），通过散列函数得到的值叫做散列值（哈希值）。

我们自己在设计散列函数的函数时应该遵循什么规则呢？

1. 得到的散列值是一个非负整数
2. 两个相同的键，通过散列函数计算出的散列值也相同
3. 两个不同的键，计算出的散列值不同

虽然我们在设计的时候要求满足以上三条要求，但对于第三点很难保证所有不同的建都被计算出不同的散列值。有可能不同的建会计算出相同的值，这叫做哈希冲突。最常见的一些解决哈希冲突的方式是开放寻址法和链表法，我们这里根据链表法，将散列函数得到相同的值的key放到同一个链表中。
如下图

<img src="https://cdn.llfc.club/1700962817978.jpg" alt="image.png" style="zoom:60%;" />

当我们根据key值的后两位计算编号，将编号相同的放入一个链表，比如030211和030311是一个编号，所以将其放入一个链表。
同样的道理040213和060113是一个编号，放入一个链表。


### 设计思路

我们要实现上述逻辑，可以考虑将11，12，13等hash值放入一个vector中。多线程根据key计算得出hash值的过程并不需要加锁，可以实现**并行计算**。
但是对于链表的增删改查需要加锁。
所以我们考虑将链表封装为一个类`bucket_type`,支持数据的增删改查。
我们将整体的查找表封装为`threadsafe_lookup_table`类，实现散列规则和调度`bucket_type`类。

### 代码实现

我们先实现内部的`bucket_type`类. 为了`threadsafe_lookup_table`可以访问他，所以将`threadsafe_lookup_table`设置为其友元类。

```c++
class bucket_type
{
    friend class threadsafe_lookup_table;
}
```

我们需要用链表存储键值结构，所以我们可以在`bucket_type`中添加一个链表存储键值结构。

```c++
    //存储元素的类型为pair，由key和value构成
    typedef std::pair<Key, Value> bucket_value;
    //由链表存储元素构
    typedef std::list<bucket_value> bucket_data;
    //链表的迭代器
    typedef typename bucket_data::iterator bucket_iterator;
    //链表数据
    bucket_data data;
    //改用共享锁
    mutable std::shared_mutex mutex;
```

并且添加了互斥量用于控制链表的读写互斥操作，但是我们采用的是共享互斥量，可以实现读写锁，保证读的时候可以并发读。
接下来我们封装一个私有的查找接口，用来内部使用。

```c++
//查找key值，找到返回对应的value，未找到则返回默认值
bucket_iterator find_entry_for(const Key & key)
{
    return std::find_if(data.begin(), data.end(),
                [&](bucket_value const& item)
                {return item.first == key; });
}
```

然后我们分别实现返回查找的值操作，以及添加操作，并且删除操作
```c++
    //查找key值，找到返回对应的value，未找到则返回默认值
    Value value_for(Key const& key, Value const& default_value) 
    {
        std::shared_lock<std::shared_mutex> lock(mutex);
        bucket_iterator const found_entry = find_entry_for(key);
        return (found_entry == data.end()) ?
                default_value : found_entry->second;
    }
    //添加key和value，找到则更新，没找到则添加
    void add_or_update_mapping(Key const& key, Value const& value)
    {
        std::unique_lock<std::shared_mutex> lock(mutex);
        bucket_iterator const found_entry = find_entry_for(key);
        if (found_entry == data.end())
        {
            data.push_back(bucket_value(key, value));
        }
        else
        {
            found_entry->second = value;
        }
    }
    //删除对应的key
    void remove_mapping(Key const& key)
    {
        std::unique_lock<std::shared_mutex> lock(mutex);
        bucket_iterator const found_entry = find_entry_for(key);
        if (found_entry != data.end())
        {
            data.erase(found_entry);
        }
    }
```

这样我们设计完成了`bucket_type`类。

接下来我们设计`threadsafe_lookup_table`类。我们用一个vector存储上面的bucket_type类型。 因为我们要计算hash值，key可能是多种类型string, int等，所以我们采用std的hash算法作为散列函数即可.

```c++
class threadsafe_lookup_table{
private:
    //用vector存储桶类型
    std::vector<std::unique_ptr<bucket_type>> buckets;
    //hash<Key> 哈希表 用来根据key生成哈希值
    Hash hasher;

    //根据key生成数字，并对桶的大小取余得到下标，根据下标返回对应的桶智能指针
    bucket_type& get_bucket(Key const& key) const
    {
        std::size_t const bucket_index = hasher(key) % buckets.size();
        return *buckets[bucket_index];
    }
};
```

`get_bucket`函数不需要加锁，各个线程可以并行计算哈希值，取出key对应的桶。如果多线程调用同一个bucket的增删改查，就通过bucket内部的互斥解决线程安全问题。 接下来我们完善`threadsafe_lookup_table`的对外接口

```c++
    threadsafe_lookup_table(
        unsigned num_buckets = 19, Hash const& hasher_ = Hash()) :
        buckets(num_buckets), hasher(hasher_)
    {
        for (unsigned i = 0; i < num_buckets; ++i)
        {
            buckets[i].reset(new bucket_type);
        }
    }

    threadsafe_lookup_table(threadsafe_lookup_table const& other) = delete;
    threadsafe_lookup_table& operator=(
        threadsafe_lookup_table const& other) = delete;

    Value value_for(Key const& key,
        Value const& default_value = Value()) 
    {
        return get_bucket(key).value_for(key, default_value);
    }

    void add_or_update_mapping(Key const& key, Value const& value)
    {
        get_bucket(key).add_or_update_mapping(key, value);
    }

    void remove_mapping(Key const& key)
    {
        get_bucket(key).remove_mapping(key);
    }
```

除此之外我们可将当前查找表的副本作为一个map返回
```c++
std::map<Key, Value> get_map() 
{
    std::vector<std::unique_lock<std::shared_mutex>> locks;
    for (unsigned i = 0; i < buckets.size(); ++i)
    {
        locks.push_back(
                std::unique_lock<std::shared_mutex>(buckets[i]->mutex));
    }
    std::map<Key, Value> res;
    for (unsigned i = 0; i < buckets.size(); ++i)
    {
        //需用typename告诉编译器bucket_type::bucket_iterator是一个类型，以后再实例化
        //当然此处可简写成auto it = buckets[i]->data.begin();
        typename bucket_type::bucket_iterator it = buckets[i]->data.begin();
        for (;it != buckets[i]->data.end();++it)
        {
            res.insert(*it);
        }
    }
    return res;
}
```


### 测试与分析

我们自定义一个类 
```c++
class MyClass
{
public:
    MyClass(int i):_data(i){}

    friend std::ostream& operator << (std::ostream& os, const MyClass& mc){
        os << mc._data;
        return os;
    }


private:
    int _data;
};
```

接下来我们实现一个函数做测试
```c++
void TestThreadSafeHash() {
    std::set<int> removeSet;
    threadsafe_lookup_table<int, std::shared_ptr<MyClass>> table;
    std::thread t1([&]() {
        for(int i = 0; i < 100; i++)
        {
           auto class_ptr =  std::make_shared<MyClass>(i); 
            table.add_or_update_mapping(i, class_ptr);
        }
    });

    std::thread t2([&]() {
        for (int i = 0; i < 100; )
        {
            auto find_res = table.value_for(i, nullptr);
            if(find_res)
            {
                table.remove_mapping(i);
                removeSet.insert(i);
                i++;
            }

            std::this_thread::sleep_for(std::chrono::milliseconds(10));
        }
    });

    std::thread t3([&]() {
        for (int i = 100; i < 200; i++)
        {
            auto class_ptr = std::make_shared<MyClass>(i);
            table.add_or_update_mapping(i, class_ptr);
        }
        });


    t1.join();
    t2.join();
    t3.join();

    for(auto & i : removeSet)
    {
        std::cout << "remove data is " << i << std::endl;
    }

   auto copy_map =  table.get_map();
    for(auto & i : copy_map)
    {
        std::cout << "copy data is " << *(i.second) << std::endl;
    }
}
```

t1用来向map中添加数据(从0到99)，t2用来从map中移除数据(从0到99)，如果map中未找到则等待10ms继续尝试，t3则继续继续添加数据(从100到199). 然后分别打印插入的集合和获取的map中的数值。 打印可以看到输出插入集合为(0~99)，copy的map集合为(100~199).

我们分析一下上述查找表的优劣

1. 首先我们的查找表可以支持并发读，并发写，并发读的时候不会阻塞其他线程。但是并发写的时候会卡住其他线程。基本的并发读写没有问题。 
2. 但是对于bucket_type中链表的操作加锁精度并不精细，因为我们采用的是`std`提供的`list`容器，所以增删改查等操作都要加同一把锁，导致锁过于粗糙。

下一节会介绍支持并发读写的自定义链表，可以解决`bucket_type`中的`list`锁精度不够的短板。


## 实现线程安全的链表

前文介绍了如何基于锁实现线程安全的栈和队列结构，以及实现线程安全的查找表，但是我们上次的查找表是基于list实现的，对于锁的精度控制的不是很准确，提及了接下来会介绍精细控制的链表，用来替换查找表中的链表。这一节我们就介绍如何通过锁控制链表访问的精度。

### 链表

一个常见的链表应该是如下结构，有一个包含数据的**数据域**以及一个指向下一个节点的指针。

<img src="https://cdn.llfc.club/1701557385171.jpg" alt="image.png" style="zoom:60%;" />
如果做一个支持多线程并发访问的链表，我们首先想到的是用一个互斥量控制整个链表，达到多线程访问时串行的效果。但是这么做精度不够，需要分化互斥量的功能。我们想到的一个办法就是每个节点都维护一个互斥量，这样能保证多个线程操作不同节点时加不同的锁，减少耦合性。

另外我们将head独立为一个虚节点，所谓虚节点就是不存储数据，只做头部标记。我们每次从头部插入只需要修将新的节点的next指针指向原来head的next指向的节点，再将head的next指针指向新的节点。

如下图
<img src="https://cdn.llfc.club/1701559209928.jpg" alt="image.png" style="zoom:60%;" />

### 源码实现

我们先定义一个基本的链表节点
```c++
template<typname T>
struct node
{
    std::mutex m;
    std::shared_ptr<T> data;
    std::unique_ptr<node> next;
    node() :next(){}
    node(T const& value) :
        data(std::make_shared<T>(value)){}
};
```

1. data为智能指针,存储的是T类型的数据域。
2. next为一个unique类型的智能指针，存储的是下一个节点的地址。 
3. m为mutex，控制多线程访问的安全性。我们将mutex分别独立到各个节点中保证锁的精度问题。

接下来我们定义一个链表，初始状态包含一个head的头节点

```c++
template<typename T>
class threadsafe_list
{
    struct node
    {
        std::mutex m;
        std::shared_ptr<T> data;
        std::unique_ptr<node> next;
        node() :
            next()
        {}
        node(T const& value) :
            data(std::make_shared<T>(value))
        {}
    };

    node head;
public:
    threadsafe_list()
    {}

    ~threadsafe_list()
    {
    }

    threadsafe_list(threadsafe_list const& other) = delete;
    threadsafe_list& operator=(threadsafe_list const& other) = delete;
}
```

我们将拷贝构造和拷贝赋值函数删除。然后链表中初始状态包含了一个头节点。 接下来我们实现析构函数，我们期望析构函数能够从头到尾的删除元素，所以先实现一个删除函数

```c++
template<typename Predicate>
void remove_if(Predicate p)
{
    node* current = &head;
    std::unique_lock<std::mutex> lk(head.m);
    while (node* const next = current->next.get())
    {
        std::unique_lock<std::mutex> next_lk(next->m);
        if (p(*next->data))
        {
            std::unique_ptr<node> old_next = std::move(current->next);
                current->next = std::move(next->next);
                next_lk.unlock();
        }
        else
        {
            lk.unlock();
            current = next;
            lk = std::move(next_lk);
        }
    }
}
```

上面的函数中，我们先取头部节点作为**当前节点**，然后将将当前节点加锁，只有**当前节点加锁了才能访问其next指针**。我们在获取next节点后也要对其加锁，这么做的好处就是保证无论是删除还是添加都从当前节点开始依次对其next节点加锁，既能保证互斥也能维护同一顺序防止死锁。
如果next节点的数据域满足谓词p的规则，则将next节点的移动赋值给old_next，随着局部作用域结束，old_next会被释放，也就达到了析构要删除节点的目的。 然后我们将next节点的next值(也就是要删除节点的下一个节点)赋值给当前节点的next指针，达到链接删除节点的下一个节点的目的。
但是我们要操作接下来的节点就需要继续锁住下一个节点，达到互斥控制的目的，锁住下个节点是通过while循环不断迭代实现的，通过next_lk达到了锁住下一个节点的目的。
如果下一个节点不满足我们p谓词函数的条件，则**需要解锁当前节点**，**将下一个节点赋值给当前节点**，并且将下**一个节点的锁移动给当前节点**。
如下图演示了current, next以及next->next节点之间的关系。

<img src="https://cdn.llfc.club/1701569562255%281%29.jpg" alt="image.png" style="zoom:60%;" />

接下来我们实现析构函数
```c++
~threadsafe_list()
{ 
    remove_if([](node const&) {return true; }); // 对于 list 中的每个节点，无条件返回 true
}
```

析构函数调用remove_if,p谓词就是一个lambda表达式，返回true。
头节点的插入工作也比较简答，将新节点的next指针赋值成头部节点的next指针指向的数据。然后将新节点赋值给头部节点的next指针即可.

```c++
void push_front(T const& value)
{
    std::unique_ptr<node> new_node(new node(value));
    std::lock_guard<std::mutex> lk(head.m);
    new_node->next = std::move(head.next);
    head.next = std::move(new_node);
}
```

但是大家要注意，插入和删除加锁的顺序要保持一致，都是从头到尾，这样能防止死锁，也能保持互斥。
假设原链表是这样的
<img src="https://cdn.llfc.club/1701570406738.jpg" alt="image.png" style="zoom:60%;" />

调用push_front之后是这样的

<img src="https://cdn.llfc.club/1701570489799.jpg" alt="image.png" style="zoom:60%;" />

接下来是根据谓词p查找对应的节点数据

```c++
    template<typename Predicate>
    std::shared_ptr<T> find_first_if(Predicate p)
    {
        node* current = &head;
        std::unique_lock<std::mutex> lk(head.m);
        while (node* const next = current->next.get())
        {
            std::unique_lock<std::mutex> next_lk(next->m);
            lk.unlock();
            if (p(*next->data))
            {
                return next->data;
            }
            current = next;
            lk = std::move(next_lk);
        }
        return std::shared_ptr<T>();
    }
```

`find_first_if`查找到第一个满足条件的节点就返回。查找的步骤也是先对当前节点加锁，判断当前节点的next节点是否为空，不为空则获取下一个节点为next，我们对next加锁，依次锁住当前节点和下一个节点，判断下一个节点是否满足谓词p,如果满足条件则返回next节点的数据即可，更新下一个节点为当前节点，下一个节点的锁next_lk更新给lk，以此锁住新的当前节点，再依次类推遍历直到找到满足条件的节点为止。

那么便利所有节点的接口就可以根据上述思路实现了

```c++
template<typename Function>
void for_each(Function f)
{
    node* current = &head;
    std::unique_lock<std::mutex> lk(head.m);
    while (node* const next = current->next.get())
    {
        std::unique_lock<std::mutex> next_lk(next->m);
        lk.unlock();
        f(*next->data);
        current = next;
        lk = std::move(next_lk);
    }
}
```

如果我们按照如下测试函数测试上面的接口，

```c++
std::set<int> removeSet;
void TestThreadSafeList()
{

    threadsafe_list<MyClass> thread_safe_list;
    std::thread t1([&]()
    {
        for(unsigned int i = 0; i < 100; i++)
        {
            MyClass mc(i);
            thread_safe_list.push_front(mc);
        }

    });


    std::thread t2([&]()
    {
        for (unsigned int i = 0; i < 100; )
        {

            auto find_res = thread_safe_list.find_first_if([&]( auto & mc)
            {
                    return mc.GetData() == i;
            });

            if(find_res == nullptr)
            {
                std::this_thread::sleep_for(std::chrono::milliseconds(10));
                continue;
            }

            removeSet.insert(i);
            i++;
        }
    });

    t1.join();
    t2.join();

}
```

将删除的数据放入集合set，最后打印set会发现数据全都被删除了。

### 尾部插入

C++ 并发编程中提到了留给读者去实现尾部插入，我们实现尾部插入需要维护一个尾部节点，这个尾部节点我们初始的时候指向head，当插入元素后，尾部节点指向了最后一个节点的地址。

考虑有多个线程并发进行尾部插入，所以要让这些线程互斥，我们需要一个互斥量last_ptr_mtx保证线程穿行，last_node_ptr表示正在操作尾部节点，以此来让多个线程并发操作尾部节点时达到互斥。比如我们的代码可以实现如下

```c++
void push_back(T const& value) {
    //防止于push_head同时进行
    //并且保证头部或者删除节点更新last_node_ptr唯一, 所以同时加锁
    std::unique_ptr<node_d> new_node(new node_d(value));
    std::unique_lock<std::mutex> lk(last_node_ptr->m);
    std::unique_lock<std::mutex> last_lk(last_ptr_mtx);
    //原来的最后节点的下一个节点指向新生成的节点
    last_node_ptr->next = std::move(new_node);
    //将最后一个节点后移
    last_node_ptr = last_node_ptr->next.get();
}
```

头部插入我们也作一些修改
```c++
void push_front(T const& value)
{
    std::unique_ptr<node_d> new_node(new node_d(value));
    std::lock_guard<std::mutex> lk(head.m);
    new_node->next = std::move(head.next);
    head.next = std::move(new_node);
    //更新最后一个节点
    if (head.next->next == nullptr) {
        std::lock_guard<std::mutex> last_lk(last_ptr_mtx);
        last_node_ptr = head.next.get();
    }
}
```

`push_front`函数将新节点放入head节点的后边，如果head节点后面没有节点，此时插入新节点后，新的节点就变为尾部节点了。所以判断新插入节点的next为nullptr，那么这个节点就是最后节点，所以要对`last_ptr_mtx`加锁，更新last_node_ptr值。

我们考虑一下，如果一个线程push_back和另一个线程`push_front`是否会出现问题？其实两个线程资源竞争的时候仅在队列为空的时候，这时无论push_back还是push_front都会操作head节点，以及更新`_last_node_ptr`值，但是我们的顺序是先锁住前一个节点，再将当前节点更新为前一个节点的下一个节点。那么从这个角度来说，`push_back`和`push_front`不会有线程安全问题。

接下来实现删除操作

```c++
template<typename Predicate>
void remove_if(Predicate p)
{
    node_d* current = &head;
    std::unique_lock<std::mutex> lk(head.m);
    while (node_d* const next = current->next.get())
    {
        std::unique_lock<std::mutex> next_lk(next->m);
        if (p(*next->data))
        {
            std::unique_ptr<node_d> old_next = std::move(current->next);
                current->next = std::move(next->next);
                //判断删除的是否为最后一个节点
            if (current->next == nullptr) {
                std::lock_guard<std::mutex> last_lk(last_ptr_mtx);
                    last_node_ptr = &head;
            }
            next_lk.unlock();
        }
        else
        {
            lk.unlock();
            current = next;
            lk = std::move(next_lk);
        }
    }
}

template<typename Predicate>
bool remove_first(Predicate p)
{
    node_d* current = &head;
    std::unique_lock<std::mutex> lk(head.m);
    while (node_d* const next = current->next.get())
    {
        std::unique_lock<std::mutex> next_lk(next->m);
        if (p(*next->data))
        {
            std::unique_ptr<node_d> old_next = std::move(current->next);
            current->next = std::move(next->next);
            //判断删除的是否为最后一个节点
            if (current->next == nullptr) {
                std::lock_guard<std::mutex> last_lk(last_ptr_mtx);
                last_node_ptr = &head;
            }
            next_lk.unlock();

            return true;
        }

        lk.unlock();
        current = next;
        lk = std::move(next_lk);
    }

    return false;
}
```

删除的时候，如果将当前节点的下一个节点满足删除条件，则将其移动到old_next节点里。old_next会随着作用域结束析构。
然后将删除节点的下一个节点赋值给当前节点的next指针，这样就达到了当前节点的next指针指向了删除节点的下一个节点的目的，以此达到了删除效果。
我们思考删除操作和push_back是否会产生线程竞争，答案是会的，比如下面这种情况

<img src="https://cdn.llfc.club/1701577481423.jpg" alt="image.png" style="zoom:60%;" />


线程1想要push_back插入节点，他会用到last_node_ptr，也会更新last_node_ptr。
而线程2想要删除最后一个节点，会更新last_node_ptr的值。
尽管我们通过node内部的互斥量可以保证两个线程在同一时刻仅能有一个线程操作最后一个节点，或者删除或者添加。
但是，假设线程2先执行删除操作，节点更新并且更新last_node_ptr的值，而此时线程1因为之前无法抢占最后一个节点(last_node_ptr)自带的互斥量所以挂起，当线程2执行完后，线程1才开始继续执行，但是此时last_node_ptr已经变化了，而线程1可能还用的是旧的last_node_ptr的值，导致插入数据失败(很可能崩溃或者插入到一个分叉的链表)。
如果将push_back修改为先对last_ptr_mtx加锁，这样就能保证一个线程修改last_node_ptr会被另一个线程看到。比如下面这样

```c++
void push_back(T const& value) {
    //防止于push_head同时进行
    //并且保证头部或者删除节点更新last_node_ptr唯一, 所以同时加锁
    std::unique_ptr<node_d> new_node(new node_d(value));
    std::unique_lock<std::mutex> last_lk(last_ptr_mtx);
    std::unique_lock<std::mutex> lk(last_node_ptr->m);
    //原来的最后节点的下一个节点指向新生成的节点
    last_node_ptr->next = std::move(new_node);
    //将最后一个节点后移
    last_node_ptr = last_node_ptr->next.get();
}
```

但是我们这样会发现删除的时候先对node加锁，再对last_ptr_mtx加锁，而push_back的时候先对last_ptr_mtx加锁，再对node加锁。会导致死锁！

所以我们将push_back修改为对node和last_ptr_mtx加锁，那么就能解决上面的问题。因为push_back必须要等到两个互斥量都竞争成功才操作，所以达到了删除和push_back串行的效果。

改进后的push_back是如下这个样子

```c++
void push_back(T const& value) {
    //防止于push_head同时进行
    //并且保证头部或者删除节点更新last_node_ptr唯一, 所以同时加锁
    std::unique_ptr<node_d> new_node(new node_d(value));
    std::lock(last_node_ptr->m, last_ptr_mtx);
    std::unique_lock<std::mutex> lk(last_node_ptr->m, std::adopt_lock);
    std::unique_lock<std::mutex> last_lk(last_ptr_mtx, std::adopt_lock);
    //原来的最后节点的下一个节点指向新生成的节点
    last_node_ptr->next = std::move(new_node);
    //将最后一个节点后移
    last_node_ptr = last_node_ptr->next.get();
}
```

我们可以实现如下函数测试，启动三个线程， 线程1执行push_front将0到20000放入链表。 线程2执行push_back将20000到40000的数据放入链表。 线程3执行删除操作，将数据从0到40000删除。 最后我们打印链表为空，验证准确性。

```c++
void MultiThreadPush()
{
    double_push_list<MyClass> thread_safe_list;

    std::thread t1([&]()
    {
            for (int i = 0; i < 20000; i++)
            {
                MyClass mc(i);
                thread_safe_list.push_front(mc);
                std::cout << "push front " << i << " success" << std::endl;
            }
    });

    std::thread t2([&]()
    {
            for (int i = 20000; i < 40000; i++)
            {
                MyClass mc(i);
                thread_safe_list.push_back(mc);
                std::cout << "push back " << i << " success" << std::endl;
            }
    });

    std::thread t3([&]()
    {
            for(int i = 0; i < 40000; )
            {
                bool rmv_res = thread_safe_list.remove_first([&](const MyClass& mc)
                    {
                        return mc.GetData() == i;
                    });

                if(!rmv_res)
                {
                    std::this_thread::sleep_for(std::chrono::milliseconds(10));
                    continue;
                }

                i++;
            }
    });

    t1.join();
    t2.join();
    t3.join();

    std::cout << "begin for each print...." << std::endl;
    thread_safe_list.for_each([](const MyClass& mc)
        {
            std::cout << "for each print " << mc << std::endl;
        });
    std::cout << "end for each print...." << std::endl;
}
```


最后程序输出
```c++
push back 39995 success
push back 39996 success
push back 39997 success
push back 39998 success
push back 39999 success
begin for each print....
end for each print....
Hello World!
```

## 线程安全无锁并发栈

前文我们通过锁的互斥机制实现了并发安全的栈，队列，查找表，以及链表等结构。接下来本文介绍通过无锁的原子变量的方式实现对应的容器，我们这一篇先从**无锁**的方式实现栈讲起。

### 栈的设计思路

栈容器是一种**先进后出**的结构，简单来讲，我们将n个元素1，2，3，4依次入栈，那么出栈的顺序是4，3，2，1.

先考虑单线程情况下操作顺序
1. 创建新节点
2. 将元素入栈，将新节点的next指针指向现在的head节点。
3. 将head节点更新为新节点的值。

再考虑多线程的情况下
假设线程1执行到第2步，没来得及更新head节点的值为新节点的值。此时线程2也执行完第2步，将head更新为线程2插入的新节点，之后线程1又将head更新为线程1的新插入节点，那么此时head的位置就是错的。
如下图

<img src="https://cdn.llfc.club/1701670454146.jpg" alt="image.png" style="zoom:60%;" />

我们可以通过原子变量的compare_exchange(比较交换操作)来控制更新head节点，以此来达到线程安全的目的。
我们先定义节点的结构
```c++
template<typename T>
struct node
{
    T data;
    node* next;
    node(T const& data_) : 
            data(data_)
    {}
};
```

一个node节点包含两部分内容，一个T类型的数据域，一个`node*`的next指针，指向下一个节点。
我们接下来定义一个无锁栈的结构

```c++
template<typename T>
class lock_free_stack
{
private:
    lock_free_stack(const lock_free_stack&) = delete;
    lock_free_stack& operator = (const lock_free_stack&) = delete;

    std::atomic<node*> head;
public:
    lock_free_stack() {}
}
```

当然书中的做法更简略一些
```c++
template<typename T>
void push(const T& value){
    auto new_node = new Node(value)
    do{
        new_node->next = head.load();
    }while(!head.compare_exchange_weak(new_node->next, new_node));
}
```

我还是建议大家用do-while的方式实现，这样我们可以在do-while中增加很多自己的定制逻辑,另外推荐大家用compare_exchange_weak，尽管存在失败的情况，但是他的开销小，所以compare_exchange_weak返回false我们再次重试即可。

单线程情况下pop操作的顺序

1. 取出头节点元素
2. 更新head为下一个节点。
3. 返回取出头节点元素的数据域。

多线程情况下，第1，2点同样存在线程安全问题。此外我们返回节点数据域时会进行拷贝赋值，如果出现异常会造成数据丢失，这一点也要考虑。 所以我们同样通过head原子变量比较和交换的方式检测并取出头部节点。

我们先写一个单线程版本
```c++
template<typename T>
void pop(T& value){
    node* old_head = head.load(); //1
    head = head->next; //2
    value = old_head->data;
}
```

我们知道1处和2处在多线程情况下会存在线程安全问题。所以我们用原子变量的比较交换操作改写上面的代码
```c++
template<typename T>
void pop(T& value){
    do{
        node* old_head = head.load(); //1
    }while(!head.compare_exchange_weak(old_head, old_head->next)); //2
    value = old_head->data; //3
}
```

我们通过判断`head`和`old_head`的值是否相等，如果相等则将`head`的值设置为`old_head`的下一个节点，否则返回false，并且将`old_head`更新为当前head的值(比较交换函数帮我们做的)。
我们看上面的代码，有三点严重问题

1. 未判断空栈的情况，这一点比较好处理，如果为空栈我们可以令pop返回false，或者抛出异常，当然抛出异常不可取。
2. 将数据域赋值给引用类型的value时存在拷贝赋值(3处)，我们都知道拷贝赋值会存在异常的情况，当异常发生时元素已经从栈定移除了，破坏了栈的结构，这一点和锁处理时不一样，锁处理的时候是先将元素数据域取出赋值再出栈，所以不会有问题，但是无锁的方式就会出现栈被破坏的情况。解决方式也比较简单，数据域不再存储T类型数据，而是存储`std::shared_ptr<T>`类型的数据。智能指针在赋值的时候不会产生异常。
3. 未释放弹出的节点的内存。

那我们修改之后的代码就是这样了

```c++
class lock_free_stack
{
private:
    struct node
    {
        std::shared_ptr<T> data;
        node* next;
        node(T const& data_) : //⇽-- - 1
            data(std::make_shared<T>(data_))
        {}
    };
    lock_free_stack(const lock_free_stack&) = delete;
    lock_free_stack& operator = (const lock_free_stack&) = delete;
    std::atomic<node*> head;
public:
    lock_free_stack() {}
    void push(T const& data)
    {
        node* const new_node = new node(data);    //⇽-- - 2
            new_node->next = head.load();    //⇽-- - 3
            while (!head.compare_exchange_weak(new_node->next, new_node));    //⇽-- - 4
    }

    std::shared_ptr<T> pop() {
        node* old_head = nullptr; //1        
        do {
            old_head = head.load(); //2
            if (old_head == nullptr) {
                return nullptr; 
            }
        } while (!head.compare_exchange_weak(old_head, old_head->next)); //3        

        return old_head->data;  //4    
    }
};
```

简单描述下pop函数的功能，

1. 处初始化一个临时old_head的变量，
2. 处加载head节点

3 处通过比较和交换操作，判断head和old_head是否相等，如相等则将head更新为old_head的next节点。如不相等，将old_head更新为head的值(compare_exchange_weak自动帮我们做了),再次进入循环。尽管2处又加载了一次head的值给old_head有些重复，但是为了代码的可读性和指针判空，我觉得这么写更合适一点。

资源回收的问题我们还没处理。 我们先实现一个简单的回收处理逻辑

```c++
template<typename T>
std::shared_ptr<T> pop() {
    node* old_head = nullptr; //1        
    do {
        old_head = head.load();
        if (old_head == nullptr) {
            return nullptr; 
        }
    } while (!head.compare_exchange_weak(old_head, old_head->next)); //2        

    std::shared_ptr<T> res;   //3
    res.swap(old_head->data); //4
    delete old_head;  //5 
    return res;  //6    
}
```

上面的代码在3处定义了一个T类型的智能指针res用来返回pop的结果，所以在4处将`old_head`的data值转移给res，这样就相当于清除`old_head`的data了。

在5处删除了old_head. 意在回收数据，但这存在很大问题，比如线程1执行到5处删除old_head，而线程2刚好执行到2处用到了和线程1相同的`old_head`，线程2执行`compare_exchange_weak`的时候`old_head->next`会引发崩溃。

所以要引入一个机制，延迟删除节点。将本该及时删除的节点放入待珊节点。基本思路如下

1. 如果有多个线程同时pop，而且存在一个线程1已经交换取出head数据并更新了head值，另一个线程2即将基于旧有的head获取next数据，如果线程1删除了旧有head，线程2就有可能产生崩溃。这种情况我们就要将线程1取出的head放入待删除的列表。
2. 同一时刻仅有一个线程1执行pop函数，不存在其他线程。那么线程1可以将旧head删除，并删除待删列表中的其他节点。
3. 如果线程1已经将head节点交换弹出，线程2还未执行pop操作，当线程1准备将head删除时发现此时线程2进入执行pop操作，那么线程1能将旧head删除，因为线程2读取的head和线程1不同(线程2读取的是线程1交换后新的head值)。此情形和情形1略有不同，情形1是两个线程同时pop只有一个线程交换成功的情况，情形3是一个线程已经将head交换出，准备删除之前发现线程2执行pop进入，所以这种情况下线程1可将head删除，但是线程1不能将待删除列表删除，因为有其他线程可能会用到待删除列表中的节点。


我们思考这种情形

线程1 执行pop已经将head换出
线程2 执行pop函数，发现线程1正在pop操作，线程2就将待删除的节点head(此head非线程1head)放入待删列表.
线程3 和线程2几乎同时执行pop函数但是还未执行head的交换操作，此head和线程2的head相同。

这种情况下线程1可能读取待删列表为空，因为线程2可能还未更新，也可能读取待删列表不为空(线程2已更新)，但是线程1不能删除这个待删列表，因为线程3可能在用。
那基于上述三点，我们可以简单理解为

1. 如果head已经被更新，且旧head不会被其他线程引用，那旧head就可以被删除。否则放入待删列表。
2. 如果仅有一个线程执行pop操作，那么待删列表可以被删除，如果有多个线程执行pop操作，那么待删列表不可被删除。

我们需要用一个原子变量`threads_in_pop`记录有几个线程执行pop操作。在pop结束后再减少threads_in_pop。 我们需要一个原子变量to_be_deleted记录待删列表的首节点。

那么我们先实现一个改造版本

```c++
std::shared_ptr<T> pop() {
     //1 计数器首先自增，然后才执行其他操作
    ++threads_in_pop;  
    node* old_head = nullptr;     
    do {
        //2 加载head节点给旧head存储
        old_head = head.load();  
        if (old_head == nullptr) {
            --threads_in_pop;
            return nullptr; 
        }
    } while (!head.compare_exchange_weak(old_head, old_head->next)); // 3    
    //3处 比较更新head为旧head的下一个节点    

    std::shared_ptr<T> res;
    if (old_head)
    {
        // 4 只要有可能，就回收已删除的节点数据
        res.swap(old_head->data);    
    }
    // 5 从节点提取数据，而非复制指针
    try_reclaim(old_head);   
    return res;
}
```

1. 在1处我们对原子变量threads_in_pop增加以表示线程执行pop函数。 
2. 在2处我们将head数据load给old_head。如果old_head为空则直接返回。 
3. 3处通过head和old_head作比较，如果相等则交换，否则重新do while循环。这么做的目的是为了防止多线程访问，保证只有一个线程将head更新为old_head的下一个节点。 
4. 将old_head的数据data交换给res。 
5. `try_reclaim`函数就是删除old_head或者将其放入待删列表，以及判断是否删除待删列表。

接下来我们实现try_reclaim函数
```c++
void try_reclaim(node* old_head)
{
    //1 原子变量判断仅有一个线程进入
    if(threads_in_pop == 1)
    {
        //2 当前线程把待删列表取出
        node* nodes_to_delete = to_be_deleted.exchange(nullptr);
        //3 更新原子变量获取准确状态，判断pop是否仅仅正被当前线程唯一调用
        if(!--threads_in_pop)
        {
            //4 如果唯一调用则将待删列表删除
            delete_nodes(nodes_to_delete);
        }else if(nodes_to_delete)
        {
            //5 如果pop还有其他线程调用且待删列表不为空，
            //则将待删列表首节点更新给to_be_deleted
            chain_pending_nodes(nodes_to_delete);
        }
        delete old_head;
    }
    else {
        //多个线程pop竞争head节点，此时不能删除old_head
        //将其放入待删列表
        chain_pending_node(old_head);
        --threads_in_pop;
    }
}
```

1. 1处我们判断pop的线程数是否为1，并没有采用load，也就是即便判断的时候其他线程也可以pop，这样不影响效率，即便模糊判断threads_in_pop为1，同一时刻threads_in_pop可能会增加也没关系，threads_in_pop为1仅表示当前时刻走入1处逻辑之前仅有该线程执行pop，那说明没有其他线程竞争head，head已经被更新为新的值，其他线程之后pop读取的head和我们要删除的old_head不是同一个，就是可以被直接删除的。 
2. 处我们将当前待删除的列表交换给本线程的nodes_to_delete临时变量，表示接管待删除列表。但是能否删除还要判断是不是仅有本线程在执行pop。

3 处更新原子变量获取准确状态，判断pop是否仅仅正被当前线程唯一调用，如果是被唯一调用则删除待删列表，否则将nodes_to_delete临时变量再更新回待删列表。(因为可能有多个线程会用待删列表中的节点)

接下来我们实现`delete_nodes`函数, 该函数用来删除以nodes为首节点的链表，该函数写成了static函数，也可以用普通函数。

```c++
static void delete_nodes(node* nodes)
{
    while (nodes)
    {
        node* next = nodes->next;
        delete nodes;
        nodes = next;
    }
}
```

接下来实现chain_pending_node函数，该函数用来将单个节点放入待删列表

```c++
void chain_pending_node(node* n)
{
    chain_pending_nodes(n, n);   
}
```

`chain_pending_nodes`接受两个参数，分别为链表的头和尾。

```c++
void chain_pending_nodes(node* first, node* last)
{
    //1 先将last的next节点更新为待删列表的首节点
    last->next = to_be_deleted;    
    //2  借循环保证 last->next指向正确
    // 将待删列表的首节点更新为first节点
    while (!to_be_deleted.compare_exchange_weak(
        last->next, first));     
}
```

1. 处将last->next的值更新为to_be_deleted, 这么做的一个好处是如果有其他线程修改了to_be_deleted.能保证当前线程的last->next指向的是最后修改的to_be_deleted，达到链接待删列表的作用。 
2. 处可能更新失败，因为其他线程修改了to_be_deleted的值，但是不要紧，我们再次循环直到匹配last->next的值为to_be_deleted为止，将to_be_deleted更新为first的值。

接下来我们还要实现将nodes_to_delete为首的链表还原到待删列表中, 函数为chain_pending_nodes接受一个参数为待还原的链表的首节点

```c++
void chain_pending_nodes(node* nodes)
{
    node* last = nodes;
    //1 沿着next指针前进到链表末端
    while (node* const next = last->next)    
    {
        last = next;
    }
    //2 将链表放入待删链表中
    chain_pending_nodes(nodes, last);
}
```

### 分析

上面的无锁栈存在一个问题，就是当多个线程pop时将要删除的节点放入待删列表中，如果每次pop都会被多个线程调用，则要删除的节点就会一直往待删除列表中增加，导致待删除列表无法被回收。这个问题我们可以考虑当pop执行结束时最后一个线程回收待删列表。留作下一节分析。

我们先写一个函数测试以下

```c++
void TestLockFreeStack() {

    lock_free_stack<int> lk_free_stack;
    std::set<int>  rmv_set;
    std::mutex set_mtx;

    std::thread t1([&]() {
        for (int i = 0; i < 20000; i++) {
            lk_free_stack.push(i);
            std::cout << "push data " << i << " success!" << std::endl;
            }
        });

    std::thread t2([&]() {
        for (int i = 0; i < 10000;) {
            auto head = lk_free_stack.pop();
            if (!head) {
                std::this_thread::sleep_for(std::chrono::milliseconds(10));
                continue;
            }
            std::lock_guard<std::mutex> lock(set_mtx);
            rmv_set.insert(*head);
            std::cout << "pop data " << *head << " success!" << std::endl;
            i++;
        }
      });

    std::thread t3([&]() {
        for (int i = 0; i < 10000;) {
            auto head = lk_free_stack.pop();
            if (!head) {
                std::this_thread::sleep_for(std::chrono::milliseconds(10));
                continue;
            }
            std::lock_guard<std::mutex> lock(set_mtx);
            rmv_set.insert(*head);
            std::cout << "pop data " << *head << " success!" << std::endl;
            i++;
        }
        });

    t1.join();
    t2.join();
    t3.join();

    assert(rmv_set.size() == 20000);
}
```


## 风险指针的运用

术语“风险指针”是指`Maged Michael`发明的一种技法， 后来被IBM申请为专利。 前文我们设计了无锁并发栈的结构，对于pop操作回收节点采用的是**延时删除**的策略，即将要删除的节点放入待删除列表中。 但是待删列表中的节点可能永远不会被回收，因为每次多个线程pop就不会触发回收待删列表的操作。上一节我们说可以通过执行pop的最后一个线程执行回收，那为了实现这个目的，我们就要换一种思路。就是我们将要删除的节点做特殊处理，如果**有线程使用它**，就将他标记为正在使用，那么这个节点的指针就是**风险指针**，也就是不能被其他线程删除。

### 改进pop 

我们假设有一块全局区域存储的是一个风险数组，数组里放的就是风险指针。 我们提供一个函数去设置数组中某个节点为风险指针，没被设置为风险指针的节点就是可用的。 然后我们再提供一个函数去查找数组中的节点，返回一个可用的节点。 假设查找的函数叫做`get_hazard_pointer_for_current_thread`。

```c++
std::shared_ptr<T> pop(){
	// 1
	std::atomic<void*>& hp=get_hazard_pointer_for_current_thread(); 
	node* old_head=head.load();  // ⇽---  2
	node* tmp;
	do{
		temp=old_head;
		hp.store(old_head);  // ⇽---  3
		old_head=head.load();
	}while(old_head!=temp);  //  ⇽---  4
	// ...
}
```

1. 处获取数组中可用节点指针，用hp存储节点指针的引用。 
2. 处加载当前头节点保存到old节点里。 
3. 处将old_head的值赋值给hp。 
4. while循环处的作用就是防止多个线程访问pop函数，某一个线程B将head修改，那说明他已经将它的临时变量old节点放入风险数组中，而本线程A的old节点和线程B的old节点指向的是同一个旧有的head，所以线程A就没必要将这个old节点放入风险数组了，需要再次循环获取新的head加载为old节点，再放入风险数组。

我们实现一个完整意义的pop操作

```c++
std::shared_ptr<T> pop()
{
    //1 从风险列表中获取一个节点给当前线程
    std::atomic<void*>& hp=get_hazard_pointer_for_current_thread(); 
    node* old_head=head.load();
    do
    {
        node* temp;
        do    
        {
            temp=old_head;
            hp.store(old_head);
            old_head=head.load();
        }//2 如果old_head和temp不等说明head被其他线程更新了，需重试
        while(old_head!=temp); 
    }//3 将当前head更新为old_head->next，如不满足则重试
    while(old_head&&
          !head.compare_exchange_strong(old_head,old_head->next)); 
    // 4一旦更新了head指针，便将风险指针清零
    hp.store(nullptr);    
    std::shared_ptr<T> res;
    if(old_head)
    {
        res.swap(old_head->data);
        //5 删除旧有的头节点之前，先核查它是否正被风险指针所指涉
        if(outstanding_hazard_pointers_for(old_head))    
        {
            //6 延迟删除
            reclaim_later(old_head);    
        }
        else
        {
            //7 删除头部节点
            delete old_head;    
        }
        //8 删除没有风险的节点
        delete_nodes_with_no_hazards();    
    }
    return res;
}
```

1. 我们观察1处代码从全局的风险数组中jiu获取一个可用的节点作为风险节点。这样其他线程在回收节点的时候会从这个数组中看到这个风险节点，进而不会删除该节点。 
2. 处代码做循环比较是为了hp存储的节点为当前线程操作的head，如果其它线程更新了head，那么当前线程就要进行重试。以保证每个线程的hp存储的都是自己看到的最新的head。 
3. 处将head和old_head做比较，如果相等则更新head为old_head->next的值。如果不等则再次重复循环，因为有可能有多个线程都满足2处的条件，多个线程的hp和old_head指向相同，所以要重试，保证多线程情况下head的移动唯一。 
4. 一旦更新了head指针，就可以将这个风险指针清零了，因为其他线程pop操作的head已经不是我们hp存储的old_head了。所以此种情况下是线程安全的。 
5. 删除旧节点之前，先看它是否被风险指针所指涉。 
6. 如果要删除的节点被风险指针指涉，则延迟删除，放入待删列表。都则直接删除该节点即可。
7. 每个线程pop后，都要查一下待删列表，将其中没有风险的节点删除。

接下来我们实现从全局连表中返回一个可用的节点
```c++
std::atomic<void*>& get_hazard_pointer_for_current_thread() {
    //每个线程都具有自己的风险指针 线程本地变量
    thread_local static hp_owner hazzard;  
    return hazzard.get_pointer();
}
```

我们通过一个线程本地变量hazzard存储当前线程正在使用的节点，这个节点被称作风险节点。其他线程不能删除。
接下来我们实现`hazard_pointer`类，管理风险指针和线程id
```c++
struct hazard_pointer {
    std::atomic<std::thread::id> id;
    std::atomic<void*>  pointer;
};
```

id为正在使用该风险指针的id，pointer为指针类型，存储的节点数据地址。 当一个线程从风险数组中查找某个闲置节点作为风险节点，则需要将pointer指向节点的数据，并且将id设置为当前的线程id。

我们定义一个全局的风险节点数组，用来存储风险节点。
```c++
hazard_pointer hazard_pointers[max_hazard_pointers];
```

然后我们用hp_owner类管理这个风险指针

```c++
class hp_owner {
public:
    hp_owner(hp_owner const&) = delete;
    hp_owner operator=(hp_owner const&) = delete;
    hp_owner():hp(nullptr){
        for (unsigned i = 0; i < max_hazard_pointers; ++i) {
            std::thread::id  old_id;
            if (hazard_pointers[i].id.compare_exchange_strong(old_id, std::this_thread::get_id())) {
                hp = &hazard_pointers[i];
                break;
            }
        }

        if (!hp) {
            throw std::runtime_error("No hazard pointers available");
        }
    }

    ~hp_owner() {
        hp->pointer.store(nullptr);
        hp->id.store(std::thread::id());
    }
private:
    hazard_pointer* hp;
};
```

每个线程每次调用`get_hazard_pointer_for_current_thread`只会在第一次的时候构造hp_owner类型的hazzard，之后该线程再次调用该函数不会构造hp_owner，因为是线程本地变量。
当一个线程析构的时候会释放其本地变量hazzard，进而执行hp_owner析构函数，从而恢复初值。
接下来我们要实现`hp_owner`的`get_pointer`函数。

```c++
std::atomic<void*>& get_pointer() {
    return hp->pointer;
}
```

hp_owner 的get_pointer函数返回其成员pointer指向的地址
接下来我们实现判断该节点是否被风险指针所指涉的函数
```c++
    bool outstanding_hazard_pointers_for(void* p)
    {
        for (unsigned i = 0; i < max_hazard_pointers; ++i)
        {
            if (hazard_pointers[i].pointer.load() == p)
            {
                return true;
            }
        }
        return false;
    }
```

如果当前节点被风险指针所指涉则将该节点放入待删队列延迟删除
```c++
void reclaim_later(node* old_head) {
    add_to_reclaim_list(new data_to_reclaim(old_head));
}
```

将节点放入待删列表，我们封装了一个`data_to_reclaim`类型的节点放入待删列表。
我们定义待删节点的结构体
```c++
//待删节点
struct data_to_reclaim {
    node* data;
    std::function<void(node*)> deleter;
    data_to_reclaim* next;
    data_to_reclaim(node * p):data(p), next(nullptr){}
    ~data_to_reclaim() {
        delete data;
    }
};
```

然后在无锁栈中定义一个节点表示待删列表的首节点，因为栈是被多个线程操作的，待删列表也会被多个线程访问，那么我们需要用原子变量表示这个首节点

```c++
std::atomic<data_to_reclaim*>  nodes_to_reclaim;
```

我们实现将节点放入待删列表的逻辑
```c++
void add_to_reclaim_list(data_to_reclaim* reclaim_node) {
    reclaim_node->next = nodes_to_reclaim.load();
    while (!nodes_to_reclaim.compare_exchange_weak(reclaim_node->next, reclaim_node));
}
```

因为可能有多个线程同时将节点放入待删列表，所以此处做重试。 接下来实现从待删列表中删除无风险的节点

```c++
void delete_nodes_with_no_hazards() {
    data_to_reclaim* current = nodes_to_reclaim.exchange(nullptr);
    while (current) {
        data_to_reclaim* const next = current->next;
        if (!outstanding_hazard_pointers_for(current->data)) {
                delete current;
        }
        else {
            add_to_reclaim_list(current);
        }
        current = next;
    }
}
```

### 优劣分析

风险指针的机制能保证要删除的节点在合理的时机回收，但是也引发了一些**性能问题**，比如为了删除某个节点要遍历风险数组判断该节点是否被风险指针所指涉。其次我们对于要删除的节点需要从风险数组中选择一个合适的节点记录其地址，所以也需要遍历。 C++ 并发编程一书中提出了用空间换取时间和性能的办法，就是开辟`2*N`个大小的风险数组，只有当使用的节点达到N个时我们才依次判断N个节点是否被风险指针所指涉，这样我i们减少了判断回收的次数。但同样增加内存的开销。 另外作者也提及了风险指针为IBM的技术专利，即使我们懂得这种方法也不见得有权利使用，为后文提及了引用计数做了铺垫。

## 利用引用计数实现无锁栈

前文我们通过风险指针的方式实现了无锁栈，但是也提出了一些弊端，比如每次pop都要从风险数组中选择一个空闲的节点作为标记。其次删除节点前要遍历风险数组对比节点是否被风险指针所指涉，如果被风险指针指涉则需放入待删列表。最后pop结束时也要回收待删列表中的节点，还要依次将待删列表中的节点和风险数组对比，如果未被风险指针指涉则需删除，否则跳过。

但是这种方式多次遍历风险数组，会有**性能损耗**，我们提出一种新的解决方式，利用**引用计数**实现无锁并发的栈。

### 引用计数

在C++并发编程一书中提出了两个计数，一个外部计数，一个内部计数，二者加起来就是有效的引用计数，很多读者对此费解，为何不用一个引用计数维护呢？那本文就是带着大家如何一步一步去实现并说明单引用计数的不可行性。

那我们先定义一个栈结构，以及它的内部节点结构 
```c++
template<typename T>
class single_ref_stack {
public:
    single_ref_stack():head(nullptr) {

    }

    ~single_ref_stack() {
        //循环出栈
        while (pop());
    }

private:
    struct ref_node {
        //1 数据域智能指针
        std::shared_ptr<T>  _data;
        //2 引用计数
        std::atomic<int> _ref_count;
        //3  下一个节点
        ref_node* _next;
        ref_node(T const& data_) : _data(std::make_shared<T>(data_)),
            _ref_count(1), _next(nullptr) {}
    };

    //头部节点
    std::atomic<ref_node*> head;
};
```

1. `single_ref_stack`为我们定义的栈结构。内部包含一个head节点，head节点为一个`ref_node*`类型的原子变量。 
2. `single_ref_stack`的构造函数将head设置为nullptr，析构函数循环pop直到栈为空为止。pop我们之后再实现。 
3. 定义ref_node结构作为每个栈存储的元素。内部包含`_data`表示数据域， int类型的原子变量表示引用计数。`_next`表示下一个节点指针。 ref_node的构造函数接收一个T类型的通用数据类型，利用这个参数构造自己的数据域。

接下来我们实现push操作
```c++
void push(T const& data) {
    auto new_node = new ref_node(data);
    new_node->next = head.load();
    while (!head.compare_exchange_weak(new_node->next, new_node));
}
```

`push` 操作很简单，创建一个`ref_node`类型的指针对象`new_node`，将`new_node`的`next`指针指向现在的头节点，然后不断地重试(防止其他线程修改head后导致head变化不一致),直到将head更新为new_node.

接下来我们实现pop
```c++
std::shared_ptr<T> pop() {
    ref_node* old_head = head.load();
    for (;;) {
        if (!old_head) {
            return std::shared_ptr<T>();
        }
        //1 只要执行pop就对引用计数+1
        ++(old_head->_ref_count);
        //2 比较head和old_head想等则交换否则说明head已经被其他线程更新
        if (head.compare_exchange_strong(old_head, old_head->_next)) {  // ---->1
            auto cur_count = old_head->_ref_count.load();
            auto new_count;
            //3  循环重试保证引用计数安全更新
            do {
                //4 减去本线程增加的1次和初始的1次
                new_count = cur_count - 2;
            } while (!old_head->_ref_count.compare_exchange_weak(cur_count,  new_count));

            //返回头部数据
            std::shared_ptr<T> res;
            //5  交换数据
            res.swap(old_head->_data);
            //6
            if (old_head->_ref_count == 0) {
                delete old_head;
            }

            return res;
        }
        else {  // --->2
            //7 
            if (old_head->_ref_count.fetch_sub(1) == 1) {
                delete old_head;
            }
        }
    }
}
```

1. 上面的代码我们先判断`old_head`是否为空，如果为空则说明栈为空。 
2. 然后代码1处对引用计数+1, 因为是原子变量所以可以保证线程安全。 
3. 然后代码2处比较head和old_head是否相等，如果相等则将head更新为old_head的next指向的数据。 简而言之就是将head更新为新的栈顶元素。因为存在多个线程并发执行2处代码的情况，导致只有一个线程交换成功，交换成功的线程就承担起返回数据的任务。

并且在4处减少2个引用计数(减去初始的1个加上自己pop开始增加的那一个)，并且在3处循环重试更新引用计数。在6处判断引用计数如果变为0则删除指针。

交换失败的线程是抢占失败的线程，则执行7处代码需减少1次引用计数(因为该线程进入pop时已经增加了1次引用计数)。fetch_sub会将原子变量的数值减1，然后返回减少之前的数值。所以我们判断如果之前的数值为1则说明该线程是最后引用此指针的线程，可以将指针删除。

我们观察上述pop函数，存在严重漏洞
1. 线程1和线程2同时执行1处,线程1先进去，执行完new_count=1，不删除返回，线程2执行1处判断失败，old_head变化为head，执行2处操作执行了删除，删除了错误的节点，并且没有返回，for循环继续执行，后面的其线程的head都会崩溃
 

引发崩溃的原因我们知道了就是old_head被删除了，那我们要做的就是将引用计数提出来，不放在指针里，和指针**解耦**。
我们将原来的节点结构拆成两个
```c++
struct node {
    //1 数据域智能指针
    std::shared_ptr<T>  _data;
    //2  下一个节点
    ref_node _next;
    node(T const& data_) : _data(std::make_shared<T>(data_)) {}

};

struct ref_node {
    // 引用计数
    std::atomic<int> _ref_count;

    node* _node_ptr;
    ref_node( T const & data_):_node_ptr(new node(data_)), _ref_count(1){}

    ref_node():_node_ptr(nullptr),_ref_count(0){}
};
```

`ref_node`表示栈存储的节点结构，包括引用计数和节点的指针。而`node`为实际的节点结构，包括节点的数据域以及下一个节点的地址。
那我们的`single_ref_stack`结构管理的head是指针类型好还是副本类型好呢？
我们可以假设head存储的是指针类型
```c++
//头部节点
std::atomic<ref_node*> head;
```

那么pop逻辑就要改为
```c++
std::shared_ptr<T> pop() {
    //0 处
    ref_node* old_head = head.load();
    for (;;) {
        //1 只要执行pop就对引用计数+1并更新到head中
        ref_node* new_head;
        do {
            new_head = old_head;
            //7 处
            new_head->_ref_count += 1;
        } while (!head.compare_exchange_weak(old_head, new_head));
        //4 
        old_head = new_head;

        auto* node_ptr = old_head->_node_ptr;
        if (node_ptr == nullptr) {
            return  std::shared_ptr<T>();
        }

        //2 比较head和old_head想等则交换否则说明head已经被其他线程更新
        if (head.compare_exchange_strong(old_head, node_ptr->_next)) {

            //要返回的值
            std::shared_ptr<T> res;
            //交换智能指针
            //5 处
            res.swap(node_ptr->_data);

            //6 增加的数量
            int increase_count = old_head->_ref_count.fetch_sub(2);

            //3 处判断仅有当前线程持有指针则删除
            if (increase_count == 2) {
                delete node_ptr;
            }

            return res;
        }else {
            if (old_head->_ref_count.fetch_sub(1) == 1) {
                delete node_ptr;
            }
        }
    }
}
```

解释一下上面的逻辑：
在1处head调用比较交换和old_head做比较，比较分为两个方面，一个是引用计数一个是`node*`的值。
那我们假设线程1和线程2依次通过了比较交换逻辑(假设线程1先于线程2)，那么假设线程1在4处看到的old_head的引用计数为2，线程2在4处看到old_head的引用计数为3.
而head最后被更新的引用计数为3.所以在2处的判断逻辑里，线程2会进入if的逻辑，线程1会进入else的逻辑,最后会有一个线程回收node_ptr节点，这么看来是正常的。
但是我们仔细分析，看上面的代码有很大漏洞
1. 假设线程1比线程2先执行，线程1在2处执行比较交换后head会被更新为新的值。线程2执行比较交换操作会失败，则进入else处理, old_head会被更新为新的head值， 此时old_head的引用计数为1则会被线程2误删，因为线程2此时读到的old_head正是新的head指向的数据。而且没有弹出和修改head的值。这样其他线程pop头部元素时会崩溃。
	<img src="https://cdn.llfc.club/1703215490981.jpg" alt="image.png" style="zoom:60%;" />
2. 线程1和线程2都执行完0处代码，二者读取的old_head值相同。假设线程1比线程2先执行，线程2因未抢占到cpu的时间片停顿在1处，线程1按次序依次执行最后执行到3处将`node_ptr`删除。而且现在的head已经指向了新的栈顶元素即`old_head`的下一个元素。此时线程2抢占到时间片，执行1处代码又将old_head更新为head当前值了，只不过引用计数加了1变为2，但是指向的是下一个节点，所以这种情况下进入仍会进入if条件，对新的old_head节点删除。这种情况倒是正常。
	<img src="https://cdn.llfc.club/1703215559019.jpg" alt="image.png" style="zoom:60%;" />
3. 还是假设线程1和线程2都执行完0处代码，线程1抢先执行完5处。准备执行6处时，线程2抢占CPU执行了7处代码，尽管会被while比较old_head和head不同而重试，进而更新`old_head`。但是线程2的do逻辑中第一次的old_head和线程1的old_head指向的是同一个，线程2修改了`old_head`中的引用计数，导致线程1执行6处代码时不会进入if逻辑。又因为线程2在2处之后while会不断重试，线程2的head已经和old_head指向不同了，导致线程2也不会回收old_head内部节点指向的数据，导致内存泄漏。

	<img src="https://cdn.llfc.club/1703215758466.jpg" alt="image.png" style="zoom:60%;" />

这就告诉我们当我们设计pop逻辑的时候尽量不要存储指针，存储指针意味着存在多个线程操作同一块内存的情况。 
所以我们得出以下结论
1. head的类型修改为ref_node类型而不是指针。
2. 现有的引用保留，我们用其表示增加的引用计数，该引用计数可以用原子类型，也可以不用原子类型。为简化和节省效率我们用普通int类型。
3. 新增一个表示减少的引用计数，因为这个表示减少的引用计数要在多个线程中同步，并且要保证安全性，那我们将其放入node类里, 因为node类的指针被存储在栈的节点中，所以可以达到多个线程修改这个减少的引用计数的效果。
4. 一个节点能否被回收取决于整体的引用计数是否为0。

### 改进引用节点
按照上面的推论，我们新增_dec_count表示减少的引用计数，放在node结构里。
```c++
    struct ref_node;
    struct node {
        //1 数据域智能指针
        std::shared_ptr<T>  _data;
        //2  下一个节点
        ref_node _next;
        node(T const& data_) : _data(std::make_shared<T>(data_)) {}

        //减少的数量
        std::atomic<int>  _dec_count;
    };

    struct ref_node {
        // 引用计数
        int _ref_count;

        node* _node_ptr;
        ref_node( T const & data_):_node_ptr(new node(data_)), _ref_count(1){}

        ref_node():_node_ptr(nullptr),_ref_count(0){}
    };
```

然后将栈中的head结构变为ref_node类型的原子变量。

```c++
//头部节点
std::atomic<ref_node> head;
```

我们重新实现push

```c++
    void push(T const& data) {
        auto new_node =  ref_node(data);
        new_node._node_ptr->_next = head.load();
        while (!head.compare_exchange_weak(new_node._node_ptr->_next, new_node));
    }
```

我们重新实现pop

```c++
std::shared_ptr<T> pop() {
    ref_node old_head = head.load();
    for (;;) {
        //1 只要执行pop就对引用计数+1并更新到head中
        ref_node new_head;

        //2
        do {
            new_head = old_head;
            new_head._ref_count += 1;
        } while (!head.compare_exchange_weak(old_head, new_head));

        old_head = new_head;
        //3
        auto* node_ptr = old_head._node_ptr;
        if (node_ptr == nullptr) {
            return  std::shared_ptr<T>();
        }

        //4 比较head和old_head相等则交换否则说明head已经被其他线程更新
        if (head.compare_exchange_strong(old_head, node_ptr->_next)) {

            //要返回的值
            std::shared_ptr<T> res;
            //交换智能指针
            res.swap(node_ptr->_data);

            //5  增加的数量
            int increase_count = old_head._ref_count - 2;
            //6  
            if (node_ptr->_dec_count.fetch_add(increase_count) == -increase_count) {
                delete node_ptr;
            }

            return res;
        }else {
            //7
            if (node_ptr->_dec_count.fetch_sub(1) == 1) {
                delete node_ptr;
            }
        }
    }
}
```


1. 多个线程并发pop如果有线程在2处重试，可能时head和old_head的引用计数不同或者node的地址不同，不过无论如何我们的head采用的是副本存储，所以重试失败增加的引用计数不会影响到其他线程。
2. 在代码3处我们将old_head的node地址取出来，留作node_ptr,这样我们以后可以对node_ptr内部的引用计数做减少，因为多个线程操作node_ptr指向的数据，所以引用计数是原子变量，并且多个线程是可见的。
3. 在4处进行判断，由于我们的head存储的是ref_node类型，所以多个线程看到的old_head的值可能不一样，但我们能保证仅有一个线程进入if逻辑，进入的线程就是old_head和head匹配的那个，我们定义了res用来返回数据。在5处对增加的引用计数减2操作，获取除了自己以外并行操作这个old_head的线程数。然后我们说过增加引用计数和减少引用计数相加为0就说明可以删除节点。那我们在6处利用fetch_add操作返回操作之前的值，让fetch_add增加`increase_count`，并且`fetch_add`返回增加之前`_dec_count`的值，如果这个值是负的`increase_count`即表示当前仅有该线程操作这个old_head节点，即可删除。

为了让大家了解这个过程我们假设线程1和线程2都执行到4处之前，线程2没抢占到cpu暂停，而线程1抢占并且执行了4处的交换进入if条件，而此时线程2抢占cpu继续执行else逻辑，将_dec_count减少1，原来的`_dec_count`为0，减少后变为-1，fetch_sub返回之前的值为0不满足if条件所以线程2不会删除node_ptr。此时线程1继续抢占cpu执行到5处`_ref_count`为3，increse_count为1，`_dec_count`为-1，`_dec_count`进行`fetch_add`之后变为0,但是`fetch_add`返回的时相加之前的值即为-1，而`increase_count`恰好为1，所以线程1回收这个node_ptr。

### 测试和验证

为了测试安全性，效率就不测了，这个无锁的栈后期还要完善，目前我们只要测试安全性即可。
我们启动三个线程t1,t2,t3，t1用来向栈中压入元素,t2和t3用来从栈中弹出元素。

```c++
void TestSingleRefStack() {
    single_ref_stack<int>  single_ref_stack;
    std::set<int>  rmv_set;
    std::mutex set_mtx;

    std::thread t1([&]() {
        for (int i = 0; i < 20000; i++) {
            single_ref_stack.push(i);
            std::cout << "push data " << i << " success!" << std::endl;
            std::this_thread::sleep_for(std::chrono::milliseconds(5));
        }
        });

    std::thread t2([&]() {
        for (int i = 0; i < 10000;) {
            auto head = single_ref_stack.pop();
            if (!head) {
                std::this_thread::sleep_for(std::chrono::milliseconds(10));
                continue;
            }
            std::lock_guard<std::mutex> lock(set_mtx);
            rmv_set.insert(*head);
            std::cout << "pop data " << *head << " success!" << std::endl;
            i++;
        }
        });

    std::thread t3([&]() {
        for (int i = 0; i < 10000;) {
            auto head = single_ref_stack.pop();
            if (!head) {
                std::this_thread::sleep_for(std::chrono::milliseconds(10));
                continue;
            }
            std::lock_guard<std::mutex> lock(set_mtx);
            rmv_set.insert(*head);
            std::cout << "pop data " << *head << " success!" << std::endl;
            i++;
        }
        });

    t1.join();
    t2.join();
    t3.join();

    assert(rmv_set.size() == 20000);
}
```


## 利用内存模型优化无锁栈

前文我们通过引用计数实现了无锁并发的栈结构，但是对于原子变量的读，写以及读改写操作默认采用的是`memory_order_seq_cst`,`memory_order_seq_cst`为**全局顺序模型**，也就是所有线程看到的执行顺序一致，但是这种模型对性能消耗较大，本文在之前实现的无锁栈的基础上介绍如何通过更为宽松的模型提升性能。先带着大家复习一下内存模型相关知识

### release-acquire同步

我们在之前的文章介绍了6种内存顺序，其中我们可以通过`release`和`acquire`的方式实现同步的效果，现在带着大家复习一下：

线程A执行store操作，采用`memory_order_release`顺序模型。线程B执行load操作采用`memory_order_acquire`顺序模型。如果线程B的load操作读取到A操作的store操作的数值，我们称线程a的store操作synchronizes-with(同步)线程b的load操作

### happens-before先行

因为`a->store`同步于`b->load`， 则 `a->store`先行于`b->load`。
只要同步就能推出先行，所谓先行就是逻辑执行的顺序，一定是`a->store`先于`b->load`
先行还包括一种情况，`sequenced-before`(顺序执行)， 所谓顺序执行就是单线程中执行的顺序为从上到下的顺序, 比如  

```c++
int func(){
    int a = 1008; //1
    int b = 1024; //2
}
```

单线程角度1先于2执行(`1 sequenced before 2`)，也可推导出1先行于2.
先行具有传递性 `1 happens-before 2`， `2 happens-before 3`, 则`1 happens-before 3`
注意先行是C++语意层面的概念， 指令实际的执行顺序可能是先2后1，取决于编译器。

但是我们可以通过**内存顺序进行约束**达到指令编排让1先于2的目的。如release内存序能保证其写操作之前的指令不会排在其后。acquire内存序能保证其读操作之前写入的指令不会排在其之后，也能保证其之后的指令不会排在读之前。所以release和acquire形成同步后类似于屏障，当然C++ 也有类似于的原语`std::atomic_thread_fence`(栅栏)。

写个代码复习一下

```c++
void TestReleaseSeq() {
    int data = 0;
    std::atomic<int> flag = 0;
    std::thread t1([&]() {
        data = 42;  //1
        flag.store(1, std::memory_order_release); //2  这个原子操作之前的所有写操作都不会被重排到这个操作之后。
        });

    std::thread  t2([&]() {
        //3
        while (!flag.load (std::memory_order_acquire));
        //4 
        assert(data == 42);
    });

    t1.join();
    t2.join();
}
```

我们从两方面解读代码：

1. 指令编排角度,2处使用了release内存序，使用`std::memory_order_release`语义的关键点在于，它确保了在**这个存储操作之前的所有写操作都不会被重排序到这个操作之后**。 
2. 理论上，如果没有其他约束，编译器或CPU确实可能会尝试将第4行（`assert(data == 42);`）重排到第3行（`while`循环）之前或其中。实际上不会这样做： a. 控制流依赖：`assert` 语句在 `while` 循环之后，形成了一个控制流依赖。编译器和CPU通常会保持这种依赖关系。 b. 数据依赖：虽然不是直接的数据依赖，但 `flag` 的值影响了是否执行 `assert`，这也是一种依赖关系。 c. 编译器屏障：`std::atomic` 操作（如 `flag.load()`）通常会作为编译器屏障，阻止某些重排序。

### 释放序列的扩展

这段文字摘录于C++并发编程一书

> 如果存储操作的标记是`memory_order_release`、`memory_order_acq_rel`或`memory_order_seq_cst`，而载入操作则以`memory_order_consume`、`memory_order_acquire`或`memory_order_seq_cst`标记，这些操作前后相扣成链，每次载入的值都源自前面的存储操作，那么该操作链由一个释放序列组成。若最后的载入操作服从内存次序`memory_order_acquire`或`memory_order_seq_cst`，则最初的存储操作与它构成同步关系。但如果该载入操作服从的内存次序是`memory_order_consume`，那么两者构成前序依赖关系。操作链中，每个“读-改-写”操作都可选用任意内存次序，甚至也能选用`memory_order_relaxed`次序。


我们对上述阐述总结为下面的理解
`release-sequnece`的概念如下：
针对一个原子变量M的`release`操作A完成后, 接下来M上可能还会有一连串的其他操作. 如果这一连串操作是由
1. 同一线程上的写操作
2. 或者任意线程上的`read-modify-write`(可以是任意内存顺序) 操作
这两种构成的, 则称这一连串的操作为以release操作A为首的`release sequence`.这里的写操作和`read-modify-write`操作可以使用任意内存顺序.
而同步的概念是：
	一个acquire操作在同一个原子变量上读到了一个`release`操作写入的值, 或者读到了以这个release操作为首的`release sequence`写入的值, 那么这个 release操作 “`synchronizes-with`” 这个 acquire 操作
所以`release-sequence`不一定构成同步，只有acquire到release的值才算作同步。
我们看下面的例子,该例子选取自C++ 并发编程中，我对其稍作修改以保证可以正常运行。
我们先定义了三个全局变量，分别是`queue_data`表示入队的数据，count表示入队的数量。`store_finish`表示存储完成。
```c++
std::vector<int> queue_data;
std::atomic<int> count;
std::atomic<bool> store_finish = false;
```

我们实现入队逻辑，这个逻辑以后会有一个线程独立执行

```c++
void populate_queue()
{
    unsigned const number_of_items = 20;
    queue_data.clear();
    for (unsigned i = 0; i < number_of_items; ++i)
    {
        queue_data.push_back(i);
    }
    // 1 最初的存储操作
    count.store(number_of_items, std::memory_order_release);   
    store_finish.store(true, std::memory_order_release);
}
```

上述函数将20个元素从0到19依次入队，然后修改count值为20，使用release内存顺序，并且将完成标记设置为true.
然后我们实现消费函数

```c++
void consume_queue_items()
{
    while (true)
    {
        //2等待存储完成
        while (!store_finish.load(std::memory_order_acquire));

        int item_index;
        //3 读—改—写”操作
        if ((item_index = count.fetch_sub(1, std::memory_order_acquire)) <= 0)   
        {
            return;
        }
        //4 从内部容器queue_data 读取数据项是安全行为
        std::cout << "queue_data is  " << queue_data[item_index-1] << std::endl;
    }
}
```

上述函数，我们在2处等待存储完成，在3处读改写修改count的值，采用的是acquire内存顺序，然后我们从队列中根据item_index读取数据。
假设一个线程t1用来执行populate_queue，一个线程t2用来执行consume_queue_items。
那么因为`release-acquire`的关系，我们可以推断出 `t1 synchronizes-with t2`.
那我们用三个线程并行操作会怎样呢？
```c++
void TestReleaseSeq2() {
    std::thread a(populate_queue);
    std::thread b(consume_queue_items);
    std::thread c(consume_queue_items);
    a.join();
    b.join();
    c.join();
}
```

可以看到输出如下

<img src="https://cdn.llfc.club/1703586901585.jpg" alt="image.png" style="zoom:60%;" />


虽然控制台打印混乱，但是我们可以看到消费者线程t2和t3并没有打印重复的数据，说明他们互斥访问count,每个线程取到的count不一样进而访问queue_data中的不同数据。

假设只有一个线程a和线程b,我们知道一个生产者a和一个消费者b构成了同步关系，没有问题，如果增加了消费者线程c，b和c中都有fetch_sub这种读-改-写操作，采用的都是acquire内存顺序，但从线程b和c的角度并不能构成同步，那是不是就意味着b和c可能获取到count的值相同？

答案是否定的，单从线程角度b和c并不能构成同步，但是b和c必然有一个线程先执行一个线程后执行fetch_sub(原子变量的操作任何顺序模型都能保证操作的原子性)。假设b先执行，和a构成`release-sequence`关系，b读取到a执行的`count strore`的结果， b处于以a线程的release为首的释放序列中，则b的store操作会和c的读-改-写(fetch操作)构成同步(c 采用的是acquire). [C++并发编程一书](https://book.douban.com/subject/35653912/)中对类似的代码也做了同样的解释。

如下图是书中给出的图示，实线表示先行关系，虚线标识释放序列

<img src="https://cdn.llfc.club/1703666791712.jpg" alt="image.png" style="zoom:60%;" />


那我们可以这么简化上面的分析结论

1. a线程和b线程构成release-sequence的释放序列
2. 即使b线程和c线程不构成同步，但是b线程的读改写操作处于release-sequence中，且c线程采用acquire方式读改写，则b的读改写和c线程的读改写构成同步， 以a线程的release为首的sequence序列和c线程的读改写构成同步。
3. 这里要强调一点， 如果a relese-sequence b， a和b不一定构成同步，但是b sychronizes with c， 则a synchronizes with c. 简单来说处于relase序列中的任意读改写操作和其他的线程构成同步，那么我们就能得出relese-sequence为首的操作和其他线程同步。

### 优化无锁栈

我们优化无锁栈先从push操作下手，我们要考虑的是如果有数据入栈，那么pop时要读取的数据。所以我们要让push操作同步给pop操作，想到的办法很简单，push对head的修改采用release内存序列，pop对head的读改写采用acquire内存序列。

如果未有元素入栈，多个线程pop并不会产生问题，根据head内部的ptr指向为空判断空栈直接返回空指针。

如果此时已经有一个元素在栈中，多个线程并发pop，执行读改写操作，这些线程本来是无法同步的，但是最先pop的线程会和push线程构成同步关系，且形成`release-sequence`。那之后的线程pop就会和第一个pop的线程的写操作形成同步。

简单总结上面的含义：

1. 因为要保证pop操作时节点的数据是有效的。push和pop要构成同步关系，push 采用release内存序修改head，pop 采用acquire内存序修改head
2. 第一个pop的线程的写操作和之后的pop线程读操作要构成同步关系


## 无锁并发队列的设计

前文介绍了无锁并发栈的设计，本文继续介绍无锁队列的设计。队列和栈容器的难点稍微不同，因为对于队列结构，push()和pop()分别访问其不同部分，而在栈容器上，这两项操作都访问头节点，所以两种数据结构所需的同步操作相异。如果某线程在队列一端做出改动，而另一线程同时访问队列另一端，代码就要保证前者的改动过程能正确地为后者所见

### 单一消费者和生产者队列

我们实现一个简单的无锁队列，只应对一个生产者一个消费者的情况，便于我们理解

```c++
#include<atomic>
#include<memory>
template<typename T>
class SinglePopPush
{
private:
    struct node
    {
        std::shared_ptr<T> data;
        node* next;
        node() :
            next(nullptr)
        {}
    };
    std::atomic<node*> head;
    std::atomic<node*> tail;
    node* pop_head()
    {
        node* const old_head = head.load();
        // ⇽-- - 1
        if (old_head == tail.load())   
        {
            return nullptr;
        }
        head.store(old_head->next);
        return old_head;
    }
public:
    SinglePopPush() :
        head(new node), tail(head.load())
    {}
    SinglePopPush(const SinglePopPush& other) = delete;
    SinglePopPush& operator=(const SinglePopPush& other) = delete;
    ~SinglePopPush()
    {
        while (node* const old_head = head.load())
        {
            head.store(old_head->next);
            delete old_head;
        }
    }
    std::shared_ptr<T> pop()
    {
        node* old_head = pop_head();
        if (!old_head)
        {
            return std::shared_ptr<T>();
        }
        // ⇽-- -2
        std::shared_ptr<T> const res(old_head->data);  
            delete old_head;
        return res;
    }
    void push(T new_value)
    {
        std::shared_ptr<T> new_data(std::make_shared<T>(new_value));
        // ⇽-- - 3
        node* p = new node;    
        //⇽-- - 4
        node* const old_tail = tail.load(); 
        //⇽-- - 5
        old_tail->data.swap(new_data);   
        //⇽-- - 6
        old_tail->next = p; 
        //⇽-- - 7
        tail.store(p);    
    }
};
```

上面的实现初看上去还不错。在同一时刻，如果只有一个线程调用push()，且仅有一个线程调用pop()，这份代码便可以相对完美地工作。

本例中的push()和pop()之间存在先行关系，这点很重要，它使队列的使用者可安全地获取数据。

tail指针的存储操作7与其载入操作1同步：按控制流程，在运行push()的线程上，原有的尾节点中的data指针先完成存储操作5，然后tail才作为指针存入新值7；

并且，在运行pop()的线程上，tail指针先完成载入操作1，原来的data指针才执行加载操作2，故data的存储操作5在载入操作1之前发生

（全部环节正确无误。因此这个单一生产者、单一消费者（Single-Producer Single-Consumer，SPSC）队列可以完美地工作。

不过，若多个线程并发调用push()或并发调用pop()，便会出问题。我们先来分析push()。如果有两个线程同时调用push()，就会分别构造一个新的空节点并分配内存3，而且都从tail指针读取相同的值4，结果它们都针对同一个尾节点更新其数据成员，却各自把data指针和next指针设置为不同的值5和6。这形成了数据竞争！

pop_head()也有类似问题，若两个线程同时调用这个函数，它们就会读取同一个头节点而获得相同的next指针，而且都把它赋予head指针以覆盖head指针原有的值。最终两个线程均认为自己获取了正确的头节点，这是错误的根源。给定一项数据，我们不仅要确保仅有一个线程可对它调用pop()，如果有别的线程同时读取头节点，则还需保证它们可以安全地访问头节点中的next指针。我们曾在前文的无锁栈容器中遇见过类似问题，其pop()函数也有完全相同的问题。

### 多线程push

解决多线程push的竞争问题。

一种方法是将data指针原子化，通过比较-交换操作来设置它的值。如果比较-交换操作成功，所操作的节点即为真正的尾节点，我们便可安全地设定next指针，使之指向新节点。若比较-交换操作失败，就表明有另一线程同时存入了数据，我们应该进行循环，重新读取tail指针并从头开始操作。

如果`std::shared_ptr<>`上的原子操作是无锁实现，那便万事大吉，否则我们仍需采取别的方法。一种可行的方法是令pop()返回`std::unique_ptr<>`指针（凭此使之成为指涉目标对象的唯一指针），并在队列中存储指向数据的普通指针。这样让代码得以按`std::atomic<T*>`的形式存储指针，支持必要的`compare_exchange_strong()`调用。

```c++
void push(T new_value)
{
    std::unique_ptr<T> new_data(new T(new_value));
    counted_node_ptr new_next;
    new_next.ptr=new node;
    new_next.external_count=1;
    for(;;)
    {
        //⇽--- 1
        node* const old_tail=tail.load();    
        T* old_data=nullptr;
        //⇽--- 2
        if(old_tail->data.compare_exchange_strong(
            old_data,new_data.get()))   
        {
            old_tail->next=new_next;
            // 3
            tail.store(new_next.ptr);    
            new_data.release();
            break;
        }
    }
}
```


引用计数避免了上述的数据竞争，但那不是push()中仅有的数据竞争。只要我们仔细观察，便会发现其代码模式与栈容器相同：先载入原子指针1，然后依据该指针读取目标值2。

另一线程有可能同时更新tail指针3，如果该更新在pop()内部发生，最终将导致删除尾节点。若尾节点先被删除，代码却依然根据指针读取目标值，就会产生未定义行为。

有一种方法能解决上面的问题，且该方法颇具吸引力：在尾节点中添加一外部计数器，与处理头节点的方法相同。不过队列中的每个节点已配备一个外部计数器，分别存储在对应前驱节点内的next指针中。

若要让同一个节点具有两个外部计数器，便需要改动引用计数的实现方式，以免过早删除节点。我们为了满足上述要求，可在节点的结构体中记录外部计数器的数目，外部计数器一旦发生销毁，该数目则自减，并且将该外部计数器的值加到内部计数器的值之上。对于任意特定节点，如果内部计数器的值变为零，且再也没有外部计数器存在，我们就知道该节点能被安全地删除.

```c++
template<typename T>
class lock_free_queue
{
private:
    struct node;
    struct counted_node_ptr
    {
        int external_count;
        node* ptr;
    };
    std::atomic<counted_node_ptr> head;
    //⇽--- 1
    std::atomic<counted_node_ptr> tail;    
    struct node_counter
    {
        unsigned internal_count:30;
        //⇽--- 2
        unsigned external_counters:2;   
    };
    struct node
    {
        std::atomic<T*> data;
        //⇽---  3
        std::atomic<node_counter> count;    
        counted_node_ptr next;
        node()
        {
            node_counter new_count;
            new_count.internal_count=0;
            //⇽---  4
            new_count.external_counters=2;    
            count.store(new_count);
            next.ptr=nullptr;
            next.external_count=0;
        }
    };
public:
    void push(T new_value)
    {
        std::unique_ptr<T> new_data(new T(new_value));
        counted_node_ptr new_next;
        new_next.ptr=new node;
        new_next.external_count=1;
        counted_node_ptr old_tail=tail.load();
        for(;;)
        {
            // 5
            increase_external_count(tail,old_tail);    
            T* old_data=nullptr;
            // 6
            if(old_tail.ptr->data.compare_exchange_strong(   
               old_data,new_data.get()))
            {
                old_tail.ptr->next=new_next;
                old_tail=tail.exchange(new_next);
                //  7
                free_external_counter(old_tail);    
                new_data.release();
                break;
            }
            old_tail.ptr->release_ref();
        }
    }
};
```

tail指针(1处) 和head指针的型别均为atomic<counted_node_ptr>，而node结构体则以成员count (3处)取代原有的internal_count。

该count成员也是一个结构体，内含internal_count变量和新引入的external_counters变量(2处) 。请注意，external_counters仅需使用两位，因为同一个节点最多只可能有两个外部计数器。因此，结构体count为它分配了一个两位的位域，而把internal_count设定为30位的整型值，从而维持了计数器32位的整体尺寸。

按此处理，内部计数器的取值范围仍然非常大，还保证了在32位或64位计算机上，一个机器字（machine word）便能容纳整个结构体。后文很快会解释，为了杜绝条件竞争，上述两种计数器必须合并，视作单一数据项，共同进行更新。只要把结构体的大小限制在单个机器字内，那么在许多硬件平台上，其原子操作就更加有机会以无锁方式实现。

节点经过初始化，其internal_count成员被置零，而external_counters成员则设置成2(4处)，因为我们向队列加入的每个新节点，它最初既被tail指针指涉，也被前一个节点的next指针指涉。

我们先调用一个新函数increase_external_count()令外部计数器的值增加（5处），再载入tail指针，进而读取尾节点的data成员并对它调用compare_exchange_strong()（6处），然后对原有的tail指针执行free_external_counter()（7处）。

我们画一下这个图

<img src="https://cdn.llfc.club/1704599347162.jpg" alt="image.png" style="zoom:60%;" />


### 多线程pop

多线程pop实现和之前无锁栈类似，我们只要做外部引用计数的增加和内部引用计数的减少即可

```c++
template<typename T>
class lock_free_queue
{
private:
    struct node
    {
        void release_ref();
        //node的余下代码与代码清单7.16相同
    };
public:
    std::unique_ptr<T> pop()
    {
        // 1
        counted_node_ptr old_head=head.load(std::memory_order_relaxed);    
        for(;;)
        {
            //2
            increase_external_count(head,old_head);    
            node* const ptr=old_head.ptr;
            if(ptr==tail.load().ptr)
            {
                //3
                ptr->release_ref();    
                return std::unique_ptr<T>();
            }
            // 4
            if(head.compare_exchange_strong(old_head,ptr->next))    
            {
                T* const res=ptr->data.exchange(nullptr);
                // 5
                free_external_counter(old_head);   
                return std::unique_ptr<T>(res);
            }
            // 6
            ptr->release_ref();    
        }
    }
};
```

节点的弹出操作从加载old_head指针开始（1处），接着进入一个无限循环，并且令已加载好的指针上的外部计数器的值自增（2处）。若头节点正巧就是尾节点，即表明队列内没有数据，我们便释放引用（3处），并返回空指针。

否则表明队列中存在数据，因此当前线程试图调用compare_exchange_strong()将其收归己有（4处）。以上调用会对比结构体head和old_head，其成员都包括外部计数器和指针，但均被视作一个整体。无论哪个成员发生了变化而导致不匹配，代码即释放引用（6处）并重新循环。

如果比较-交换操作成功，当前线程就顺利地将节点所属的数据收归己有，故我们随即释放弹出节点的外部计数器（5处），再将数据返回给pop()的调用者。若两个外部计数器都被释放，且内部计数器值变为0，则节点本身可被删除。有几个函数负责处理引用计数

下面是减少引用计数的函数

```c++
template<typename T>
class lock_free_queue
{
private:
    struct node
    {
        void release_ref()
        {
            node_counter old_counter=
                count.load(std::memory_order_relaxed);
            node_counter new_counter;
            do
            {
                new_counter=old_counter;
                //1
                --new_counter.internal_count;    
            }
            //2
            while(!count.compare_exchange_strong(    
                  old_counter,new_counter,
                  std::memory_order_acquire,std::memory_order_relaxed));
            if(!new_counter.internal_count &&
               !new_counter.external_counters)
            {
                //3
                delete this;    
            }
        }
    };
};
```

尽管我们在这里只改动位域成员internal_count(1处)，也必须按原子化方式更新整个计数器结构体。所以更新操作要用比较-交换函数配合循环实现（2处）。

当计数器internal_count完成自减后，如果内外两个计数器的值均为0，就表明调用release_ref()的是最后一个指涉目标节点的指针（代码清单pop （5 6两处）的ptr），我们应当删除节点（3处）。

接下来我们实现增加引用计数的操作

```c++
template<typename T>
class lock_free_queue
{
private:
    static void increase_external_count(
        std::atomic<counted_node_ptr>& counter,
        counted_node_ptr& old_counter)
    {
        counted_node_ptr new_counter;
        do
        {
            new_counter=old_counter;
            ++new_counter.external_count;
        }
        while(!counter.compare_exchange_strong(
              old_counter,new_counter,
              std::memory_order_acquire,std::memory_order_relaxed));
        old_counter.external_count=new_counter.external_count;
    }
};
```


`increase_external_count()`已改成了静态成员函数，需要更新的目标不再是自身固有的成员计数器，而是一个外部计数器，它通过第一个参数传入函数以进行更新。

针对无锁队列的节点释放其外部计数器

```c++
template<typename T>
class lock_free_queue
{
private:
    static void free_external_counter(counted_node_ptr &old_node_ptr)
    {
        node* const ptr=old_node_ptr.ptr;
        int const count_increase=old_node_ptr.external_count-2;
        node_counter old_counter=
            ptr->count.load(std::memory_order_relaxed);
        node_counter new_counter;
        do
        {
            new_counter=old_counter;
            //⇽---  1
            --new_counter.external_counters;  
            //⇽---  2  
            new_counter.internal_count+=count_increase;    
        }
        //⇽---  3
        while(!ptr->count.compare_exchange_strong(    
              old_counter,new_counter,
              std::memory_order_acquire,std::memory_order_relaxed));
        if(!new_counter.internal_count &&
           !new_counter.external_counters)
        {
            //⇽---  4
            delete ptr;    
        }
    }
};
```


与`free_external_counter()`对应的是`increase_external_count()`函数，该函数对整个计数器结构体仅执行一次`compare_exchange_strong()`，便合并更新了其中的两个计数器(3处)，这与`release_ref()`中更新`internal_count`的自减操作类似。

计数器`external_counters`则同时自减(1处)。如果这两个值均变为0，就表明目标节点再也没有被指涉，遂可以安全删除（4处）。

为了避免条件竞争，上述更新行为需要整合成单一操作完成，因此需要用比较-交换函数配合循环运行。若两项更新分别独立进行，万一有两个线程同时调用该函数，则它们可能都会认为自己是最后的执行者，所以都删除节点，结果产生未定义行为。

### 优化

虽然上述代码尚可工作，也无条件竞争，但依然存在性能问题。一旦某线程开始执行 push()操作，针对 `old_tail.ptr->data`成功完成了`compare_exchange_strong()`调用(push代码6处)，就没有其他线程可以同时运行push()。若有其他任何线程试图同时压入数据，便始终看不到nullptr，而仅能看到上述线程执行push()传入的新值，导致`compare_exchange_strong()`调用失败，最后只能重新循环。这实际上是忙等，消耗CPU周期却一事无成，结果形成了实质的锁。第一个push()调用令其他线程发生阻塞，直到执行完毕才解除，所以这段代码不是无锁实现。问题不止这一个。若别的线程被阻塞，则操作系统会提高对互斥持锁的线程的优先级，好让它尽快完成，但本例却无法依此处理，被阻塞的线程将一直消耗CPU周期，等到最初调用push()的线程执行完毕才停止。这个问题带出了下一条妙计：让等待的线程协助正在执行push()的线程，以实现无锁队列。

我们很清楚应该在这种方法中具体做什么：先设定尾节点上的next指针，使之指向一个新的空节点，且必须随即更新tail指针。由于空节点全都等价，因此这里所用空节点的起源并不重要，其创建者既可以是成功压入数据的线程，也可以是等待压入数据的线程。如果将节点内的next指针原子化，代码就能借`compare_exchange_strong()`设置其值。只要设置好了next指针，便可使用`compare_exchange_weak()`配合循环设定tail指针，借此令它依然指向原来的尾节点。若tail指针有变，则说明它已同时被别的线程更新过，因此我们停止循环，不再重试。

pop()需要稍微改动才可以载入原子化的next指针

```c++
template<typename T>
class lock_free_queue
{
private:
    struct node
    {
        std::atomic<T*> data;
        std::atomic<node_counter> count;
        //⇽---  1
        std::atomic<counted_node_ptr> next;    
    };
public:
    std::unique_ptr<T> pop()
    {
        counted_node_ptr old_head=head.load(std::memory_order_relaxed)；
        for(;;)
        {
            increase_external_count(head,old_head);
            node* const ptr=old_head.ptr;
            if(ptr==tail.load().ptr)
            {
                return std::unique_ptr<T>();
            }
            //  ⇽---  2
            counted_node_ptr next=ptr->next.load();   
            if(head.compare_exchange_strong(old_head,next))
            {
                T* const res=ptr->data.exchange(nullptr);
                free_external_counter(old_head);
                return std::unique_ptr<T>(res);
            }
            ptr->release_ref();
        }
    }
};
```


上面的代码进行了简单改动：next指针现在采用了原子变量（1处），并且（2处）的载入操作也成了原子操作。本例使用了默认的memory_order_seq_cst次序，而ptr->next指针原本属于std::atomic<counted_node_ptr>型别，在（2处）隐式转化成counted_node_ptr型别，这将触发原子化的载入操作，故无须显式调用load()。不过我们还是进行了显式调用，目的是提醒自己，在以后优化时此处应该显式设定内存次序。

新版本的push()相对更复杂，如下

```c++
template<typename T>
class lock_free_queue
{
private:
    // ⇽---  1
    void set_new_tail(counted_node_ptr &old_tail,   
                      counted_node_ptr const &new_tail)
    {
        node* const current_tail_ptr=old_tail.ptr;
        // ⇽---  2
        while(!tail.compare_exchange_weak(old_tail,new_tail) &&   
              old_tail.ptr==current_tail_ptr);
        // ⇽---  3
        if(old_tail.ptr==current_tail_ptr)
            //⇽---  4   
            free_external_counter(old_tail);    
        else
            //⇽---  5
            current_tail_ptr->release_ref();    
    }
public:
    void push(T new_value)
    {
        std::unique_ptr<T> new_data(new T(new_value));
        counted_node_ptr new_next;
        new_next.ptr=new node;
        new_next.external_count=1;
        counted_node_ptr old_tail=tail.load();
        for(;;)
        {
            increase_external_count(tail,old_tail);
            T* old_data=nullptr;
            //⇽---  6
            if(old_tail.ptr->data.compare_exchange_strong(    
                   old_data,new_data.get()))
            {
                counted_node_ptr old_next={0};
                //⇽---  7
                if(!old_tail.ptr->next.compare_exchange_strong(    
                       old_next,new_next))
                {
                    //⇽---  8
                    delete new_next.ptr;    
                    new_next=old_next;   // ⇽---  9
                }
                set_new_tail(old_tail, new_next);
                new_data.release();
                break;
            }
            else    // ⇽---  10
            {
                counted_node_ptr old_next={0};
                // ⇽--- 11
                if(old_tail.ptr->next.compare_exchange_strong(    
                       old_next,new_next))
                {
                    // ⇽--- 12
                    old_next=new_next;    
                    // ⇽---  13
                    new_next.ptr=new node;    
                }
                //  ⇽---  14
                set_new_tail(old_tail, old_next);   
            }
        }
    }
};
```

由于我们确实想在(6处)设置data指针，而且还需接受另一线程的协助，因此引入了else分支以处理该情形(10处)。上述push()的新版本先在(6处)处设置好节点内的data指针，然后通过compare_exchange_strong()更新next指针(7处)，从而避免了循环。

若交换操作失败，我们便知道另一线程同时抢先设定了next指针，遂无须保留函数中最初分配的新节点，可以将它删除（8处）。

虽然next指针是由别的线程设定的，但代码依然持有其值，留待后面更新tail指针（9处）。更新tail指针的代码被提取出来，写成set_new_tail()函数（1处）。它通过compare_exchange_weak()配合循环来更新tail指针（2处）。

如果其他线程试图通过push()压入新节点，计数器external_count就会发生变化，而上述新函数正是为了防止错失这一变化。但我们也要注意，若另一线程成功更新了tail指针，其值便不得再次改变。若当前线程重复更新tail指针，便会导致控制流程在队列内部不断循环，这种做法完全错误。

相应地，如果比较-交换操作失败，所载入的ptr指针也需要保持不变。在脱离循环时，假如ptr指针的原值和新值保持一致（3处）就说明tail指针的值肯定已经设置好，原有的外部计数器则需要释放（4处）。若ptr指针前后有所变化，则另一线程将释放计数器，而当前线程要释放它持有的唯一一个tail指针（5处）。

这里，若多个线程同时调用push()，那么只有一个线程能成功地在循环中设置data指针，失败的线程则转去协助成功的线程完成更新。当前线程一进入push()就分配了一个新节点，我们先更新next指针，使之指向该节点（11处）。假定操作成功，该节点就充当新的尾节点⑫，而我们还需另行分配一个新节点，为下一个压入队列的数据预先做好准备⑬。接着，代码尝试调用set_new_tail()以设置尾节点（14处），再重新循环。

### 官方案例的隐患

我们基于上面的案例执行下面的测试代码，发现程序崩溃

```c++
void TestCrushQue() {
    crush_que<int>  que;
    std::thread t1([&]() {
        for (int i = 0; i < TESTCOUNT*10000; i++) {
            que.push(i);
            std::cout << "push data is " << i << std::endl;
            std::this_thread::sleep_for(std::chrono::milliseconds(10));
        }
        });
    std::thread t2([&]() {
        for (int i = 0; i < TESTCOUNT*10000;) {
            auto p = que.pop();
            if (p == nullptr) {
                std::this_thread::sleep_for(std::chrono::milliseconds(10));
                continue;
            }
            i++;
            std::cout << "pop data is " << *p << std::endl;
        }
        });
    t1.join();
    t2.join();
}
```


我们看到崩溃在底层代码的原子变量交换这里

<img src="https://cdn.llfc.club/71fef3117c6f7dd7bd68e32c448e555.png" alt="image.png" style="zoom:60%;" />

我们按照调用堆栈往上查找，发现是head和tail的ptr为空导致


<img src="https://cdn.llfc.club/1704760877771.jpg" alt="image.png" style="zoom:60%;" />

解决这个问题比较简单，我们在队列的构造函数中添加head和tail的初始化即可。

```c++
memoryleak_que() {
    counted_node_ptr new_next;
    new_next.ptr = new node();
    new_next.external_count = 1;
    tail.store(new_next);
    head.store(new_next);
    std::cout << "new_next.ptr is " << new_next.ptr << std::endl;
}
```

我们也需要在析构函数里回收头尾节点，基本思路是依次出队，但是因为最后一个节点为tail，当head和tail相等时则停止回收，所以我们要额外回收头部节点(此时头部和尾部节点重合)

```c++
~memoryleak_que() {
    while (pop());
    auto head_counted_node = head.load();
    delete head_counted_node.ptr;
}
```

为了测试内存泄漏，我们在栈中添加一个静态成员变量

```c++
class memoryleak_que{
public:
static std::atomic<int> destruct_count;
};
template<typename T>
std::atomic<int> lock_free_queue<T>::destruct_count = 0;
```

我们在`release_ref`和`free_external_counter`中删除指针时增加这个静态成员变量的数量，最后统计删除的数量和我们开辟的数量是否相等

```c++
void release_ref()
{
    std::cout << "call release ref " << std::endl;
    node_counter old_counter =
    count.load(std::memory_order_relaxed);
    node_counter new_counter;
    do
    {
        new_counter = old_counter;
        //1
        --new_counter.internal_count;
    }
        //2
    while (!count.compare_exchange_strong(
                old_counter, new_counter,
                std::memory_order_acquire, std::memory_order_relaxed));
        if (!new_counter.internal_count &&
                !new_counter.external_counters)
    {
        //3
        delete this;
        std::cout << "release_ref delete success" << std::endl;
        destruct_count.fetch_add(1);
    }
}
```


```c++
static void free_external_counter(counted_node_ptr& old_node_ptr)
{
    std::cout << "call  free_external_counter " << std::endl;
    node* const ptr = old_node_ptr.ptr;
    int const count_increase = old_node_ptr.external_count - 2;
    node_counter old_counter =
        ptr->count.load(std::memory_order_relaxed);
    node_counter new_counter;
    do
    {
        new_counter = old_counter;
        //⇽---  1
        --new_counter.external_counters;
        //⇽---  2  
        new_counter.internal_count += count_increase;
    }
    //⇽---  3
    while (!ptr->count.compare_exchange_strong(
            old_counter, new_counter,
            std::memory_order_acquire, std::memory_order_relaxed));
    if (!new_counter.internal_count &&
            !new_counter.external_counters)
    {
        //⇽---  4
        destruct_count.fetch_add(1);
        std::cout << "free_external_counter delete success" << std::endl;
        delete ptr;
    }
}
```

测试并发执行两个线程，最后assert断言删除节点数和开辟的节点数相等

```c++
void TestLeakQue() {
    memoryleak_que<int>  que;
    std::thread t1([&]() {
        for (int i = 0; i < TESTCOUNT ; i++) {
            que.push(i);
            std::cout << "push data is " << i << std::endl;
            std::this_thread::sleep_for(std::chrono::milliseconds(10));
        }
        });
    std::thread t2([&]() {
        for (int i = 0; i < TESTCOUNT ;) {
            auto p = que.pop();
            if (p == nullptr) {
                std::this_thread::sleep_for(std::chrono::milliseconds(10));
                continue;
            }
            i++;
            std::cout << "pop data is " << *p << std::endl;
        }
        });
    t1.join();
    t2.join();
    assert(que.destruct_count == TESTCOUNT );
}
```

测试触发断言，说明存在内存泄漏。

经过调试我们发现其实是在pop头部节点时判断head和tail相等，直接返回空指针，但是引用计数没有做减少。这和栈的方式不同，栈的pop判断条件如果head节点的ptr指向空地址，说明这个节点为无效节点无需pop直接返回空指针，当有新数据插入时在头部插入新节点并更新head为新节点。这么做保证了即使最后那个无效节点引用计数怎么增加都无所谓。

但是队列不行，队列的操作方式是先开辟了head和tail节点，这两个节点最开始是无效的，但是当插入数据时，就将head的ptr指向的数据data更新为新的数据即可。这样head之前和tail相等时pop增加的引用计数如果不合理减少就会造成问题。

解决的思路也比较简单，如果head和tail相等说明为空队列，空队列减少该节点内部引用计数即可。

```c++
 std::unique_ptr<T> pop()
{
    counted_node_ptr old_head = head.load(std::memory_order_relaxed);
    for (;;)
    {
        increase_external_count(head, old_head);
        node* const ptr = old_head.ptr;
        if (ptr == tail.load().ptr)
        {
            //头尾相等说明队列为空，要减少内部引用计数
            ptr->release_ref();
            return std::unique_ptr<T>();
        }
        //  ⇽---  2
        counted_node_ptr next = ptr->next.load();
        if (head.compare_exchange_strong(old_head, next))
        {
            T* const res = ptr->data.exchange(nullptr);
            free_external_counter(old_head);
            return std::unique_ptr<T>(res);
        }
        ptr->release_ref();
    }
}
```

最后我们测试多线程pop和push的情况，目前稳定回收节点并且并发安全

```c++
void TestLockFreeQueMultiPushPop() {
    lock_free_queue<int>  que;
    std::thread t1([&]() {
        for (int i = 0; i < TESTCOUNT * 100; i++) {
            que.push(i);
            std::cout << "push data is " << i << std::endl;
            std::this_thread::sleep_for(std::chrono::milliseconds(10));
        }
        });
    std::thread t4([&]() {
        for (int i = TESTCOUNT*100; i < TESTCOUNT * 200; i++) {
            que.push(i);
            std::cout << "push data is " << i << std::endl;
            std::this_thread::sleep_for(std::chrono::milliseconds(10));
        }
        });
    std::thread t2([&]() {
        for (int i = 0; i < TESTCOUNT * 100;) {
            auto p = que.pop();
            if (p == nullptr) {
                std::this_thread::sleep_for(std::chrono::milliseconds(10));
                continue;
            }
            i++;
            std::cout << "pop data is " << *p << std::endl;
        }
        });
    std::thread t3([&]() {
        for (int i = 0; i < TESTCOUNT * 100;) {
            auto p = que.pop();
            if (p == nullptr) {
                std::this_thread::sleep_for(std::chrono::milliseconds(10));
                continue;
            }
            i++;
            std::cout << "pop data is " << *p << std::endl;
        }
        });
    t1.join();
    t2.join();
    t3.join();
    t4.join();
    assert(que.destruct_count == TESTCOUNT * 200);
}
```


## 无锁设计4条原则

前面的文章介绍了无锁并发的相关知识，涵盖了无锁队列，无锁栈，环状无锁队列的设计，本文总结下无锁并发设计的几个设计规则，以供读者自己编写无锁代码时可以起到抛砖引玉的效果。

### 模型设计

原则1：

在原型设计中使用`std::memory_order_seq_cst`次序若代码服从`std::memory_order_seq_cst`次序，则对其进行分析和推理要比其他内存次序容易得多，因为它令全部操作形成一个确定的总序列。

回顾之前我们实现的无锁栈和无锁队列，它们的原始版本全都采用`std::memory_order_seq_cst`次序，当基本操作均正常工作后，我们才放宽内存次序约束。

在这种意义上，采用其他内存次序其实是一项优化，需要避免过早实施。我们通常只有先完全了解代码全貌，认清哪些代码操作核心数据结构，才可以确定放宽哪些操作的内存次序约束。否则，事情就会很棘手。即便代码在测试过程中正常工作，也无法保证在生产环境下代码依然如此，这令内存次序的放宽调整变得复杂。所以，仅仅测试代码的运行并不足够，除非我们能够采用测试工具（假如真的存在），系统化地核查线程访问内存次序的全部可能的组合，验证它们是否与指定的内存次序约束保持一致。

### 内存回收方案

原则2：

使用无锁的内存回收方案无锁代码中的一大难题是内存管理。最基本的要求是，只要目标对象仍然有可能正被其他线程指涉，就不得删除。然而，为了避免过度消耗内存，我们还是想及时删除无用的对象。

我们在这一章学习了3种方法，以确保内存回收满足安全要求：

1. 暂缓全部删除对象的动作，等到没有线程访问数据结构的时候，才删除待销毁的对象；
2. 采用风险指针，以辨识特定对象是否正在被某线程访问；
3. 就对象进行引用计数，只要外部环境仍正在指涉目标对象，它就不会被删除。

3种方法的关键思想都是以某种方式掌握正在访问目标对象的线程数目，仅当该对象完全不被指涉的时候，才会被删除。针对无锁数据结构，还有很多别的方法可以回收内存。

譬如，无锁数据是使用垃圾回收器的理想场景。若我们得以采用垃圾回收器，即事先知晓它具备适时删除无用节点的能力，则算法的实现代码写起来就会轻松一些。

另一种处理方法是重复使用节点，等到数据结构销毁时才完全释放它们。我们之前实现的环状无锁队列就是重复使用固定个数的队列，头尾成环。由于重用了节点，因此所分配的内存便一直有效，代码从而避开了一些涉及未定义行为的麻烦细节。然而，这种方法有一个缺点，它导致程序频频出现被称为“ABA问题”的情形。


### 防范ABA问题

原则3：防范ABA问题在所有涉及比较-交换的算法中，我们都要注意防范ABA问题。

该问题产生过程如下：

步骤1：线程甲读取原子变量x，得知其值为A。
步骤2：线程甲根据A执行某项操作，比如查找，或如果x是指针，则依据它提取出相关值（称为ov）。
步骤3：线程甲因操作系统调度而发生阻塞。
步骤4：另一线程对原子变量x执行别的操作，将其值改成B。
步骤5：又有线程改变了与A相关的数据，使得线程甲原本持有的值失效（步骤2中的ov）。这种情形也许是A表示某内存地址，而改动操作则是释放指针的目标内存，或变更目标数据，最后将产生严重后果。 
步骤6：原子变量x再次被某线程改动，重新变回A。

若x属于指针型别，其指向目标可能在步骤5被改换成一个新对象。

步骤7：线程甲继续运行，在原子变量x上执行比较-交换操作，与A进行对比。因此比较-交换操作成功执行（因x的值依然为A），但A的关联数据却不再有效，即原本在步骤2中取得的ov已失效，而线程甲却无从分辨，这将破坏数据结构。

画出示意图

<img src="https://cdn.llfc.club/1704879342682.jpg" alt="image.png" style="zoom:60%;" />

之前我们实现的无锁结构均不存在ABA问题，但它很容易由无锁算法的代码引发。该问题最常见的解决方法之一是，在原子变量x中引入一个ABA计数器。将变量x和计数器组成单一结构，作为一个整体执行比较-交换操作。每当它的值被改换，计数器就自增。照此处理，如果别的线程改动了变量x，即便其值看起来与最初一样，比较-交换操作仍会失败。

如果某数据结构的操作算法涉及空闲内存列表，或者涉及循环使用节点(比如我们之前实现的循环队列)，而不是通过内存分配器回收管理，那么ABA问题就格外常见。

举一个例子 原有的栈结构为 A —> B —> C

假设一个线程1执行pop将A头部节点的数据加载出来，还未做读改写更新head为B，此时时间片被其他线程2抢占执行pop将A,B分别出栈，然后线程3抢占时间片又将A入栈，那么我们看到此时栈的情况为 A —> C , 如果时间片切换回线程1，此时线程1执行读改写操作发现head还是为A，他会误认为这期间没有其他线程改变栈，所以线程1的读改写将head更新为B。其实B已经被弹出了，那么这就是ABA问题。

上面的仅仅是一个ABA案例的描述，那我们实现的无锁栈或者无锁队列为什么不存在这个ABA问题呢？原因是我们每次push加入的node节点都不同。node的结构包含数据域和下一个节点的指针

```c++
struct node
{
    std::shared_ptr<T> data;
    node* next;
    node(T const& data_) : //⇽-- - 1
        data(std::make_shared<T>(data_))
    {}
};
```

我们每次调用push虽然传递的data可以理解为A，但是构造的智能指针地址不同，也就是node中存储的data不同。所以即使线程1做读改写比较的时候发现数值都为A，但是地址不同，也可区分出栈被改变。

```c++
void push(T const& data)
{
    node* const new_node = new node(data);    //⇽-- - 2
    new_node->next = head.load();    //⇽-- - 3
    while (!head.compare_exchange_weak(new_node->next, new_node));    //⇽-- - 4
}
std::shared_ptr<T> pop() {
    node* old_head = nullptr; //1        
    do {
        old_head = head.load(); //2
        if (old_head == nullptr) {
            return nullptr; 
        }
    } while (!head.compare_exchange_weak(old_head, old_head->next)); //3        
    return old_head->data;  //4    
}
```

### 解决忙等

原则4：找出忙等循环，协助其他线程。

如我们在无锁队列第一版的push代码中，若两个线程同时执行压入操作，其中一个就须等待另一个结束，才可以继续运行。这实质上是一个忙等循环，如果放任不管，受到阻塞的线程就唯有浪费CPU时间却无计可施。阻塞型操作与使用互斥和锁一样，三者均有可能以忙等循环的方式实现。

假设按照调度安排，某线程先开始执行，却因另一线程的操作而暂停等待，那么只要我们修改操作的算法，就能让前者先完成全部步骤，从而避免忙等，操作也不会被阻塞。

之后我们让比较失败的线程辅助完成节点的创建和tail的更新。这要求将非原子变量的数据成员改为原子变量，并采用比较-交换操作设置其值。不过，更复杂的数据结构需要进行更多修改。

## 线程间切分任务的方法


### 按数量切分

对于大量处理的数据，可以按照任务数量区分，简单来说如果我们要处理n个任务，总计有m个线程，那么我们可以简单的规划每个线程处理n/m个任务。

如下图

<img src="https://cdn.llfc.club/1705459243909.jpg" alt="image.png" style="zoom:70%;" />


这种方式用来划分大量相同任务时可以采用，但是有些逻辑并不是完全可以靠数量划分的，比如递归逻辑。

### 递归划分

前文我们提及了快速排序的并行实现，包括利用async和线程池的方式。=
快速排序算法含有两大基本步骤：
选定一个元素为比较的基准元素；
将数据集按大小划分为前后两部分，重新构成新序列，再针对这两个部分递归排序。
数据划分无法从一开始就并行化，因为数据只有经过处理后，我们才清楚它会归入哪个部分。
若我们要并行化这个算法，就需要利用递归操作的固有性质。
每层递归均会涉及更多的`quick_sort()`函数调用，因为我们需对基准元素前后两部分都进行排序。
由于这些递归调用所访问的数据集互不相关，因此它们完全独立，正好吻合并发程序的首选执行方式。
下图展示了以递归方式划分数据。

<img src="https://cdn.llfc.club/1705461120545.jpg" alt="image.png" style="zoom:70%;" />

在早期我们实现并行递归的快速排序，那段代码每深入一层递归，都借`std::async()`生成新的异步任务处理前半部分数据，而后部分则继续用本线程计算后半部分数据。
我们通过`std::async()`让C++线程库自主决定，是另起新线程执行新任务，还是在原线程上同步运行。
这点相当重要：假设排序操作的数据集非常庞大，若每次递归都生成新线程，则势必令线程数目激增。
我们将通过后文的性能分析了解到，太多线程反而可能令应用程序变慢。
如果数据集着实庞大，还有可能消耗殆尽全部线程。按上述递归方式来切分数据是不错的思路，但需约束线程数目的增长，不可任其数目无限膨胀。
此例比较简单，`std::async()`足以应付，但它不是唯一选择。
后来我们觉得开辟过多的线程并不合适，采用了线程池。
并发编程的作者提出的另一种做法是，根据`std::hardware_concurrency()`函数的返回值设定线程的数目，实现了`accumulate()`的并行版本。
接着，我们采用之前实现的线程安全的栈容器，将尚未排序的数据段压入其中，而不是启动新线程以执行递归调用。
若某线程无所事事，或因全部数据段均已处理妥当，或因它正等着另一数据段完成排序，若是后者，该线程即从栈容器取出所等的数据段自行排序。


```c++
#include <thread>
#include <list>
#include "thread_safe_stack.h"
#include <future>
#include <memory>
template<typename T>
struct sorter  //1  
{
    struct chunk_to_sort
    {
        std::list<T> data;
        std::promise<std::list<T> > promise;
    };
    thread_safe_stack<chunk_to_sort> chunks;    //⇽-- - 2
    std::vector<std::thread> threads;   // ⇽-- - 3
    unsigned const max_thread_count;
    std::atomic<bool> end_of_data;
    sorter() :
        max_thread_count(std::thread::hardware_concurrency() - 1),
        end_of_data(false)
    {}
    ~sorter()    //⇽-- - 4
    {
        end_of_data = true;     //⇽-- - 5
        for (unsigned i = 0; i < threads.size(); ++i)
        {
            threads[i].join();    //⇽-- - 6
        }
    }
    void try_sort_chunk()
    {
        std::shared_ptr<chunk_to_sort> chunk = chunks.try_pop();    //⇽-- - 7
        if (chunk)
        {
            sort_chunk(chunk);    //⇽-- - 8
        }
    }
    std::list<T> do_sort(std::list<T>& chunk_data)    //⇽-- - 9
    {
        if (chunk_data.empty())
        {
            return chunk_data;
        }
        std::list<T> result;
        result.splice(result.begin(),chunk_data,chunk_data.begin());
        T const& partition_val = *result.begin();
        typename std::list<T>::iterator divide_point =  //⇽-- - 10
            std::partition(chunk_data.begin(),chunk_data.end(),
                           [&](T const& val) {return val < partition_val; });
        chunk_to_sort new_lower_chunk;
        new_lower_chunk.data.splice(new_lower_chunk.data.end(),
                                    chunk_data,chunk_data.begin(),
                                    divide_point);
        std::future<std::list<T> > new_lower =
            new_lower_chunk.promise.get_future();
        chunks.push(std::move(new_lower_chunk));   // ⇽-- - 11
        if (threads.size() < max_thread_count)    // ⇽-- - 12
        {
            threads.push_back(std::thread(&sorter<T>::sort_thread,this));
        }
        std::list<T> new_higher(do_sort(chunk_data));
        result.splice(result.end(),new_higher);
        while (new_lower.wait_for(std::chrono::seconds(0)) !=
              std::future_status::ready)    //⇽-- - 13
        {
            try_sort_chunk();   // ⇽-- - 14
        }
        result.splice(result.begin(),new_lower.get());
        return result;
    }
    void sort_chunk(std::shared_ptr<chunk_to_sort > const& chunk)
    {
        chunk->promise.set_value(do_sort(chunk->data));    //⇽-- - 15
    }
    void sort_thread()
    {
        while (!end_of_data)    //⇽-- - 16
        {
            try_sort_chunk();    // ⇽-- - 17
            //交出时间片
            std::this_thread::yield();    //⇽-- - 18
        }
    }
};
```

我们实现一个函数调用上面的封装快速排序

```c++
template<typename T>
std::list<T> parallel_quick_sort(std::list<T> input)    //⇽-- - 19
{
    if (input.empty())
    {
        return input;
    }
    sorter<T> s;
    return s.do_sort(input);    //⇽-- - 20
}
```

本例中，`parallel_quick_sort()`函数(19处)把绝大部分功能委托给sorter类(1处)，后者通过栈容器管理待排序的数据段(2处)，并集中管控多个线程以并发执行任务(3处)，从而以便捷的操作方式给出了代码实现。

本例中，主要工作由成员函数`do_sort()`负责(9处)，它借标准库的`std::partition()`函数完成数据分段(10处)。

`do_sort()`将新划分出来的数据段压入栈容器(11处)，但没有为每个数据段都专门生成新线程，而仅当仍存在空闲的处理器时(12处)才生成新线程。

因为划分出的前半部分数据可能会由别的线程处理，所以我们需要等待它完成排序而进入就绪状态(13处)。

如果当前线程是整个程序中仅有的线程，或者其他线程都正忙于别的任务，那么这一等待行为则需妥善处理，在当前线程的等待期间，我们让它试着从栈容器取出数据进行处理(14处)。

`try_sort_chunk()`先从栈容器弹出一段数据(7处)并对其进行排序(8处)，再把结果存入附属该段的promise中(15处)，使之准备就绪，以待提取。

向栈容器压入数据段与取出相关结果相互对应，两项操作均由同一个线程先后执行(11和12处)。

只要标志`end_of_data`没有成立（16处），各线程便反复循环，尝试对栈内数据段进行排序17。

每个线程在两次检测标志之间进行让步（18处），好让别的线程有机会向栈容器添加数据段。这段代码由sorter类的析构函数汇合各个线程（4处）。

`do_sort()`将在全部数据段都完成排序后返回（即便许多工作线程仍在运行），主线程进而从`parallel_quick_sort()`的调用返回20，并销毁sorter对象。其析构函数将设置标志end_of_data成立（5处），然后等待全部线程结束（6处）。标志的成立使得线程函数内的循环终止（16处）。

### 按照工作类别划分任务

单线程应用程序照样需要同时运行多个任务，而某些程序即便正忙于手头的任务，也需随时处理外部输入的事件（譬如用户按键或网络数据包传入）。这些情形都与单一功能的设计原则矛盾，必须妥善处理。若我们按照单线程思维手动编写代码，那最后很可能混成“大杂烩”：先执行一下任务甲，再执行一下任务乙，接着检测按键事件，然后检查传入的网络数据包，又回头继续执行任务甲，如此反复循环。这就要求任务甲保存状态，好让控制流程按周期返回主循环，结果令相关的代码复杂化。如果向循环加入太多任务，处理速度便可能严重放缓，让用户感觉按键的响应时间过长。相信读者肯定见过这种操作方式的极端表现：我们让某个应用程序处理一些任务，其用户界面却陷入僵滞，到任务完成后才恢复。

只要把每个任务都放在独立的线程上运行，操作系统便会替我们“包办”切换动作。因此，任务甲的代码可专注于执行任务，我们无须再考虑保存状态和返回主循环，也不必纠结间隔多久就得这样操作。

假定每项任务都相互独立，且各线程无须彼此通信，那么该构想即可轻而易举地实现。可惜往往事与愿违。即便经过良好的设计，后台任务也常常按用户要求执行操作，它们需在完成时通过某种方式更新界面，好让用户知晓。反之，若用户想取消任务，就要通过界面线程向后台任务发送消息，告知它停止。

所以各个任务线程中要提供互相通知的接口，这种思想和Actor模式不谋而合。

当然我们划分任务给不同的线程也要注意精细程度，比如两个线程要做的功能中某个环节是一个共有的功能，那么我们需要将这个功能整合到一个单线程上。我们可以理解在一些高并发的设计中，即便某些模块是高并发，但是耦合度很高的逻辑处理还是采用单线程方式，我们之前设计网络i服务器是逻辑处理也是单线程，但是我们可以根据功能做区分再分化为不同的线程，这就类似于Actor设计模式了。

假设有这样一个情形，我们实现一个系统控制机器中各部件的运动，A部件运动结束后通知B部件运动，B部件结束后通知C部件继续运动等，C运动结束后再通知A部件继续运动。

按照任务划分的模式，A，B，C分别运行在不同的线程中处理不同的任务，而任务又要以流水线A->B->C的方式运作。
我们可以这样抽象出一个Actor类，它包含消息的投递，消息的处理，以及消息队列的管理，并且它是一个单例类，全局唯一。
先实现这个基本的模板单例类, 这期间会用到CRTP技术，CRTP：一个继承 以自己为模板参数的模板类 的类。
CRTP 奇特递归模板技术， Curiously recurring template pattern。
模板单例类实现如下

```c++
#include <thread>
#include "ThreadSafeQue.h"
#include <atomic>
#include <iostream>
template<typename ClassType, typename QueType>
class ActorSingle {
public:
    static ClassType& Inst() {
        static ClassType as;
        return as;
    }
    ~ ActorSingle(){
    }
    void PostMsg(const QueType& data) {
        _que.push(data);
    }
protected:
    ActorSingle():_bstop(false){
    }
    ActorSingle(const ActorSingle&) = delete;
    ActorSingle(ActorSingle&&) = delete;
    ActorSingle& operator = (const ActorSingle&) = delete;
    std::atomic<bool> _bstop;
    ThreadSafeQue<QueType>  _que;
    std::thread _thread;
};
```

模板单例类包含了原子变量_bstop控制线程是否停止
包含了_que用来存储要处理的信息，这是一个线程安全的队列。
`_thread`是要处理任务的线程。
线程安全队列我们之前有实现过，但是还需要稍微改进下以满足接受外部停止的通知。
我们给ThreadSafeQue添加一个原子变量_bstop表示线程停止的标记
在需要停止等待的时候我们调用如下通知函数

```c++
void NotifyStop() {
    _bstop.store(true);
    data_cond.notify_one();
}
```

等待消息的函数需要补充根据停止条件去返回的逻辑,目的为防止线程被一直挂起

```c++
std::unique_lock<std::mutex> wait_for_data()   
{
    std::unique_lock<std::mutex> head_lock(head_mutex);
    data_cond.wait(head_lock,[&] {return (_bstop.load() == true) || (head.get() != get_tail()); });
    return std::move(head_lock);   
}
```

修改wait_pop_head，根据停止条件返回空指针

```c++
std::unique_ptr<node> wait_pop_head()
{
    std::unique_lock<std::mutex> head_lock(wait_for_data()); 
    if (_bstop.load()) {
        return nullptr;
    }
    return pop_head();
}
```

等待返回数据的逻辑也稍作修改，因为有可能是接收到停止信号后等待返回，所以此时返回空指针即可

```c++
std::shared_ptr<T> WaitAndPop() //  <------3
{
    std::unique_ptr<node> const old_head = wait_pop_head();
    if (old_head == nullptr) {
        return nullptr;
    }
    return old_head->data;
}
```

比如我们要实现一个ClassA 处理A类任务，可以这么做

```c++
#include "ActorSingle.h"
#include "ClassB.h"
struct MsgClassA {
    std::string name;
    friend std::ostream& operator << (std::ostream& os, const MsgClassA& ca) {
        os << ca.name;
        return os;
    }
};
class ClassA : public ActorSingle<ClassA, MsgClassA> {
    friend class ActorSingle<ClassA, MsgClassA>;
public:
    ~ClassA() {
        _bstop = true;
        _que.NotifyStop();
        _thread.join();
        std::cout << "ClassA destruct " << std::endl;
    }
    void DealMsg(std::shared_ptr<MsgClassA> data) {
        std::cout << "class A deal msg is " << *data << std::endl;
        MsgClassB msga;
        msga.name = "llfc";
        ClassB::Inst().PostMsg(msga);
    }
private:
    ClassA(){
        _thread = std::thread([this]() {
            for (; (_bstop.load() == false);) {
                std::shared_ptr<MsgClassA> data = _que.WaitAndPop();
                if (data == nullptr) {
                    continue;
                }
                DealMsg(data);
            }
            std::cout << "ClassA thread exit " << std::endl;
            });
    }
};
```

我们利用CRTP模式让ClassA继承了以ClassA为类型的模板，然后在DealMsg函数内部调用了 ClassB的投递消息，将任务B交给另一个线程处理。
关于ClassB的实现方式和ClassA类似，然后我们在ClassB的DealMsg中调用ClassC的PostMsg将消息投递给C的线程处理。
达到的效果就是
A->B->C
我们在主函数调用
```c++
#include <iostream>
#include "ClassA.h"
int main()
{
    MsgClassA msga;
    msga.name = "llfc";
    ClassA::Inst().PostMsg(msga);
    std::this_thread::sleep_for(std::chrono::seconds(2));
    std::cout << "main process exited!\n";
}
```

程序输出如下

```
class A deal msg is llfc
class B deal msg is llfc
class C deal msg is llfc
main process exited!
ClassC thread exit
ClassC destruct
ClassB thread exit
ClassB destruct
ClassA thread exit
ClassA destruct
```

可以看到处理的顺序是A->B->C，并且每个类都有析构和函数回收，说明我们的程序不存在内存泄漏。

这里要提示读者一个问题，如果A给B投递消息，而B又要给A投递消息，那么如果在A的头文件包含B的头文件，而B的头文件包含A的头文件势必会造成互引用问题，那么最好的解决方式就是在A和B的头文件中分别声明对方，在cpp文件中再包含即可。

上面的例子通过模板和继承的方式实现了类似Actor的收发消息的功能。

## 并行计算

前文介绍了几种数据划分的方式，包括按照线程数量划分，按照递归方式划分，以及按照任务类型划分等。

本文结合之前的划分方式，基于stl的find, for_each以及partial_sum等算法实现并行版本。

### 并行版本for_each

实现并行的`for_each`，最简单的方式就是将数据划分，每个线程分别处理一段连续的数据即可。
在介绍并行版本之前，我们先实现一个管理线程 的类join_threads，用来管控线程防止线程过早退出

```c++
class join_threads
{
    std::vector<std::thread>& threads;
public:
    explicit join_threads(std::vector<std::thread>& threads_) :
        threads(threads_)
    {}
    ~join_threads()
    {
        for (unsigned long i = 0; i < threads.size(); ++i)
        {
            if (threads[i].joinable())
                threads[i].join();
        }
    }
};
```

接下来我们实现第一种方式

```c++
template<typename Iterator, typename Func>
void parallel_for_each(Iterator first, Iterator last, Func f)
{
    unsigned long const length = std::distance(first, last);
    if (!length)
        return;
    unsigned long const min_per_thread = 25;
    unsigned long const max_threads =
        (length + min_per_thread - 1) / min_per_thread;
    unsigned long const hardware_threads =
        std::thread::hardware_concurrency();
    unsigned long const num_threads =
        std::min(hardware_threads != 0 ? hardware_threads : 2, max_threads);
    unsigned long const block_size = length / num_threads;
    std::vector<std::future<void>> futures(num_threads - 1);   //⇽-- - 1
        std::vector<std::thread> threads(num_threads - 1);
    join_threads joiner(threads);
    Iterator block_start = first;
    for (unsigned long i = 0; i < (num_threads - 1); ++i)
    {
        Iterator block_end = block_start;
        std::advance(block_end, block_size);
        std::packaged_task<void(void)> task( // ⇽-- - 2
            [=]()
        {
            std::for_each(block_start, block_end, f);
        });
        futures[i] = task.get_future();
        threads[i] = std::thread(std::move(task));    //⇽-- - 3
            block_start = block_end;
    }
    std::for_each(block_start, last, f);
    for (unsigned long i = 0; i < (num_threads - 1); ++i)
    {
        futures[i].get();   // ⇽-- - 4
    }
}
```

1. 我们规定如果处理的数量不超过25个则用单线程。否则根据处理的数量划分任务，计算开辟的线程数，如果要开辟的线程数大于内核线程的数量，则以内核线程数为准。
2. 根据实际开辟的线程数num_threads计算每个线程处理的块大小。并且初始化两个vector，分别用来存储处理结果的future和处理任务的线程。
3. 我们在(2处)代码生成了一个任务task，然后获取future赋值给vector对应下标为i的future元素，并且把任务绑定给对应下标为i的thread。
4. numthreads-1个线程并行处理for_each，剩下的主线程处理余下的for_each，最后通过futures.get汇总

第二种划分方式是我们采取递归的方式，我们知道采用递归的方式无法提前开辟准确数量的线程，我们采用async帮我们完成这个任务

```c++
template<typename Iterator, typename Func>
void async_for_each(Iterator first, Iterator last, Func f)
{
    unsigned long const length = std::distance(first, last);
    if (!length)
        return;
    unsigned long const min_per_thread = 25;
    if (length < (2 * min_per_thread))
    {
        std::for_each(first, last, f);    //⇽-- - 1
    }
    else
    {
        Iterator const mid_point = first + length / 2;
        //⇽-- - 2
        std::future<void> first_half =   std::async(&async_for_each<Iterator, Func>,
                first, mid_point, f);
        //⇽-- - 3
        async_for_each(mid_point, last, f); 
        // ⇽-- - 4
        first_half.get();   
    }
}
```

async可以帮助我们判断是否需要开启线程还是自动串行执行。每次我们将要处理的数据一分为2，前半部分交给一个async开辟线程处理，后半部分在本线程处理。而所谓的本线程不一定是主线程，因为我们通过async递归执行`parallel_for_each`，也就相当于在一个线程里独立执行了。

### find的并行实现

find 的并行查找方式还是分两种，一种是将要查找的区间划分为几个段，每段交给一个线程查找。
另一种是采用递归的方式每次折半，前半部分交给一个线程查找，后半部分留在本线程查找。
我们先说第一种
find比较特殊，我们要防止线程忙等待，也要防止线程在其他线程已经查找到值后做无谓的浪费。可以用一个共享的全局atomic变量表示是否找到目标。
因为主线程要获取某个线程查找到的迭代器位置，所以我们用promise 设置 value为迭代器

```C++
template<typename Iterator, typename MatchType>
Iterator parallel_find(Iterator first, Iterator last, MatchType match)
{
    struct find_element    //⇽-- - 1
    {
        void operator()(Iterator begin,Iterator end,
                        MatchType match,
                        std::promise<Iterator>*result,
                        std::atomic<bool>*done_flag)
        {
            try
            {
                for (; (begin != end) && !done_flag->load(); ++begin)    //⇽-- - 2
                {
                    if (*begin == match)
                    {
                        result->set_value(begin);    //⇽-- - 3
                        done_flag->store(true);    //⇽-- - 4
                        return;
                    }
                }
            }
            catch (...)    //⇽-- - 5
            {
                try
                {
                    result->set_exception(std::current_exception());    //⇽-- - 6
                    done_flag->store(true);
                }
                catch (...)    //⇽-- - 7
                {}
            }
        }
    };
    unsigned long const length = std::distance(first, last);
    if (!length)
        return last;
    unsigned long const min_per_thread = 25;
    unsigned long const max_threads = (length + min_per_thread - 1) / min_per_thread;
    unsigned long const hardware_threads = std::thread::hardware_concurrency();
    unsigned long const num_threads = std::min(hardware_threads != 0 ? hardware_threads : 2, max_threads);
    unsigned long const block_size = length / num_threads;
    std::promise<Iterator> result;    //⇽-- - 8
    std::atomic<bool> done_flag(false);     //⇽-- - 9
    std::vector<std::thread> threads(num_threads - 1); //⇽-- - 10
    {    
        join_threads joiner(threads);
        Iterator block_start = first;
        for (unsigned long i = 0; i < (num_threads - 1); ++i)
        {
            Iterator block_end = block_start;
            std::advance(block_end, block_size);
            // ⇽-- - 11
            threads[i] = std::thread(find_element(),  block_start, block_end, match, &result, &done_flag);
            block_start = block_end;
        }
        // ⇽-- - 12
        find_element()(block_start, last, match, &result, &done_flag);   
    }
    // ⇽-- - 13
    if (!done_flag.load())   
    {
        return last;
    }
    //⇽-- - 14
    return result.get_future().get();    
}
```

1. `find_element`重载了()运算符，接受四个参数，分别是迭代器的开始，迭代起的结束，要查找的数值，以及用来通知外部的promise，还有线程之间用来检测是否有某个线程完成查找的原子变量。
2. `find_element`重载()的逻辑就是查找这个区间内满足某个值的位置，并将这个位置的迭代起设置到promise中，然后将完成的原子变量标记为true。

说第二种方式，利用递归折半查找，我们可以用async帮助我们完成并行任务。

```c++
template<typename Iterator, typename MatchType>
Iterator parallel_find_impl(Iterator first, Iterator last, MatchType match,
    std::atomic<bool>& done)   // ⇽-- - 1
{
    try
    {
        unsigned long const length = std::distance(first,last);
        unsigned long const min_per_thread = 25;   // ⇽-- - 2
        if (length < (2 * min_per_thread))    //⇽-- - 3
        {
            for (; (first != last) && !done.load(); ++first)     //⇽-- - 4
            {
                if (*first == match)
                {
                    done = true;    //⇽-- - 5
                    return first;
                }
            }
            return last;    //⇽-- - 6
        }
        else
        {
            //⇽-- - 7
            Iterator const mid_point = first + (length / 2);   
            //⇽-- - 8
            std::future<Iterator> async_result = std::async(&parallel_find_impl<Iterator,MatchType>,    
                           mid_point,last,match,std::ref(done));
            //⇽-- - 9
            Iterator const direct_result = parallel_find_impl(first,mid_point,match,done); 
            //⇽-- - 10
            return (direct_result == mid_point) ?async_result.get() : direct_result;    
        }
    }
    catch (...)
    {
        // ⇽-- - 11
        done = true;   
        throw;
    }
}
template<typename Iterator, typename MatchType>
Iterator parallel_find_async(Iterator first, Iterator last, MatchType match)
{
    std::atomic<bool> done(false);
    //⇽-- - 12
    return parallel_find_impl(first, last, match, done);    
}
```

1. 并行查找的方式种我们先根据长度是否小于50决定是否开启并行任务，如果小于50则采取单线程方式。
2. 如果采用并行的方式，我们将长度折半，前半部分交给async，后半部分交给本线程。
3. 最后我们在主线程中汇合，获取结果。

#### partial_sum并行版本

C++ 提供了累计计算求和的功能，比如一个vector中存储的数据为{1,2,3},那么经过计算，第一个元素仍然为1，第二个元素为1+2， 第三个元素为1+2+3，结果为{1,3,6}.

关于并行版本我们可以这么思考，假设元数组为{1,2,3,4,5,6,7},那我们可以划分为三个部分，第一部分为{1,2,3}交给第一个线程处理, 第二部分{4,5,6}交给第二个线程处理，7交给本线程处理。

但是我们要考虑的一个问题是线程2要用到线程1最后计算的结果，线程1计算后{1,3,6}，线程2需要用到6做累加，我们可以先让线程1计算出第3个元素值6，再将这个6传递给线程2，剩下的就可以并行计算了。同样的道理本线程要处理最后一个元素的累加结果，他需要等到线程2处理完第6个元素的值。

所以基本思路是每个线程优先处理分区的最后一个元素，通过promise设置给其他线程，在这个阶段线程之间是串行的，等到所有线程都开始计算其他位置后就是并行了。·

```c++
template<typename Iterator>
void parallel_partial_sum(Iterator first, Iterator last)
{
    typedef typename Iterator::value_type value_type;
    struct process_chunk    //⇽-- - 1
    {
        void operator()(Iterator begin, Iterator last,
            std::future<value_type>* previous_end_value,
            std::promise<value_type>* end_value)
        {
            try
            {
                Iterator end = last;
                ++end;
                std::partial_sum(begin, end, begin);    //⇽-- - 2
                if (previous_end_value)    //⇽-- - 3
                {
                    value_type addend = previous_end_value->get();   // ⇽-- - 4
                    *last += addend;   // ⇽-- - 5
                    if (end_value)
                    {
                        end_value->set_value(*last);    //⇽-- - 6
                    }
                    // ⇽-- - 7
                    std::for_each(begin, last, [addend](value_type& item)
                        {
                            item += addend;
                        });
                }
                else if (end_value)
                {
                    // ⇽-- - 8
                    end_value->set_value(*last);
                }
            }
            catch (...)  // ⇽-- - 9
            {
                if (end_value)
                {
                    end_value->set_exception(std::current_exception());   // ⇽-- - 10
                }
                else
                {
                    throw;   // ⇽-- - 11
                }
            }
        }
    };
        unsigned long const length = std::distance(first, last);
        if (!length) {
            return;
        }
        unsigned long const min_per_thread = 25;     //⇽-- - 12
        unsigned long const max_threads = (length + min_per_thread - 1) / min_per_thread;
        unsigned long const hardware_threads = std::thread::hardware_concurrency();
        unsigned long const num_threads = std::min(hardware_threads != 0 ? hardware_threads : 2, max_threads);
        unsigned long const block_size = length / num_threads;
        typedef typename Iterator::value_type value_type;
        std::vector<std::thread> threads(num_threads - 1);   // ⇽-- - 13
        std::vector<std::promise<value_type> > end_values(num_threads - 1);   // ⇽-- - 14
        std::vector<std::future<value_type> > previous_end_values;   // ⇽-- - 15
        previous_end_values.reserve(num_threads - 1);   // ⇽-- - 16
        join_threads joiner(threads);
        Iterator block_start = first;
        for (unsigned long i = 0; i < (num_threads - 1); ++i)
        {
            Iterator block_last = block_start;
            std::advance(block_last, block_size - 1);   // ⇽-- - 17
            // ⇽-- - 18
            threads[i] = std::thread(process_chunk(), block_start, block_last,
                (i != 0) ? &previous_end_values[i - 1] : 0,
                &end_values[i]);
            block_start = block_last;
            ++block_start;   // ⇽-- - 19
            previous_end_values.push_back(end_values[i].get_future());   // ⇽-- - 20
        }
        Iterator final_element = block_start;
        std::advance(final_element, std::distance(block_start, last) - 1);   // ⇽-- - 21
        // ⇽-- - 22
        process_chunk()(block_start, final_element, (num_threads > 1) ? &previous_end_values.back() : 0,
            0);
}
```

1. 定义了`process_chunk`类，重载了()运算符，在重载的逻辑里我们先计算区间内的`partial_sum`累计求和(2处)
2. 因为我们处理的区间不一定是首个区间，也就是他还需要加上前面区间处理得出的最后一个元素的值，所以我们通过`previouse_end_value`判断本区间不是首个区间，并且加上前面处理的结果。优先将最后一个值计算出来设置给promise。然后在利用for_each遍历计算其他位置的值。

## C++ 线程池原理和实现

线程池是一种并发编程的技术，用于有效地管理和**复用**线程资源。它由一组预先创建的线程组成，这些线程可以在需要时执行任务，并在任务完成后返回线程池中等待下一个任务。

线程池的主要目的是避免反复创建和销毁线程的开销，以及有效地控制并发线程的数量。通过使用线程池，可以降低系统的负载，并提高任务执行的效率。


以下是线程池的一些关键特点：

1. 线程池包含一个线程队列和任务队列，任务队列用于存储待执行的任务。
2. 线程池在启动时会创建一定数量的线程，并将它们放入线程队列中。
3. 当有任务需要执行时，线程池从任务队列中获取任务，并将其分配给空闲的线程执行。
4. 执行完任务的线程会继续等待下一个任务的到来，而不是被销毁。
5. 如果任务队列为空，线程池中的线程可以进入**睡眠状态**，减少资源占用。
6. 线程池可以**限制同时执行的线程数量**，避免过多的并发线程导致系统负载过高。

使用线程池有以下几个优点：

1. 提高性能：通过复用线程，避免了线程创建和销毁的开销，提高了任务执行的效率。
2. 资源控制：线程池可以限制并发线程的数量，避免系统负载过高，保护系统资源。
3. 提高响应性：线程池可以在任务到来时立即进行处理，减少了任务等待的时间，提高了系统的响应速度。
4. 简化编程：使用线程池可以将任务的提交和执行分离，简化了并发编程的复杂性。

需要注意的是，在使用线程池时，需要合理设置线程池的大小，避免线程过多导致资源浪费，或线程过少导致任务等待的时间过长。

### 线程池的实现

首先我不希望线程池被拷贝，我希望它能以单例的形式在需要的地方调用, 那么单例模式就需要删除拷贝构造和拷贝赋值，所以我设计一个基类

```c++
class NoneCopy {
public:
    ~NoneCopy(){}
protected:
    NoneCopy(){}
private:
    NoneCopy(const NoneCopy&) = delete;
    NoneCopy& operator=(const NoneCopy&) = delete;
};
```

然后让线程池ThreadPool类继承NoneCopy, 这样ThreadPool也就不支持拷贝构造和拷贝赋值了，拷贝构造和拷贝赋值的前提是其基类可以拷贝构造和赋值。

```c++
class ThreadPool : public NoneCopy {
public:
    ~ThreadPool();
    static ThreadPool& instance() {
        static ThreadPool ins;
        return ins;
    }
private:
    ThreadPool();
};
```


我们先实现了instance函数，该函数是一个静态成员函数，返回局部的静态实例ins.
我们之前在单例模式中讲过，函数内局部的静态变量，其生命周期和进程同步，但是可见度仅在函数内部。
局部静态变量只会在第一次调用这个函数时初始化一次。故可以作为单例模式。这种模式在C++ 11之前是不安全的，因为各平台编译器实现规则可能不统一导致多线程会生成多个实例。
但是C++ 11过后，语言层面对其优化保证了多个线程调用同一个函数只会生成一个实例，所以C++ 11过后我们可以放心使用。
接下来考虑构造函数，我们说过线程池需要线程队列和任务队列，所以这两个队列要在构造函数中完成构造，线程队列我们可以用一个vector存储，任务队列因为要保证先进先出，所以用queue结构即可。
因为任务队列要有通用性，所以我们规定任务队列中存储的类型为

```c++
using Task = std::packaged_task<void()>;
```

我们在ThreadPool中添加如下成员

```c++
std::atomic_int          thread_num_;
std::queue<Task>         tasks_;
std::vector<std::thread> pool_;
std::atomic_bool         stop_;
```

其中 `tasks _`表示任务队列， `pool_`表示线程队列， `thread_num_`表示空闲的线程数, `stop_`表示线程池是否退出。
那我们可以实现线程池的构造函数了

```c++
ThreadPool(unsigned int num = std::thread::hardware_concurrency())
    : stop_(false) {
    if (num <= 1)
        thread_num_ = 2;
    else
        thread_num_ = num;
    start();
}
```

我们在构造函数中初始化停止标记为false，初始化线程数默认为硬件允许的物理并行核数。然后调用了start函数。

start函数主要的功能为启动线程并且将线程放入vector中管理，线程的回调函数基本功能就是从任务队列中消费数据，如果队列中有任务则pop出任务并执行，否则线程需要挂起。在部分初学者实现的线程池当中会采用循环等待的方式(如果队列为空则继续循环)，这种方式会造成线程忙等，进而引发资源的浪费。

所以我们现在还需要给ThreadPool添加两个成员

```c++
std::mutex               cv_mt_;
std::condition_variable  cv_lock_;
```

分别表示互斥量和条件变量，用来控制线程的休眠和唤醒。
那我们实现start函数

```c++
void start() {
    for (int i = 0; i < thread_num_; ++i) {
        pool_.emplace_back([this]() {
            while (!this->stop_.load()) {
                Task task;
                {
                    std::unique_lock<std::mutex> cv_mt(cv_mt_);
                    this->cv_lock_.wait(cv_mt, [this] {
                        return this->stop_.load() || !this->tasks_.empty();
                            });
                     if (this->tasks_.empty())
                        return;
                    task = std::move(this->tasks_.front());
                    this->tasks_.pop();
                }
                    this->thread_num_--;
                    task();
                    this->thread_num_++;
            }
        });
    }
}
```

pool_为线程队列，在线程队列中我们采用emplace_back直接调用线程的构造函数，将线程要处理的逻辑写成lambda表达式，从而构造线程并且将线程插入线程队列中。
lambda表达式内的逻辑先判断是否停止，如果停止则退出循环, 否则继续循环。
循环的逻辑就是每次从队列中取任务，先调用条件变量等待队列不为空，或者收到退出信号，二者只要满足其一，条件变量的wait就返回，并且继续向下走。否则条件变量wait不会返回，线程将挂起。
如果条件变量判断条件满足(队列不为空或者发现停止信号)，线程继续向下执行，判断如果任务队列为空则说明是因为收到停止信号所以直接返回退出，否则就说明任务队列有数据，我们取出任务队列头部的task，将空闲线程数减少1，执行task，再将空闲线程数+1.

接下来我们实现析构函数
```c++
~ThreadPool() {
    stop();
}
```

析构函数中的stop就是要向线程发送停止信号，避免线程一直处于挂起状态(因为任务队列为空会导致线程挂起)

```c++
void stop() {
    stop_.store(true);
    cv_lock_.notify_all();
    for (auto& td : pool_) {
        if (td.joinable()) {
            std::cout << "join thread " << td.get_id() << std::endl;
            td.join();
        }
    }
}
```

stop函数中我们将停止标记设置为true，并且调用条件变量的notify_all唤醒所有线程，并且等待所有线程退出后线程池才析构完成。
我们再实现一个函数提供给外部查询当前空闲的线程数，这个功能可有可无，主要是方便外部根据空闲线程数是否达到阈值派发任务。

```c++
int idleThreadCount() {
    return thread_num_;
}
```

我们实现了线程池处理任务的逻辑，接下来我们要封装一个接口提供给外部，支持其投递任务给线程池。

因为我们要投递任务给线程池，任务的功能和参数都不同，而之前我们设置的线程池执行的task类型为void(void)，返回值为void，参数为void的任务。那我们可用用参数绑定的方式将一个函数绑定为void(void)类型, 比如我们用如下操作
```c++
int functionint(int param) {
    std::cout << "param is " << param << std::endl;
    return 0;
}
void bindfunction() {
    std::function<int(void)> functionv = std::bind(functionint, 3);
    functionv();
}
```

假设我们希望任务队列里的任务要调用functionint，以及参数为3，因为在投递任务时我们就知道任务要执行的函数和参数，所以我们可以将执行的函数和参数绑定生成参数为void的函数。

我们通过bindfunction将functionint绑定为一个返回值为int，参数为void的新函数functionv。而我们的任务队列要放入返回值为void，参数也为void的函数，该怎么办呢？

其实很简单，我们可以利用lambda表达式生成一个返回值和参数都为void的函数，函数内部调用functionv即可，有点类似于go，python等语言的闭包，但是C++的闭包是一种伪闭包，需要用值的方式捕获用到的变量。

比如我们将上面的函数functionint和调用的参数3打包放入队列，可以这么写

```c++
void pushtasktoque() {
    std::function<int(void)> functionv = std::bind(functionint, 3);
    using Task = std::packaged_task<void()>;
    std::queue<Task> taskque;
    taskque.emplace([functionv]() {
        functionv();
        });
}
```

我们先将functionint绑定为functionv，然后定义一个队列存储的类型为`std::packaged_task<void()>`, 为了防止拷贝构造的开销，我们调用队列的emplace函数，该函数接受lambda表达式直接构造任务放入了队列里。因为lambda表达式捕获了functionv的值，所以可以在内部调用functionv。

lambda表达式返回值为void参数也为void，所以可以直接放入任务队列。

接下来要一个问题，一个问题是我们投递任务，有时候投递方需要获取任务是否完成, 那我们可以利用packaged_task返回一个future给调用方，调用方在外部就可以通过future判断任务是否返回了。我们修改上面的函数，实现commit任务的函数

```c++
std::future<int> committask() {
    std::function<int(void)> functionv = std::bind(functionint, 3);
    auto taskf = std::make_shared<std::packaged_task<int(void)>>(functionv);
    auto res = taskf->get_future();
    using Task = std::packaged_task<void()>;
    std::queue<Task> taskque;
    taskque.emplace([taskf]() {
        (*taskf)();
        });
    return res;
}
```

我们将functionv传递给`packaged_task`构造函数，构造了一个`packaged_task`类型的智能指针，每个人的编程风格不同，大家也可以不用智能指针，直接使用`packaged_task`对象，比如下面的

```c++
std::packaged_task<int(void)> taskf(functionv);
```

我构造的是packaged_task类型的智能指针，所以通过`taskf->get_future()`获取future对象res，这个res作为参数返回给外部，外部就可以通过res判断任务是否完成。
接下来我们定义了一个任务队列，任务队列调用emplace直接构造任务插入队列中，避免拷贝开销。参数为lambda表达式，lamba捕获taskf对象的值，在内部调用`(*taskf)()`完成任务调用。
上面只是通过具体的函数和参数实现了投递任务的功能，而实际情况是我们要投递各种类型的任务，以及多种类型和多个参数，该怎么实现committask函数更通用呢？
对于更通用的设计我们通常采用模板

```c++
template <class F, class... Args>
std::future<int> commit(F&& f, Args&&... args){
    //....
    return std::future<int>();
}
```

上面的模板定义了两个类型，F表示可调用对象类型，可以是lambda表达式，函数，function类等， Args为可变参数模板，可以是任意种类的类型，任意数量。commit函数参数采用F和Args的右值引用，这种模板类型的右值引用也被称作万能引用类型，可以接受左值引用，也可接受右值引用，利用引用折叠技术，可以推断出f和args的最终类型。我在基础课程里讲过，这里再给大家复习一下折叠规则，假设T为模板类型，推到规则如下：

```
T& & => T&
T& && => T&
T&& & => T&
T&& && => T&&
```


总结一下，就是只要出现了左值引用最后折叠的结果都是左值引用，只有右值应用和右值引用折叠才能变成右值引用。

```c++
template<typename T>
void Function(T&& t){
    //...
}
int main(){
    int a = 3;
    Function(a);
    Function(3);
    return 0;
}
```

当我们把一个int类型的左值a传递给 Function的 T&& 参数t时(T为模板类型)， T被推导为int & , 那么参数t整体的类型就变为int & && => int &类型，也就是左值引用类型。
当我们把一个右值3传递给Function的T&& 参数t时，T被推导为int类型。t被推导为int && 类型，也就是右值引用类型。
如果大家熟悉boost库，可以用boost库的`type_id_with_cvr`打印具体类型，比如我们下面的代码

```c++
#include <boost/type_index.hpp>
using boost::typeindex::type_id_with_cvr;
int functionint(int param) {
    std::cout << "param is " << param << std::endl;
    return 0;
}
template <class F, class... Args>
std::future<int> commit(F&& f, Args&&... args) {
    //....
        // 利用Boost库打印模板推导出来的 T 类型
    std::cout << "F type：" << type_id_with_cvr<F>().pretty_name() << std::endl;
    // 利用Boost库打印形参的类型
    std::cout << "f type:" << type_id_with_cvr<decltype(f)>().pretty_name() << std::endl;
    std::cout << "Args type：" << type_id_with_cvr<Args...>().pretty_name() << std::endl;
    std::cout << "args type：" << type_id_with_cvr<decltype(args)...>().pretty_name() << std::endl;
    return std::future<int>();
}
void reference_collapsing(){
    int a = 3;
    commit(functionint, a);
}
```

调用reference_collapsing函数输出如下

```c++
F type：int (__cdecl&)(int)
f type:int (__cdecl&)(int)
Args type：int & __ptr64
args type：int & __ptr64
```

可以看出F和f的类型都为函数对象的左值引用类型`int (__cdecl&)(int)`，因为可变参数列表只有一个int左值类型，所以Args被推导为int &类型， 同样的道理args也是int &类型。

那如果我们换一种方式调用

```c++
void reference_collapsing2(){
    commit(std::move(functionint), 3);
}
```

调用reference_collapsing2输出如下
```c++
F type：int __cdecl(int)
f type:int (__cdecl&&)(int)
Args type：int
args type：int && __ptr64
```

F为函数对象类型`int __cdecl(int)`, f被对段位函数对象的右值引用类型`int (__cdecl&&)(int)`
Args 被推断为int类型， args被推断为int && 类型。
所以我们就可以得出之前给大家的结论，对于模板类型参数T && , 编译器会根据传入的类型为左值还是右值，将T 推断为不同的类型， 如果传入的类型为int类型的左值，则T为int&类型，如果传入的类型为int类型的右值，则T为int类型。
模板参数介绍完了，还要介绍一下原样转发, 熟悉我视频风格的读者都知道在介绍正确做法前我会先介绍错误示范，我们先看下面的例子

```c++
void use_rightref(int && rparam) {
    //....
}
template<typename T>
void use_tempref(T&& tparam) {
    use_rightref(tparam);
}
void test_tempref() {
    use_tempref(3);
}
```

我先给大家介绍下上面代码的调用流程，我们在`test_tempref`里调用`use_tempref`, 参数3是一个右值，所以`use_tempref`中T被推断为int类型， tparam为int && 类型。我们接着将tparam传递给`use_rightref`,tparam是int && 类型，刚好可以传递给`use_rightref`，然而上面的代码会报错。

```c++
“void use_rightref(int &&)”: 无法将参数 1 从“T”转换为“int &&”
```

报错的原因是我们将tparam传递给`use_rightref`的时候参数类型不匹配。在`use_tempref`中，tparam为int && 类型，即int 的右值引用类型。但是将tparam传递给`use_rightref`时，tparam是作为左值传递的， 他的类型是int && 类型，但是在函数`use_tempref`中tparam可以作为左值使用。这么说大家有点难理解
我们分开理解，左值和右值的区别
左值（lvalue） 是指表达式结束后依然存在的、可被取地址的数据。通俗地说，左值就是可以放在赋值符号左边的值。
右值（rvalue） 是指表达式结束后就不再存在的临时数据。通常是不可被取地址的临时值，例如常量、函数返回值、表达式计算结果等。在 C++11 之后，右值引用的引入使得我们可以直接操作右值。
我们看下面的代码 

```c++
template<typename T>
void use_tempref(T&& tparam) {
    int a = 4;
    tparam = a;
    tparam = std::move(a);
}
void test_tempref() {
    use_tempref(3);
}
```

上述代码编译没有问题可以运行，tparam可以作为左值被赋值。所以当它作为参数传递给其他函数的时候，它也是作为左值使用的，那么传递给`use_rightref`时，就会出现`int&&` 绑定左值的情况，这在编译阶段是不允许的。

下面这种tparam也是被作为左值使用
```c++
void use_tempref(int && tparam) {
    int a = 4;
    tparam = a;
    tparam = std::move(a);
}
void test_tempref() {
    use_tempref(3);
}
```

上面代码编译也会通过的。

那么我们接下来要解决tparam作为左值传递给`use_rightref`报错的问题，C++ 给我们提供了原样转发功能，这个在基础中也给大家介绍过, C++ 源码对于forward的实现有两个版本，分别是将一个左值转化为一个左值或者右值，以及将一个右值转化为一个右值。

```c++
template <class _Ty>
_NODISCARD constexpr _Ty&& forward(
    remove_reference_t<_Ty>& _Arg) noexcept { // forward an lvalue as either an lvalue or an rvalue
    return static_cast<_Ty&&>(_Arg);
}
template <class _Ty>
_NODISCARD constexpr _Ty&& forward(remove_reference_t<_Ty>&& _Arg) noexcept { // forward an rvalue as an rvalue
    static_assert(!is_lvalue_reference_v<_Ty>, "bad forward call");
    return static_cast<_Ty&&>(_Arg);
}
```

因为实现了两个版本，所以forward会根据传递的是左值调用第一个版本，传递的是右值调用第二个版本。
我们看看`remove_reference_t<_Ty>`的源码

```c++
template <class _Ty>
struct remove_reference<_Ty&> {
    using type                 = _Ty;
    using _Const_thru_ref_type = const _Ty&;
};
template <class _Ty>
struct remove_reference<_Ty&&> {
    using type                 = _Ty;
    using _Const_thru_ref_type = const _Ty&&;
};
template <class _Ty>
using remove_reference_t = typename remove_reference<_Ty>::type;
```

我们通过观察就会发现`remove_reference_t<_Ty>`其实是去除了`_Ty`中的引用返回内部的type.
所以我们`forward<int>(3)`时，执行`forward(remove_reference_t<_Ty>&& _Arg)`, `_Ty`为int && 类型，`remove_reference_t<_Ty>`为int类型. 返回的为`static_cast<_Ty&&>(_Arg)`类型，即int && &&类型,折叠一下变为int &&类型。
同样当我们forward(a)，比如a是一个int类型的左值，则执行`_Ty&& forward(remove_reference_t<_Ty>& _Arg)`, `_Ty`为int &类型， `remove_reference_t<_Ty>`为int类型， 返回值为`static_cast<_Ty&&>(_Arg)` ,即int & && 类型折叠为int &类型。
所以有了这些知识，我们解决上面的编译错误可以这么干

```c++
void use_rightref(int && rparam) {
    //....
}
template<typename T>
void use_tempref(T&& tparam) {
    use_rightref(std::forward<T>(tparam));
}
void test_tempref() {
    use_tempref(3);
}
```

接下来我们回到线程池的话题，commit函数需要返回future对象，但是我们又无法在函数定义的时候提前写好返回值future的类型，那怎么办呢？
可以用到C++ 11的一个技术就是尾置推导

```c++
template <class F, class... Args>
auto commit(F&& f, Args&&... args) -> 
        std::future<decltype(std::forward<F>(f)(std::forward<Args>(args)...))> {
        using RetType = decltype(std::forward<F>(f)(std::forward<Args>(args)...));
        return std::future<RetType>{};
}
```

我们在commit函数返回值写成了auto,告诉编译器具体的返回类型在其后，这样编译器在加载完函数的参数f和args之后，可以推导返回值类型.
推导也很简单，我们通过`decltype(std::forward<F>(f)(std::forward<Args>(args)...))`, decltype会根据根据表达式推断表达式的结果类型，我们用future存储这个类型，这个future就是返回值类型。
decltype中我们用了forward原样转发f和args，其实f不用转发，因为我们调用f是按照左值调用的，至于args原样转发是考虑f接受的参数可能是一个右值，但是这种情况其实不多，所以对于普通情形，我们写成`decltype(f(args...))`没问题的。
因为推导的类型我们以后还会用到，所以用了RetType来记录这个类型。
接下来我们给出commit的完整代码

```c++
template <class F, class... Args>
auto commit(F&& f, Args&&... args) -> 
std::future<decltype(std::forward<F>(f)(std::forward<Args>(args)...))> {
    using RetType = decltype(std::forward<F>(f)(std::forward<Args>(args)...));
    if (stop_.load())
        return std::future<RetType>{};
    auto task = std::make_shared<std::packaged_task<RetType()>>(
            std::bind(std::forward<F>(f), std::forward<Args>(args)...));
    std::future<RetType> ret = task->get_future();
    {
        std::lock_guard<std::mutex> cv_mt(cv_mt_);
        tasks_.emplace([task] { (*task)(); });
    }
    cv_lock_.notify_one();
    return ret;
}
```

在commit中我们生成一个packaged_task<RetType()>类型的智能指针task，通过task获取future.
接下来我们加锁并且将task放入队列，但是因为task的返回类型为RetType，所以我们采用了lambda表达式捕获task，内部调用task，将这个lambda表达式放入任务队列。
然后通知其他线程唤醒，并且返回future。

### 测试

为了测试线程池，我们可以用前文实现的快速排序的方法，将任务分段递归投递给线程池，让线程池排序

```c++
template<typename T>
std::list<T>pool_thread_quick_sort(std::list<T> input) {
    if (input.empty())
    {
        return input;
    }
    std::list<T> result;
    result.splice(result.begin(), input, input.begin());
    T const& partition_val = *result.begin();
    typename std::list<T>::iterator divide_point =
        std::partition(input.begin(), input.end(),
            [&](T const& val) {return val < partition_val; });
    std::list<T> new_lower_chunk;
    new_lower_chunk.splice(new_lower_chunk.end(),
        input, input.begin(),
        divide_point);
    std::future<std::list<T> > new_lower = ThreadPool::instance().commit(pool_thread_quick_sort<T>, new_lower_chunk);
    std::list<T> new_higher(pool_thread_quick_sort(input));
    result.splice(result.end(), new_higher);
    result.splice(result.begin(), new_lower.get());
    return result;
}
```

我们再写一个测试用例

```c++
void TestThreadPoolSort() {
    std::list<int> nlist = { 6,1,0,5,2,9,11 };
    auto sortlist = pool_thread_quick_sort<int>(nlist);
    for (auto& value : sortlist) {
        std::cout << value << " ";
    }
    std::cout << std::endl;
}
```

结果输出

```
0 1 2 5 6 9 11
```


## 线程池技术补充

### 轮询方式的线程池

配合我们之前封装的线程安全队列threadsafe_queue

```c++
#include <mutex>
#include <queue>
template<typename T>
class threadsafe_queue
{
private:
    struct node
    {
        std::shared_ptr<T> data;
        std::unique_ptr<node> next;
        node* prev;
    };
    std::mutex head_mutex;
    std::unique_ptr<node> head;
    std::mutex tail_mutex;
    node* tail;
    std::condition_variable data_cond;
    std::atomic_bool  bstop;
    node* get_tail()
    {
        std::lock_guard<std::mutex> tail_lock(tail_mutex);
        return tail;
    }
    std::unique_ptr<node> pop_head()   
    {
        std::unique_ptr<node> old_head = std::move(head);
        head = std::move(old_head->next);
        return old_head;
    }
    std::unique_lock<std::mutex> wait_for_data()   
    {
        std::unique_lock<std::mutex> head_lock(head_mutex);
        data_cond.wait(head_lock,[&] {return head.get() != get_tail() || bstop.load() == true; });
        return std::move(head_lock);   
    }
        std::unique_ptr<node> wait_pop_head()
        {
            std::unique_lock<std::mutex> head_lock(wait_for_data());   
            if (bstop.load()) {
                return nullptr;
            }
                return pop_head();
        }
        std::unique_ptr<node> wait_pop_head(T& value)
        {
            std::unique_lock<std::mutex> head_lock(wait_for_data());  
            if (bstop.load()) {
                return nullptr;
            }
            value = std::move(*head->data);
            return pop_head();
        }
        std::unique_ptr<node> try_pop_head()
        {
            std::lock_guard<std::mutex> head_lock(head_mutex);
            if (head.get() == get_tail())
            {
                return std::unique_ptr<node>();
            }
            return pop_head();
        }
        std::unique_ptr<node> try_pop_head(T& value)
        {
            std::lock_guard<std::mutex> head_lock(head_mutex);
            if (head.get() == get_tail())
            {
                return std::unique_ptr<node>();
            }
            value = std::move(*head->data);
            return pop_head();
        }
public:
    threadsafe_queue() :  // ⇽-- - 1
        head(new node), tail(head.get())
    {}
    ~threadsafe_queue() {
        bstop.store(true);
        data_cond.notify_all();
    }
    threadsafe_queue(const threadsafe_queue& other) = delete;
    threadsafe_queue& operator=(const threadsafe_queue& other) = delete;
    void Exit() {
        bstop.store(true);
        data_cond.notify_all();
    }
    bool wait_and_pop_timeout(T& value) {
        std::unique_lock<std::mutex> head_lock(head_mutex);
        auto res = data_cond.wait_for(head_lock, std::chrono::milliseconds(100),
                [&] {return head.get() != get_tail() || bstop.load() == true; });
        if (res == false) {
            return false;
        }
        if (bstop.load()) {
            return false;
        }
        value = std::move(*head->data);    
        head = std::move(head->next);
        return true;
    }
    std::shared_ptr<T> wait_and_pop() //  <------3
    {
        std::unique_ptr<node> const old_head = wait_pop_head();
        if (old_head == nullptr) {
            return nullptr;
        }
        return old_head->data;
    }
    bool  wait_and_pop(T& value)  //  <------4
    {
        std::unique_ptr<node> const old_head = wait_pop_head(value);
        if (old_head == nullptr) {
            return false;
        }
        return true;
    }
    std::shared_ptr<T> try_pop()
    {
        std::unique_ptr<node> old_head = try_pop_head();
        return old_head ? old_head->data : std::shared_ptr<T>();
    }
    bool try_pop(T& value)
    {
        std::unique_ptr<node> const old_head = try_pop_head(value);
        if (old_head) {
            return true;
        }
        return false;
    }
    bool empty()
    {
        std::lock_guard<std::mutex> head_lock(head_mutex);
        return (head.get() == get_tail());
    }
    void push(T new_value) //<------2
    {
        std::shared_ptr<T> new_data(
            std::make_shared<T>(std::move(new_value)));
        std::unique_ptr<node> p(new node);
        {
            std::lock_guard<std::mutex> tail_lock(tail_mutex);
            tail->data = new_data;
            node* const new_tail = p.get();
            new_tail->prev = tail;
            tail->next = std::move(p);
            tail = new_tail;
        }
        data_cond.notify_one();
    }
    bool try_steal(T& value) {
        std::unique_lock<std::mutex> tail_lock(tail_mutex,std::defer_lock);
        std::unique_lock<std::mutex>  head_lock(head_mutex, std::defer_lock);
        std::lock(tail_lock, head_lock);
        if (head.get() == tail)
        {
            return false;
        }
        node* prev_node = tail->prev;
        value = std::move(*(prev_node->data));
        tail = prev_node;
        tail->next = nullptr;
        return true;
    }
};
```


我们封装了一个简单轮询的线程池

```c++
#include <atomic>
#include "ThreadSafeQue.h"
#include "join_thread.h"
class simple_thread_pool
{
    std::atomic_bool done;
    //⇽-- - 1
    threadsafe_queue<std::function<void()> > work_queue; 
    //⇽-- - 2
    std::vector<std::thread> threads; 
    //⇽-- - 3
    join_threads joiner;    
    void worker_thread()
    {
        //⇽-- - 4
        while (!done)    
        {
            std::function<void()> task;
            //⇽-- - 5
            if (work_queue.try_pop(task))    
            {
                //⇽-- - 6
                task();    
            }
            else
            {
                //⇽-- - 7
                std::this_thread::yield();    
            }
        }
    }
    simple_thread_pool() :
        done(false), joiner(threads)
    {
        //⇽--- 8
        unsigned const thread_count = std::thread::hardware_concurrency();
        try
        {
            for (unsigned i = 0; i < thread_count; ++i)
            {
                //⇽-- - 9
                threads.push_back(std::thread(&simple_thread_pool::worker_thread, this));
            }
        }
        catch (...)
        {
            //⇽-- - 10
            done = true;
            throw;
        }
    }
public:
    static simple_thread_pool& instance() {
       static  simple_thread_pool pool;
       return pool;
    }
    ~simple_thread_pool()
    {
        //⇽-- - 11
        done = true;     
        for (unsigned i = 0; i < threads.size(); ++i)
        {
            //⇽-- - 9
            threads[i].join();
        }
    }
    template<typename FunctionType>
    void submit(FunctionType f)
    {
        //⇽-- - 12
        work_queue.push(std::function<void()>(f));    
    }
};
```


1. worker_thread 即为线程的回调函数，回调函数内从队列中取出任务并处理，如果没有任务则调用yield释放cpu资源。
2. submit函数比较简单，投递了一个返回值为void，参数为void的任务。这和我们之前自己设计的线程池(可执行任意参数类型，返回值不限的函数)相比功能稍差了一些。
    

### 获取任务完成结果

因为外部投递任务给线程池后要获取线程池执行任务的结果，我们之前自己设计的线程池采用的是future和decltype推断函数返回值的方式构造一个返回类型的future。

这里作者先封装一个可调用对象的类

```c++
class function_wrapper
{
    struct impl_base {
        virtual void call() = 0;
        virtual ~impl_base() {}
    };
    std::unique_ptr<impl_base> impl;
    template<typename F>
    struct impl_type : impl_base
    {
        F f;
        impl_type(F&& f_) : f(std::move(f_)) {}
        void call() { f(); }
    };
public:
    template<typename F>
    function_wrapper(F&& f) :
        impl(new impl_type<F>(std::move(f)))
    {}
    void operator()() { impl->call(); }
    function_wrapper() = default;
    function_wrapper(function_wrapper&& other) :
        impl(std::move(other.impl))
    {}
    function_wrapper& operator=(function_wrapper&& other)
    {
        impl = std::move(other.impl);
        return *this;
    }
    function_wrapper(const function_wrapper&) = delete;
    function_wrapper(function_wrapper&) = delete;
    function_wrapper& operator=(const function_wrapper&) = delete;
};
```

1. impl_base 是一个基类，内部有一个纯虚函数call，以及一个虚析构，这样可以通过delete 基类指针动态析构子类对象。
2. impl_type 继承了impl_base类，内部包含了一个可调用对象f，并且实现了构造函数和call函数，call内部调用可调用对象f。 
3. function_wrapper 内部有智能指针impl_base类型的unique_ptr变量impl, function_wrapper构造函数根据可调用对象f构造impl
4. function_wrapper支持移动构造不支持拷贝和赋值。function_wrapper本质上就是当作task给线程池执行的。

可获取任务执行状态的线程池如下

```c++
class future_thread_pool
{
private:
    void worker_thread()
    {
        while (!done)
        {
            function_wrapper task;    
                if (work_queue.try_pop(task))
                {
                    task();
                }
                else
                {
                    std::this_thread::yield();
                }
        }
    }
public:
    static future_thread_pool& instance() {
        static  future_thread_pool pool;
        return pool;
    }
    ~future_thread_pool()
    {
        //⇽-- - 11
        done = true;
        for (unsigned i = 0; i < threads.size(); ++i)
        {
            //⇽-- - 9
            threads[i].join();
        }
    }
    template<typename FunctionType>
    std::future<typename std::result_of<FunctionType()>::type>   
        submit(FunctionType f)
    {
        typedef typename std::result_of<FunctionType()>::type result_type;   
            std::packaged_task<result_type()> task(std::move(f));   
            std::future<result_type> res(task.get_future());    
            work_queue.push(std::move(task));    
            return res;   
    }
private:
    future_thread_pool() :
        done(false), joiner(threads)
    {
        //⇽--- 8
        unsigned const thread_count = std::thread::hardware_concurrency();
        try
        {
            for (unsigned i = 0; i < thread_count; ++i)
            {
                //⇽-- - 9
                threads.push_back(std::thread(&future_thread_pool::worker_thread, this));
            }
        }
        catch (...)
        {
            //⇽-- - 10
            done = true;
            throw;
        }
    }
    std::atomic_bool done;
    //⇽-- - 1
    threadsafe_queue<function_wrapper> work_queue;
    //⇽-- - 2
    std::vector<std::thread> threads;
    //⇽-- - 3
    join_threads joiner;
};
```

1. worker_thread内部从队列中pop任务并执行，如果没有任务则交出cpu资源。
2. submit函数返回值为`std::future<typename std::result_of<FunctionType()>::type>`类型，通过`std::result_of<FunctionType()>`推断出函数执行的结果，然后通过`::type`推断出结果的类型，并且根据这个类型构造future，这样调用者就可以在投递完任务获取任务的执行结果了。
3. submit函数内部我们将函数执行的结果类型定义为result_type类型，并且利用f构造一个packaged_task任务。通过task返回一个future给外部调用者，然后我们调用队列的push将task放入队列，注意队列存储的是function_wrapper，这里是利用task隐式构造了function_wrapper类型的对象。

### 利用条件变量等待

当我们的任务队列中没有任务的时候，可以让线程挂起，然后等待有任务投递到队列后在激活线程处理

```c++
class notify_thread_pool
{
private:
    void worker_thread()
    {
        while (!done)
        {
            auto task_ptr = work_queue.wait_and_pop();
            if (task_ptr == nullptr) {
                continue;
            }
            (*task_ptr)();
        }
    }
public:
    static notify_thread_pool& instance() {
        static  notify_thread_pool pool;
        return pool;
    }
    ~notify_thread_pool()
    {
        //⇽-- - 11
        done = true;
        work_queue.Exit();
        for (unsigned i = 0; i < threads.size(); ++i)
        {
            //⇽-- - 9
            threads[i].join();
        }
    }
    template<typename FunctionType>
    std::future<typename std::result_of<FunctionType()>::type>   
        submit(FunctionType f)
    {
        typedef typename std::result_of<FunctionType()>::type result_type;   
            std::packaged_task<result_type()> task(std::move(f));   
            std::future<result_type> res(task.get_future());    
            work_queue.push(std::move(task));    
            return res;   
    }
private:
    notify_thread_pool() :
        done(false), joiner(threads)
    {
        //⇽--- 8
        unsigned const thread_count = std::thread::hardware_concurrency();
        try
        {
            for (unsigned i = 0; i < thread_count; ++i)
            {
                //⇽-- - 9
                threads.push_back(std::thread(&notify_thread_pool::worker_thread, this));
            }
        }
        catch (...)
        {
            //⇽-- - 10
            done = true;
            work_queue.Exit();
            throw;
        }
    }
    std::atomic_bool done;
    //⇽-- - 1
    threadsafe_queue<function_wrapper> work_queue;
    //⇽-- - 2
    std::vector<std::thread> threads;
    //⇽-- - 3
    join_threads joiner;
};
```

1. worker_thread内部调用了work_queue的wait_and_pop函数，如果队列中有任务直接返回，如果没任务则挂起。
2. 另外我们在线程池的析构函数和异常处理时都增加了`work_queue.Exit();` 这需要在我们的线程安全队列中增加Exit函数通知线程唤醒，因为线程发现队列为空会阻塞住。

```c++
void Exit() {
    bstop.store(true);
    data_cond.notify_all();
}
```

### 避免争夺

我们的任务队列只有一个，当向任务队列频繁投递任务，线程池中其他线程从队列中获取任务，队列就会频繁加锁和解锁，一般情况下性能不会有什么损耗，但是如果投递的任务较多，我们可以采取分流的方式，创建多个任务队列(可以和线程池中线程数相等)，将任务投递给不同的任务队列，每个线程消费自己的队列即可，这样减少了线程间取任务的冲突。

```c++
#include "ThreadSafeQue.h"
#include <future>
#include "ThreadSafeQue.h"
#include "join_thread.h"
#include "FutureThreadPool.h"
class parrallen_thread_pool
{
private:
    void worker_thread(int index)
    {
        while (!done)
        {
            auto task_ptr = thread_work_ques[index].wait_and_pop();
            if (task_ptr == nullptr) {
                continue;
            }
            (*task_ptr)();
        }
    }
public:
    static parrallen_thread_pool& instance() {
        static  parrallen_thread_pool pool;
        return pool;
    }
    ~parrallen_thread_pool()
    {
        //⇽-- - 11
        done = true;
        for (unsigned i = 0; i < thread_work_ques.size(); i++) {
            thread_work_ques[i].Exit();
        }
        for (unsigned i = 0; i < threads.size(); ++i)
        {
            //⇽-- - 9
            threads[i].join();
        }
    }
    template<typename FunctionType>
    std::future<typename std::result_of<FunctionType()>::type>
        submit(FunctionType f)
    {
        int index = (atm_index.load() + 1) % thread_work_ques.size();
        atm_index.store(index);
        typedef typename std::result_of<FunctionType()>::type result_type;
        std::packaged_task<result_type()> task(std::move(f));
        std::future<result_type> res(task.get_future());
        thread_work_ques[index].push(std::move(task));
        return res;
    }
private:
    parrallen_thread_pool() :
        done(false), joiner(threads), atm_index(0)
    {
        //⇽--- 8
        unsigned const thread_count = std::thread::hardware_concurrency();
        try
        {
            thread_work_ques = std::vector < threadsafe_queue<function_wrapper>>(thread_count);
            for (unsigned i = 0; i < thread_count; ++i)
            {
                //⇽-- - 9
                threads.push_back(std::thread(&parrallen_thread_pool::worker_thread, this, i));
            }
        }
        catch (...)
        {
            //⇽-- - 10
            done = true;
            for (int i = 0; i < thread_work_ques.size(); i++) {
                thread_work_ques[i].Exit();
            }
            throw;
        }
    }
    std::atomic_bool done;
    //全局队列
    std::vector<threadsafe_queue<function_wrapper>> thread_work_ques;
    //⇽-- - 2
    std::vector<std::thread> threads;
    //⇽-- - 3
    join_threads joiner;
    std::atomic<int>  atm_index;
};
```

1. 我们将任务队列变为多个`//全局队列 std::vector<threadsafe_queue<function_wrapper>> thread_work_ques;`.
2. commit的时候根据atm_index索引自增后对总大小取余将任务投递给不同的队列。
3. worker_thread增加了索引参数，每个线程的在回调的时候会根据自己的索引取出对应队列中的任务进行执行。

### 任务窃取

当本线程队列中的任务处理完了，它可以去别的线程的任务队列中看看是否有没处理的任务，帮助其他线程处理任务，简称任务窃取。

```c++
#include "ThreadSafeQue.h"
#include <future>
#include "ThreadSafeQue.h"
#include "join_thread.h"
#include "FutureThreadPool.h"
class steal_thread_pool
{
private:
    void worker_thread(int index)
    {
        while (!done)
        {
            function_wrapper wrapper;
            bool pop_res = thread_work_ques[index].try_pop(wrapper);
            if (pop_res) {
                wrapper();
                continue;
            }
            bool steal_res = false;
            for (int i = 0; i < thread_work_ques.size(); i++) {
                if (i == index) {
                    continue;
                }
                steal_res  = thread_work_ques[i].try_pop(wrapper);
                if (steal_res) {
                    wrapper();
                    break;
                }
            }
            if (steal_res) {
                continue;
            }
            std::this_thread::yield();
        }
    }
public:
    static steal_thread_pool& instance() {
        static  steal_thread_pool pool;
        return pool;
    }
    ~steal_thread_pool()
    {
        //⇽-- - 11
        done = true;
        for (unsigned i = 0; i < thread_work_ques.size(); i++) {
            thread_work_ques[i].Exit();
        }
        for (unsigned i = 0; i < threads.size(); ++i)
        {
            //⇽-- - 9
            threads[i].join();
        }
    }
    template<typename FunctionType>
    std::future<typename std::result_of<FunctionType()>::type>
        submit(FunctionType f)
    {
        int index = (atm_index.load() + 1) % thread_work_ques.size();
        atm_index.store(index);
        typedef typename std::result_of<FunctionType()>::type result_type;
        std::packaged_task<result_type()> task(std::move(f));
        std::future<result_type> res(task.get_future());
        thread_work_ques[index].push(std::move(task));
        return res;
    }
private:
    steal_thread_pool() :
        done(false), joiner(threads), atm_index(0)
    {
        //⇽--- 8
        unsigned const thread_count = std::thread::hardware_concurrency();
        try
        {
            thread_work_ques = std::vector < threadsafe_queue<function_wrapper>>(thread_count);
            for (unsigned i = 0; i < thread_count; ++i)
            {
                //⇽-- - 9
                threads.push_back(std::thread(&steal_thread_pool::worker_thread, this, i));
            }
        }
        catch (...)
        {
            //⇽-- - 10
            done = true;
            for (int i = 0; i < thread_work_ques.size(); i++) {
                thread_work_ques[i].Exit();
            }
            throw;
        }
    }
    std::atomic_bool done;
    //全局队列
    std::vector<threadsafe_queue<function_wrapper>> thread_work_ques;
    //⇽-- - 2
    std::vector<std::thread> threads;
    //⇽-- - 3
    join_threads joiner;
    std::atomic<int>  atm_index;
};
```

1. `worker_thread`中本线程会先处理自己队列中的任务，如果自己队列中没有任务则从其它线程的任务队列中获取任务。如果都没有则交出cpu资源。
2. 为了实现try_steal的功能，我们需要修改线程安全队列threadsafe_queue，增加try_steal函数

```c++
bool try_steal(T& value) {
    std::unique_lock<std::mutex> tail_lock(tail_mutex,std::defer_lock);
    std::unique_lock<std::mutex>  head_lock(head_mutex, std::defer_lock);
    std::lock(tail_lock, head_lock);
    if (head.get() == tail)
    {
        return false;
    }
    node* prev_node = tail->prev;
    value = std::move(*(prev_node->data));
    tail = prev_node;
    tail->next = nullptr;
    return true;
}
```

因为try_steal是从队列的尾部弹出数据，为了防止此时有其他线程从头部弹出数据造成操作同一个节点，或者其他线程弹出头部数据后接着修改头部节点为下一个节点，此时本线程正在弹出尾部节点，而尾部节点正好是头部的下一个节点造成数据混乱，此时加了两把锁，对头部和尾部都加锁。

我们这里所说的弹出尾部节点不是弹出tail，而是tail的前一个节点，因为tail是尾部表示一个空节点，tail前边的节点才是尾部数据的节点，为了实现反向查找，我们为node增加了prev指针

```c++
struct node
{
    std::shared_ptr<T> data;
    std::unique_ptr<node> next;
    node* prev;
};
```

所以在push节点的时候也要把这个节点的prev指针指向前一个节点
```c++
void push(T new_value) //<------2
{
    std::shared_ptr<T> new_data(
    std::make_shared<T>(std::move(new_value)));
    std::unique_ptr<node> p(new node);
    {
        std::lock_guard<std::mutex> tail_lock(tail_mutex);
        tail->data = new_data;
        node* const new_tail = p.get();
        new_tail->prev = tail;
        tail->next = std::move(p);
        tail = new_tail;
    }
        data_cond.notify_one();
}
```

整体来说steal版本的线程池就这些内容和前边变化不大。

## 中断线程

### 可中断线程

一个可中断的线程大体的实现是这个样子的

```c++
class interruptible_thread
{
    std::thread internal_thread;
    interrupt_flag* flag;
public:
    template<typename FunctionType>
    interruptible_thread(FunctionType f)
    {
        //⇽-- - 2
        std::promise<interrupt_flag*> p;  
        //⇽-- - 3
        internal_thread = std::thread([f, &p] {    
            p.set_value(&this_thread_interrupt_flag);
            //⇽-- - 4
            f();    
        });
        //⇽-- - 5
        flag = p.get_future().get();    
    }
    void join() {
        internal_thread.join();
    }
    void interrupt()
    {
        if (flag)
        {
            //⇽-- - 6
            flag->set();    
        }
    }
};
```

1. interrupt_flag 为中断标记，其set操作用来标记中断
2. `internal_thread`为内部线程，其回调函数内部先设置`interrupt_flag*`类型的promise值，再执行回调函数。
3. 在`interruptible_thread`构造函数中等待internal_thread回调函数内部设置好flag的promise值后再退出。
4. `this_thread_interrupt_flag`是我们定义的线程变量`thread_local interrupt_flag this_thread_interrupt_flag;`


### 中断标记

中断标记`interrupt_flag`类，主要是用来设置中断标记和判断是否已经中断，有可能挂起在条件变量的wait操作上，此时中断就需要唤醒挂起的线程。
为了扩充功能，我们希望设计接口支持在任何锁上等待，那我们使用`condition_variable_any`支持任意类型的条件变量。

```c++
class interrupt_flag
{
    std::atomic<bool> flag;
    std::condition_variable* thread_cond;
    std::condition_variable_any* thread_cond_any;
    std::mutex set_clear_mutex;
public:
    interrupt_flag() :
        thread_cond(0), thread_cond_any(0)
    {}
    void set()
    {
        flag.store(true, std::memory_order_relaxed);
        std::lock_guard<std::mutex> lk(set_clear_mutex);
        if (thread_cond)
        {
            thread_cond->notify_all();
        }
        else if (thread_cond_any) {
            thread_cond_any->notify_all();
        }
    }
    bool is_set() const
    {
        return flag.load(std::memory_order_relaxed);
    }
    void set_condition_variable(std::condition_variable& cv)
    {
        std::lock_guard<std::mutex> lk(set_clear_mutex);
        thread_cond = &cv;
    }
    void clear_condition_variable()
    {
        std::lock_guard<std::mutex> lk(set_clear_mutex);
        thread_cond = 0;
    }
    template<typename Lockable>
    void wait(std::condition_variable_any& cv, Lockable& lk) {
        struct custom_lock {
            interrupt_flag* self;
            Lockable& lk;
            custom_lock(interrupt_flag* self_, std::condition_variable_any& cond, Lockable& lk_) :
                self(self_), lk(lk_) {
                self->set_clear_mutex.lock();
                self->thread_cond_any = &cond;
            }
            void unlock() {
                lk.unlock();
                self->set_clear_mutex.unlock();
            }
            void lock() {
                std::lock(self->set_clear_mutex, lk);
            }
            ~custom_lock() {
                self->thread_cond_any = 0;
                self->set_clear_mutex.unlock();
            }
        };
        custom_lock cl(this, cv, lk);
        interruption_point();
        cv.wait(cl);
        interruption_point();
    }
};
```

1. set函数将停止标记设置为true，然后用条件变量通知挂起的线程。
2. `set_condition_variable` 设置flag关联的条件变量，因为需要用指定的条件变量通知挂起的线程。
3. `clear_condition_variable`清除关联的条件变量
4. wait操作封装了接受任意锁的等待操作，wait函数内部定义了custom_lock，封装了加锁，解锁等操作。
5. wait操作内部构造了custom_lock对象cl主要是对set_clear_mutex加锁，然后在调用cv.wait，这样能和set函数中的通知条件变量构成互斥，这么做的好处就是要么先将flag设置为true并发送通知，要么先wait，然后再发送通知。这样避免了线程在wait处卡死(线程不会错过发送的通知)

`interruption_point`函数内部判断flag是否为true，如果为true则抛出异常，这里作者处理的突兀了一些。读者可将这个函数改为bool返回值，调用者根据返回值判断是否继续等都可以。

```c++
void interruption_point()
{
    if (this_thread_interrupt_flag.is_set())
    {
        throw thread_interrupted();
    }
}
```

thread_interrupted为我们自定义的异常

```c++
class thread_interrupted : public std::exception
{
public:
    thread_interrupted() : message("thread interrupted.") {}
    ~thread_interrupted() throw () {
    }
    virtual const char* what() const throw () {
        return message.c_str();
    }
private:
    std::string message;
};
```

接下来定义一个类`clear_cv_on_destruct` 

```c++
struct clear_cv_on_destruct {
    ~clear_cv_on_destruct(){
        this_thread_interrupt_flag.clear_condition_variable();
    }
};
```

`clear_cv_on_destruct` 这个类主要是用来在析构时释放和flag关联的条件变量。

除此之外，我们还可以封装几个不同版本的等待  
支持普通条件变量的等待

```c++
void interruptible_wait(std::condition_variable& cv,
    std::unique_lock<std::mutex>& lk)
{
    interruption_point();
    this_thread_interrupt_flag.set_condition_variable(cv);
    clear_cv_on_destruct guard;
    interruption_point();
    cv.wait_for(lk, std::chrono::milliseconds(1));
    interruption_point();
}
```

支持谓词的等待

```c++
template<typename Predicate>
void interruptible_wait(std::condition_variable& cv,
    std::unique_lock<std::mutex>& lk,
    Predicate pred)
{
    interruption_point();
    this_thread_interrupt_flag.set_condition_variable(cv);
    clear_cv_on_destruct guard;
    while (!this_thread_interrupt_flag.is_set() && !pred())
    {
        cv.wait_for(lk, std::chrono::milliseconds(1));
    }
    interruption_point();
}
```

上面两个版本采用wait_for而不用wait是因为如果等待之前条件变量的通知已经发送，线程之后才调用wait就会发生死等，所以这里采用的wait_for

支持future的等待

```c++
template<typename T>
void interruptible_wait(std::future<T>& uf)
{
    while (!this_thread_interrupt_flag.is_set())
    {
        if (uf.wait_for(std::chrono::milliseconds(1)) ==
            std::future_status::ready)
            break;
    }
    interruption_point();
}
```

接下来我们用案例测试上面的案例

```c++
#include <iostream>
#include "interupthread.h"
std::vector<interruptible_thread> background_threads;
std::mutex mtx1;
std::mutex mtx2;
std::condition_variable cv1;
std::condition_variable_any cv2;
void start_background_processing() {
    background_threads.push_back([]() {
        try {
            std::unique_lock<std::mutex> lock(mtx1);
            interruptible_wait(cv1, lock);
        }
        catch (std::exception& ex) {
            std::cout << "catch exception is " << ex.what() << std::endl;
        }
    });
    background_threads.push_back([]() {
        try {
            std::unique_lock<std::mutex> lock(mtx2);
            this_thread_interrupt_flag.wait(cv2, mtx2);
        }
        catch (std::exception& ex) {
            std::cout << "catch exception is " << ex.what() << std::endl;
        }
    });
}
int main()
{
    start_background_processing();
    for (unsigned i = 0; i < background_threads.size(); i++) {
        background_threads[i].interrupt();
    }
    for (unsigned i = 0; i < background_threads.size(); i++) {
        background_threads[i].join();
    }
}
```

上面的案例中启动了两个线程，每个线程回调函数中调用我们封装的可中断的等待。在主函数中断两个线程，并测试两个线程能否在等待中中断。

程序输出

```
catch exception is thread interrupted.
catch exception is thread interrupted.
```


## 并发编程排错思路和方法

### 常见问题

在介绍如何排查前我们先将问题做几个归类：

1. 内存问题，包括内存泄露(未回收内存)，空指针，悬垂指针(野指针)，double free问题等。
2. 资源竞争，多个线程竞争同一块临界区的资源，未保证互斥
3. 死锁(互相引用阻塞卡死)和活锁(乐观锁尝试)
4. 引用已释放的变量，生命周期管理失效导致
5. 浅拷贝造成内存异常
6. 线程管控失败，修改或者回收一个已经绑定正在运行线程的变量，或者线程本该回收却被卡死，皆因线程管控失败导致
7. 智能指针和裸指针混用导致二次析构，也属于double free。

接下来根据上面列出的问题，我们根据实际案例排查出现问题的原因以及规避的方法。

### 空指针

空指针的问题比较好排查，我们在封装无锁队列的时候照抄《C++并发编程实战》一书引发了崩溃，详见源码链接中crushque.h以及lockfreequetest.cpp。  
测试用例如下：

```c++
void TestCrushQue() {
    crush_que<int>  que;
    std::thread t1([&]() {
        for (int i = 0; i < TESTCOUNT * 10000; i++) {
            que.push(i);
            std::cout << "push data is " << i << std::endl;
            std::this_thread::sleep_for(std::chrono::milliseconds(10));
        }
        });
    std::thread t2([&]() {
        for (int i = 0; i < TESTCOUNT * 10000;) {
            auto p = que.pop();
            if (p == nullptr) {
                std::this_thread::sleep_for(std::chrono::milliseconds(10));
                continue;
            }
            i++;
            std::cout << "pop data is " << *p << std::endl;
        }
        });
    t1.join();
    t2.join();
}
```

最后显示的崩溃点在

<img src="https://cdn.llfc.club/1708328384150.jpg" alt="image.png" style="zoom:60%;" />

很明显这是引发崩溃的底层代码，并不是上层代码，通过调用堆栈找到和崩溃最相近的逻辑

<img src="https://cdn.llfc.club/1708328755799.jpg" alt="image.png" style="zoom:80%;" />
我们点击第二行的栈调用跳转到队列的push操作。

<img src="https://cdn.llfc.club/1708328906480.jpg" alt="image.png" style="zoom:60%;" />

在代码166行处是崩溃的上层调用，我们通过分析old_tail.ptr此时为空指针，该问题的根因在于构造无锁队列时未进行头节点和尾部节点的初始化所致。

无论linux还是windows，排查崩溃问题最首要的解决方式为观察栈调用，gdb或者windows的栈信息直观的反应了崩溃的触发顺序。


### 内存泄漏

一般来说内存泄漏检测有专门的工具库，linux环境下可使用valgrind，windows的visual studio环境下Visual Leak Detector， 这些工具只能被动的检测内存泄漏，很多情况我们需要针对已经开发的类或者逻辑编写测试用例，检测内存泄漏。
比如我们对于无锁队列中提供了一个内存泄漏的版本，详见memoryleakque.h以及测试用例lockfreequetest.cpp，以下为测试代码

```c++
void TestLeakQue() {
    memoryleak_que<int>  que;
    std::thread t1([&]() {
        for (int i = 0; i < TESTCOUNT; i++) {
            que.push(i);
            std::cout << "push data is " << i << std::endl;
            std::this_thread::sleep_for(std::chrono::milliseconds(10));
        }
        });
    std::thread t2([&]() {
        for (int i = 0; i < TESTCOUNT;) {
            auto p = que.pop();
            if (p == nullptr) {
                std::this_thread::sleep_for(std::chrono::milliseconds(10));
                continue;
            }
            i++;
            std::cout << "pop data is " << *p << std::endl;
        }
        });
    t1.join();
    t2.join();
    assert(que.destruct_count == TESTCOUNT);
}
```

针对这个队列, 我们统计释放节点的个数和开辟节点的个数是否相等，通过`assert(que.destruct_count == TESTCOUNT);`断言检测，实际测试过程中发现存在内存泄漏。

<img src="https://cdn.llfc.club/1708330464493.jpg" alt="image.png" style="zoom:60%;" />

针对无锁队列的内存泄漏无外乎就是push和pop操作造成的，我们把测试用例改为单线程，先将多线程这个可变因素去掉

```c++
void TestLeakQueSingleThread() {
    memoryleak_que<int>  que;
    std::thread t1([&]() {
        for (int i = 0; i < TESTCOUNT; i++) {
            que.push(i);
            std::cout << "push data is " << i << std::endl;
            std::this_thread::sleep_for(std::chrono::milliseconds(10));
            auto p = que.pop();
            if (p == nullptr) {
                std::this_thread::sleep_for(std::chrono::milliseconds(10));
                continue;
            }
            std::cout << "pop data is " << *p << std::endl;
        }
        });
    t1.join();
    assert(que.destruct_count == TESTCOUNT);
}
```

上面的代码测试未发现内存泄漏，但这还不能将问题归因于多线程，我们构造一种情况触发空队列的pop

```c++
void TestLeakQueMultiPop() {
    memoryleak_que<int>  que;
    std::thread t1([&]() {
        for (int i = 0; i < TESTCOUNT; i++) {
            que.push(i);
            std::cout << "push data is " << i << std::endl;
            std::this_thread::sleep_for(std::chrono::milliseconds(10));
            auto p = que.pop();
            if (p == nullptr) {
                std::this_thread::sleep_for(std::chrono::milliseconds(10));
                continue;
            }
            std::cout << "pop data is " << *p << std::endl;
            auto p2 = que.pop();
            if (p2 == nullptr) {
                std::this_thread::sleep_for(std::chrono::milliseconds(10));
                continue;
            }
            std::cout << "pop data is " << *p2 << std::endl;
        }
        });
    t1.join();
    assert(que.destruct_count == TESTCOUNT);
}
```

上面的代码再一次触发断言，说明存在内存泄漏，那我们可以将问题归因于pop操作，而且是队列为空的pop操作。
接下来配合断点调试，windows断点调试较为方便，或者linux环境gdb调试麻烦，可以在关键点打印信息排查问题。
我们使用visual studio断点排查这个问题，先让队列push一个数据，再pop两次，第二次pop肯定无效因为是空队列，但也是引发泄漏的关键原因。
接下来再push一个数据，再pop节点，我们需观察这次pop是否会触发节点回收的逻辑。
回收节点的逻辑只有两处，在release_ref和free_external_counter内部判断internal_count和external_counters为0时才会调用delete回收内存，所以我们只需要在release_ref和free_external_counter中打断点，观察这两个引用计数是否为0，如果不为0说明引用计数的计算出了问题。

<img src="https://cdn.llfc.club/1708334690329.jpg" alt="image.png" style="zoom:60%;" />

为了便于观察数据，我们采取单步调试的方式，经过断点调试，发现第二次循环pop时，`free_external_count`内部`old_node_ptr.external_count`为3，而第一次循环pop时`old_node_ptr.external_count`为2. 那么第二次计算`internal_count`就不会为0，导致节点不会回收。

问题的根因也找到了在pop判断队列为空的时候直接返回了，之前进行了`increase_external_count`将外部引用计数增加了，在判断队列为空未进行修改就返回了，我们知道外部引用计数只是一个副本，可能同时有多个线程修改外部引用计数，所以只需要让内部引用计数释放一次即可

```c++
if (ptr == tail.load().ptr)
{
    ptr->release_ref();
    return std::unique_ptr<T>();
}
```


再次测试未发现内存泄漏。

自己设计测试用例时要注意覆盖多种情况，比如无锁队列，我后来又测试了单线程，多线程一进一出，多线程一进多出，多线程一出多进，多线程多出多进等，以及加大线程数测试。详细案例可以看看源码， lockfreequetest.cpp。

### double free

对于悬垂指针也叫做野指针，指的是释放内存后，再次使用这个指针访问数据造成崩溃。double free也属于指针管理失效导致，我们看看网络编程中对官方案例存在隐患的剖析。案例在网络编程network文件夹，day05-AsyncServer中，我们实现了一个异步的echo应答server。  
正常情况下应答server没有任何问题，但是对于全双工情况(实际情况都是收发解耦合)，比如我们在收到消息后监听读事件，并发送，而不是在发送消息后监听读事件。我们将handle_read处理改为如下

```c++
void Session::handle_read(const boost::system::error_code& error, size_t bytes_transfered) {
    if (!error) {
        cout << "server receive data is " << _data << endl;
        std::string send_data(_data);
        //在发送
        _socket.async_read_some(boost::asio::buffer(_data, max_length), std::bind(&Session::handle_read,
            this, placeholders::_1, placeholders::_2));
        boost::asio::async_write(_socket, boost::asio::buffer(send_data, bytes_transfered),
            std::bind(&Session::handle_write, this, placeholders::_1));
    }
    else {
        delete this;
    }
}
```

我们启动day04-SyncClient和day05-AsyncServer分别测试，在Server handle_read里`async_read_some`处打断点，然后启动客户端，客户端发送数据后服务器触发`async_read_some`断点，此时关闭客户端，然后服务器继续执行后面的逻辑会引发崩溃。

<img src="https://cdn.llfc.club/1708481010816.jpg" alt="image.png" style="zoom:60%;" />

遇到崩溃第一反应是看看崩溃的栈信息，崩溃在最底层代码

<img src="https://cdn.llfc.club/1708482046203.jpg" alt="image.png" style="zoom:60%;" />

栈信息也看不懂

<img src="https://cdn.llfc.club/1708482122640.jpg" alt="image.png" style="zoom:60%;" />

看栈调用应该是崩溃在asio底层iocp模型写回调里了。
那我们可以用注释的方式排查问题。我们把handle_write回调里面的逻辑注释掉

```c++
void Session::handle_write(const boost::system::error_code& error) {
    // if (!error) {
    //     memset(_data, 0, max_length);
    //     _socket.async_read_some(boost::asio::buffer(_data, max_length), std::bind(&Session::handle_read,
    //         this, placeholders::_1, placeholders::_2));
    // }
    // else {
    //     delete this;
    // }
}
```

再次启动客户端和服务器，在服务器收到读回调后断点并关闭客户端，服务器放开断点继续执行，未发现崩溃。

观察注释掉的逻辑，最有嫌疑的是`delete this`, 我们仅仅将`delete this`注释掉后就不会崩溃了，那我们找到问题根因了

第一次回调触发handle_read没问题，此时在回调里关闭客户端，因为第一次回调再次调用`async_read_some`将读事件注册给asio底层的事件循环，调用`async_write`将写事件注册给asio底层循环，当客户端关闭后会第二次触发读回调，这次读回调会执行delete操作，delete this之后，Session所有的数据都被回收，而写回调也会触发，因为那么就行了二次delete操作，这就是double free问题等。 

### 资源竞争

资源竞争大部分情况是逻辑错误，比如两个线程A和B同时修改互斥区域，互斥区域未加锁，这期间也可能造成崩溃，比如线程A删除了数据C，而线程B正在访问数据C，引发崩溃后大家不要慌，先看崩溃的堆栈信息，如果是指针显示为0xdddd之类的说明是访问了被删除的数据，那么我们排查删除的逻辑，或者屏蔽删除的逻辑看看会不会出问题，基本思路是

1. 崩溃看堆栈信息，排查是不是野指针或者double free问题。
2. 如果不是崩溃信息，数据混乱就查找修改数据的逻辑，或者屏蔽这个逻辑，看看是不是多线程造成的。
3. 崩溃问题也可以通过屏蔽部分逻辑排查是不是多线程导致的。
4. 在必要的逻辑区间增加日志，排查逻辑异常的上层原因。

这部分问题要结合实际工作去排查，慢慢熟悉这种思路以后就不陌生了。

### 死锁问题

多线程出现死锁问题是很头疼，现象不如内存崩溃或者资源竞争那么明显，表现给开发者的是一种卡死的现象。造成死锁的根本原因在于锁资源互相竞争，遇到这种问题要先梳理逻辑，找到互相引用的关键点。  
我们通过代码仓库中concurrent文件夹day24-TroubleShoot 中deadlock.h演示

```c++
void deadlockdemo() {
    std::mutex mtx;
    int global_data = 0;
    std::thread t1([&mtx, &global_data]() {
        std::lock_guard<std::mutex> outer_lock(mtx);
        global_data++;
        std::async([&mtx, &global_data]() {
            std::lock_guard<std::mutex> inner_lock(mtx);
            global_data++;
            std::cout << global_data << std::endl;
            });
    });
    t1.join();
}
```

主函数调用这个函数，主进程无法退出。因为不是崩溃问题所以无法查看调用栈，对于这个问题，我们在关键位置打印日志，看看具体走到哪里出了问题。

```c++
void deadlockdemo() {
    std::mutex mtx;
    int global_data = 0;
    std::thread t1([&mtx, &global_data]() {
        std::cout << "begin lock outer_lock..." << std::endl;
        std::lock_guard<std::mutex> outer_lock(mtx);
        std::cout << "after lock outer_lock..." << std::endl;
        global_data++;
        std::async([&mtx, &global_data]() {
            std::cout << "begin lock inner_lock..." << std::endl;
            std::lock_guard<std::mutex> inner_lock(mtx);
            std::cout << "after lock inner_lock..." << std::endl;
            global_data++;
            std::cout << global_data << std::endl;
            std::cout << "unlock inner_lock..." << std::endl;
            });
        std::cout << "unlock  outer_lock..." << std::endl;
    });
    t1.join();
}
```

日志输出

```
begin lock outer_lock...
after lock outer_lock...
begin lock inner_lock...
```

可以看到内部锁没有加成功。这种情况就是死锁了，再来分析原因，因为async会返回一个future，作为右值这个future会立即调用析构函数，析构函数内部会等待任务完成(并发编程已经从源码剖析了，这里不再赘述)。内部任务要加锁加不上，外部解不开锁因为async返回的future析构无法调用成功。这就是死锁的原因了。  
修正，只要让future不立即调用析构即可，我们可以用变量接受future,这样析构就会延缓到解锁之后，变量可以放在最外层，这样变量不会触发析构。

```c++
void lockdemo() {
    std::mutex mtx;
    int global_data = 0;
    std::future<void> future_res;
    std::thread t1([&mtx, &global_data,&future_res]() {
        std::cout << "begin lock outer_lock..." << std::endl;
        std::lock_guard<std::mutex> outer_lock(mtx);
        std::cout << "after lock outer_lock..." << std::endl;
        global_data++;
        future_res = std::async([&mtx, &global_data]() {
            std::cout << "begin lock inner_lock..." << std::endl;
            std::lock_guard<std::mutex> inner_lock(mtx);
            std::cout << "after lock inner_lock..." << std::endl;
            global_data++;
            std::cout << global_data << std::endl;
            std::cout << "unlock inner_lock..." << std::endl;
            });
        std::cout << "unlock  outer_lock..." << std::endl;
        });
    t1.join();
}
```

程序输出

```
begin lock outer_lock...
after lock outer_lock...
unlock  outer_lock...
begin lock inner_lock...
after lock inner_lock...
2
unlock inner_lock...
```

关于活锁，解决方式类似，在关键位置添加注释排查具体原因。

### 引用释放的变量

随着C++ 11 lambda表达式推出后，编程更方便了，但是引用释放的变量这个问题也随之而来。案例在day24-TroubleShoot文件夹deadlock.cpp中reference_invalid函数。

```c++
void reference_invalid()
{
     class task_data {
     public:
         task_data(int i):_data(new int(i)){}
         ~task_data() { delete _data; }
         int* _data;
     };
     std::queue<std::function<void()>> task_que;
     for (int i = 0; i < 10; i++) {
         task_data data(i);
         task_que.push([&data]() {
             (*data._data)++;
             std::cout << "data is " << *data._data << std::endl;
             });
     }
    auto res_future =  std::async([&task_que]() {
            for (;;) {
                if (task_que.empty()) {
                    break;
                }
                auto& task = task_que.front();
                task();
                task_que.pop();
            }
        });
    res_future.wait();
}
```

上述函数调用后输出的数值为

```c++
data is -572662307
data is 1349705340
data is -2147481856
data is -572662307
data is -572662307
data is -572662307
data is -572662307
data is -572662307
data is -572662307
data is -572662307
```

为什么数据变乱了呢？我们分析一下，这种多线程的逻辑问题就要通过加日志或者梳理逻辑排查了。异步任务里从任务队列弹出任务并执行，我们观察任务是一个lambda表达式，捕获的是task_data类型的引用，既然是引用就有生命周期，我们在将task放入队列时，task_data类型变量data为局部变量，此时还未失效，等离开循环的作用域调用data会调用析构函数，那么内部的数据就被释放了，所以之后线程异步访问时会出现乱码。

怎么改呢？我们在网络编程中介绍了一种思路，利用智能指针构造一个伪闭包逻辑，C++不像js，python，go等有闭包机制，但是我们可以通过智能指针增加引用计数，达到闭包效果。

```c++
void reference_sharedptr()
 {
     class task_data {
     public:
         task_data(int i) :_data(new int(i)) {}
         ~task_data() { delete _data; }
         int* _data;
     };
     std::queue<std::function<void()>> task_que;
     for (int i = 0; i < 10; i++) {
         std::shared_ptr<task_data> taskptr = std::make_shared<task_data>(i);
         task_que.push([taskptr]() {
            (*( taskptr->_data))++;
             std::cout << "data is " << *(taskptr->_data) << std::endl;
             });
     }
     auto res_future = std::async([&task_que]() {
         for (;;) {
             if (task_que.empty()) {
                 break;
             }
             auto& task = task_que.front();
             task();
             task_que.pop();
         }
         });
     res_future.wait();
 }
```

再次运行输出正确。

### 浅拷贝

浅拷贝这个词对于C++开发者并不陌生，如果没有合理的内存管理机制，浅拷贝会造成很严重的内存崩溃问题。  
看下面这个例子,同样在day24-TroubleShoot文件夹deadlock.cpp中

```c++
void shallow_copy(){
     class task_data {
     public:
         task_data(int i) :_data(new int(i)) {}
         ~task_data() { 
             std::cout << "call task_data destruct" << std::endl;
             delete _data; 
         }
         int* _data;
     };
     task_data data1(1);
     task_data data2 = std::move(data1);
 }
```

上面这个例子运行会导致崩溃，我们看data1移动给data2后，二者在作用域结束时都进行析构。

因为我们没实现移动构造和拷贝构造，系统默认的移动构造执行拷贝构造，默认的拷贝构造是浅拷贝，所以data1和data2内部的`_data`引用同一块内存，他们析构的时候会造成二次析构。

读者可能觉得这个例子太简单，不会犯错，那我们看第二个例子

```c++
void shallow_copy2(){
     class task_data {
     public:
         task_data(int i) :_data(new int(i)) {}
         ~task_data() {
             std::cout << "call task_data destruct" << std::endl;
             delete _data;
         }
         int* _data;
     };
     auto task_call = []() -> task_data {
         task_data data(100);
         return data;
     };
     task_call();
 }
```

第二个例子中我们定义了一个lambda表达式task_call，返回task_data类型的对象。

关于返回局部对象，编译器有两种情况：

1. 如果编译器支持返回值优化（Return Value Optimization, RVO），那么在返回局部对象时，编译器可能会通过返回值优化来避免执行移动构造函数。RVO 是一种编译器优化技术，可以避免对返回值进行拷贝或移动操作，直接将局部对象的值放置到调用者提供的空间中，从而减少了不必要的资源开销和性能消耗。
2. 在 C++11 引入移动语义后，编译器有权将返回的局部对象视为右值，从而执行移动构造而非拷贝构造。
    

无论上述哪一种，都是将值返回，那么都会执行浅拷贝，局部变量随着作用域结束被释放，内部的内存`_data`被回收，而外部接收的返回值仍在引用`_data`，此时`_data`就是野指针。外部对象释放会造成二次析构，或者外部对象使用`_data`时也会引发野指针崩溃问题。

解决的方式就是实现拷贝构造和移动构造。

```c++
void normal_copy() {
     class task_data {
     public:
         task_data(int i) :_data(new int(i)) {}
         ~task_data() {
             std::cout << "call task_data destruct" << std::endl;
             delete _data;
         }
         task_data(const task_data& src) {
             _data = new int(*(src._data));
         }
         task_data(task_data&& src) {
             _data = new int(*(src._data));
         }
         int* _data;
     };
     auto task_call = []() -> task_data {
         task_data data(100);
         return data;
     };
     task_call();
 }
```

再次运行，看到调用两个析构函数，并且未崩溃

```c++
call task_data destruct
call task_data destruct
main exit
```

### 线程管控

多线程编程常遇到的一个问题就是线程管控。案例在day24-TroubleShoot文件夹deadlock.cpp中。
我们实现了一个生产者和消费者的管理类和一个用来控制退出的原子变量。

```c++
std::atomic<bool>  b_stop = false;
class ProductConsumerMgr {
public:
    ProductConsumerMgr(){
        _consumer = std::thread([this]() {
            while (!b_stop) {
                std::unique_lock<std::mutex> lock(_mtx);
                _consume_cv.wait(lock, [this]() {
                    if (_data_que.empty()) {
                        return false;
                        }
                    return true;
                    });
                int data = _data_que.front();
                _data_que.pop();
                std::cout << "pop data is " << data << std::endl;
                lock.unlock();
                _producer_cv.notify_one();
                }
            });
        _producer = std::thread([this]() {
            int data = 0;
            while (!b_stop) {
                std::unique_lock<std::mutex> lock(_mtx);
                _producer_cv.wait(lock, [this]() {
                    if (_data_que.size() > 100) {
                        return false;
                    }
                    return true;
                    });
                _data_que.push(++data);
                std::cout << "push data is " << data << std::endl;
                lock.unlock();
                _consume_cv.notify_one();
            }
            });
    }
    ~ProductConsumerMgr(){
        _producer.join();
        _consumer.join();
    }
private:
    std::mutex _mtx;
    std::condition_variable _consume_cv;
    std::condition_variable _producer_cv;
    std::queue<int> _data_que;
    std::thread _consumer;
    std::thread _producer;
};
```

1. 生产者不断生产数据放入队列，消费者不断从队列消费数据。
2. ProductConsumerMgr析构时等待生产者和消费者两个线程退出。
3. `b_stop`用来控制线程退出。

我们实现捕获ctl+c以及关闭窗口信号的函数，然后将b_stop设置为true.

```c++
BOOL CtrlHandler(DWORD fdwCtrlType)
  {
      switch (fdwCtrlType)
      {
          // Handle the CTRL-C signal. 
      case CTRL_C_EVENT:
          printf("Ctrl-C event\n\n");
          b_stop = true;
          return(TRUE);
          // CTRL-CLOSE: confirm that the user wants to exit. 
      case CTRL_CLOSE_EVENT:
          b_stop = true;
          printf("Ctrl-Close event\n\n");
          return(TRUE);
      case CTRL_SHUTDOWN_EVENT:
          b_stop = true;
          printf("Ctrl-Shutdown event\n\n");
          return FALSE;
      default:
          return FALSE;
      }
  }
  void TestProducerConsumer()
  {
      SetConsoleCtrlHandler((PHANDLER_ROUTINE)CtrlHandler, TRUE);
      ProductConsumerMgr mgr;
      while (!b_stop) {
          std::this_thread::sleep_for(std::chrono::milliseconds(10));
      }
  }
```

在主函数中启动TestProducerConsumer，生产者和消费者会不断工作，我们按下ctrl+c会中断程序，程序可以安全退出。在一般情况下没有问题，是不是意味着我们的程序足够健壮呢？

我们延缓生产者生产的效率，假设一个小时生产一个数据放入队列，此时Ctrl+c看看是否会中断程序

```c++
_producer = std::thread([this]() {
    int data = 0;
    while (!b_stop) {
        std::this_thread::sleep_for(std::chrono::seconds(5));
        std::unique_lock<std::mutex> lock(_mtx);
        _producer_cv.wait(lock, [this]() {
        if (_data_que.size() > 100) {
            return false;
            }
            return true;
        });
        _data_que.push(++data);
        std::cout << "push data is " << data << std::endl;
        lock.unlock();
        _consume_cv.notify_one();
    }
});
```

生产者改为上述每5s产生一个数据，此时ctrl+c并不会中断程序，程序不会退出。

问题的根本在于条件竞争，当我们的生产者生产效率低时，队列为空，测试消费者线程处于挂起状态，ctrl+c虽然将停止信号设置为true，但是ProductConsumerMgr析构并不能执行完成，析构函数会等待两个线程退出，消费者线程不会退出，因为处于挂起状态了。

怎么办呢？我们可以在析构里通知两个线程退出即可。而且两个线程要增加唤醒后判断停止标记的逻辑。

```c++
~ProductConsumerMgr(){
    _consume_cv.notify_one();
    _producer_cv.notify_one();
    _producer.join();
    _consumer.join();
}
```

两个线程增加条件判断

```c++
ProductConsumerMgr(){
        _consumer = std::thread([this]() {
            while (!b_stop) {
                std::unique_lock<std::mutex> lock(_mtx);
                _consume_cv.wait(lock, [this]() {
                    if (b_stop) {
                        return true;
                    }
                    if (_data_que.empty()) {
                        return false;
                        }
                    return true;
                    });
                if (b_stop) {
                    return ;
                }
                int data = _data_que.front();
                _data_que.pop();
                std::cout << "pop data is " << data << std::endl;
                lock.unlock();
                _producer_cv.notify_one();
                }
            });
        _producer = std::thread([this]() {
            int data = 0;
            while (!b_stop) {
                std::this_thread::sleep_for(std::chrono::seconds(5));
                std::unique_lock<std::mutex> lock(_mtx);
                _producer_cv.wait(lock, [this]() {
                    if (b_stop) {
                        return true;
                    }
                    if (_data_que.size() > 100) {
                        return false;
                    }
                    return true;
                    });
                if (b_stop) {
                    return ;
                }
                _data_que.push(++data);
                std::cout << "push data is " << data << std::endl;
                lock.unlock();
                _consume_cv.notify_one();
            }
            });
    }
```

按下ctrl+c后，程序输出如下，并且正常退出

```c++
push data is 1
pop data is 1
Ctrl-C event
main exit
```

多线程之间协同工作以及安全退出是设计要考虑的事情。

### 混用智能指针和裸指针

有时候混用智能指针和裸指针，我们也会不小心delete一个交给只能指针管理的裸指针。单例在day24-TroubleShoot文件夹中ThreadSafeQue.h以及deadlock.cpp中。

之前我们为了让线程池从其他队列的尾部窃取任务，所以用双向链表实现了线程安全队列，并且实现了从尾部pop数据的方法。

```c++
bool try_steal(T& value) {
    std::unique_lock<std::mutex> tail_lock(tail_mutex,std::defer_lock);
    std::unique_lock<std::mutex>  head_lock(head_mutex, std::defer_lock);
    std::lock(tail_lock, head_lock);
    if (head.get() == tail)
    {
        return false;
    }
    node* prev_node = tail->prev;
    value = std::move(*(prev_node->data));
    delete tail;
    tail = prev_node;
    tail->next = nullptr;
    return true;
}
```

我们实现测试用例，一个线程push数据，一个线程从尾部pop数据，一个线程

```c++
void TestSteal() {
      threadsafe_queue<int> que;
      std::thread t1([&que]() {
          int index = 0;
          for (; ; ) {
              index++;
              que.push(index);
              std::this_thread::sleep_for(std::chrono::milliseconds(200));
          }
          });
      std::thread t3([&que]() {
          for (; ; ) {
              int value;
              bool res = que.try_pop(value);
              if (!res) {
                  std::this_thread::sleep_for(std::chrono::seconds(1));
                  continue;
              }
              std::cout << "pop out value is " << value << std::endl;
          }
          });
      std::thread t2([&que]() {
          for (; ; ) {
              int value;
              bool res = que.try_steal(value);
              if (!res) {
                  std::this_thread::sleep_for(std::chrono::seconds(1));
                  continue;
              }
              std::cout << "steal out value is " << value << std::endl;
          }
          });
      t1.join();
      t2.join();
      t3.join();
  }
```

执行TestSteal时，程序崩溃。

<img src="https://cdn.llfc.club/1708753868812.jpg" alt="image.png" style="zoom:60%;" />

查看堆栈上层信息，崩溃在try_steal这个函数里了。

<img src="https://cdn.llfc.club/1708754187835.jpg" alt="image.png" style="zoom:60%;" />

多线程排查问题时，先把最有嫌疑的线程屏蔽，我们把try_steal的线程屏蔽，发现没有引发崩溃。可以确定是try_steal导致。

我们看try_steal函数内部，涉及内存的有个delete tail, 我们将这个delete tail 注释，发现没问题了。可见是delete tail 出了问题，结合底层崩溃的信息是unique_ptr的析构函数，可以推断我们混用了裸指针和智能指针，很可能是delete了智能指针管理的内存，导致智能指针析构的时候又一次delete内存引发崩溃。  
我们看下队列里节点的设计

```c++
struct node
{
    std::shared_ptr<T> data;
    std::unique_ptr<node> next;
    node* prev;
};
std::mutex head_mutex;
std::unique_ptr<node> head;
std::mutex tail_mutex;
node* tail;
```

队列是通过node构造的链表，每个节点的next指针为智能指针指向下一个节点，head为`std::unique_ptr<node>`，tail虽然为`node*`类型的指针，但是是从智能指针get获取的，那么tail是不应该删除的。

解决的办法就是不用delete即可，pop 尾部节点后将新的尾部节点next指针设置为nullptr，这样就相当于对原tail所属的unique_ptr减少引用计数了。