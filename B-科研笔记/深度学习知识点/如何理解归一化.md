## 归一化
在机器学习领域中，**不同评价指标（即特征向量中的不同特征就是所述的不同评价指标）往往具有不同的量纲和量纲单位，这样的情况会影响到数据分析的结果，**

为了消除指标之间的量纲影响，需要进行<font color=#ff0000>数据标准化处理</font>，以解决数据指标之间的可比性。原始数据经过数据标准化处理后，各指标处于同一数量级，适合进行综合对比评价。其中，最典型的就是数据的归一化处理。

**简而言之，归一化的目的就是使得预处理的数据被限定在一定的范围内（比如`[0,1]`或者`[-1,1]`），从而消除奇异样本数据导致的不良影响。**

奇异样本数据是指相对于其他输入样本特别大或特别小的样本矢量（即特征向量）

譬如，下面为具有两个特征的样本数据x1、x2、x3、x4、x5、x6（特征向量—>列向量）,其中x6这个样本的两个特征相对其他样本而言相差比较大，因此，x6认为是奇异样本数据。
![链接](https://img-blog.csdnimg.cn/img_convert/3e6e5ae01efdc6e97353275439b307de.png)

**奇异样本数据的存在会引起训练时间增大，同时也可能导致无法收敛，因此，当存在奇异样本数据时，在进行训练之前需要对预处理数据进行归一化；反之，不存在奇异样本数据时，则可以不进行归一化。**

## 归一化的对比

--如果不进行归一化，那么由于特征向量中不同特征的取值相差较大，会导致目标函数变“扁”。这样在进行梯度下降的时候，梯度的方向就会偏离最小值的方向，走很多弯路，即训练时间过长。
![链接](https://img-blog.csdnimg.cn/img_convert/83669dc245a2ea4f053f40cb79d70598.png)
--如果进行归一化以后，目标函数会呈现比较“圆”，这样训练速度大大加快，少走很多弯路。
![链接](https://img-blog.csdnimg.cn/img_convert/ba3f189b59ce8faaf237cd02f24a59b6.png)

综上可知，归一化有如下好处，即

1）**归一化后加快了梯度下降求最优解的速度，也即加快训练网络的收敛性；**

2）归一化有可能提高精度

## **几种归一化的方法**

### 1 最大最小标准化（Min-Max Normalization）
![链接](https://img-blog.csdnimg.cn/img_convert/c8c44336ef21d5d607e00b58e71b9f9b.png)
(1) 线性函数将原始数据线性化的方法转换到[0 1]的范围, 计算结果为归一化后的数据，X为原始数据

(2) 本归一化方法比较适用在**数值比较集中**的情况；

(3) **缺陷**：如果max和min不稳定，很容易使得归一化结果不稳定，使得后续使用效果也不稳定。实际使用中可以用经验常量来替代max和min。

**应用场景：**在不涉及距离度量、协方差计算、数据不符合正太分布的时候，可以使用第一种方法或其他归一化方法（不包括**Z-score方法**）。比如图像处理中，将RGB图像转换为灰度图像后将其值限定在`[0 255]`的范围
### 2 z—score 标准化
![链接](https://img-blog.csdnimg.cn/img_convert/16d18faec8d797357844bc9775ed9adb.png)
其中，μ、σ分别为原始数据集的均值和方法。

（1） 将原始数据集归一化为均值为0、方差1的数据集

（2） 该种归一化方式要求原始数据的分布可以近似为高斯分布，否则归一化的效果会变得很糟糕。

**应用场景**：在分类、聚类算法中，需要使用距离来度量相似性的时候、或者使用PCA技术进行降维的时候，`Z-score standardization`表现更好。

## **什么时候用归一化？**

（1）**如果对输出结果范围有要求**，用归一化。

（2）**如果数据较为稳定，不存在极端的最大最小值**，用归一化。

（3）**如果数据存在异常值和较多噪音，用标准化，可以间接通过中心化避免异常值和极端值的影响。**
